{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-714 Homework 4\n",
    "\n",
    "In this homework, you will leverage all of the components built in the last three homeworks to solve some modern problems with high performing network structures. We will start by integrating the NDArray implementation from Homework 3 into needle. Then, you will implement convolution, and a convolutional neural network to train a classifier on the CIFAR-10 image classification dataset. Then, you will implement recurrent and long-short term memory (LSTM) neural networks, and do word-level prediction language modeling on the Penn Treebank dataset.\n",
    "\n",
    "As always, we will start by copying this notebook and getting the starting code.\n",
    "Reminder: __you must save a copy in drive__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to set up the assignment\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/\n",
    "!mkdir -p 10714\n",
    "%cd /content/drive/MyDrive/10714\n",
    "!git clone https://github.com/dlsys10714/hw4.git\n",
    "%cd /content/drive/MyDrive/10714/hw4\n",
    "\n",
    "!pip3 install --upgrade --no-deps git+https://github.com/dlsys10714/mugrade.git\n",
    "!pip3 install pybind11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar-10-batches-py/\n",
      "cifar-10-batches-py/data_batch_4\n",
      "cifar-10-batches-py/readme.html\n",
      "cifar-10-batches-py/test_batch\n",
      "cifar-10-batches-py/data_batch_3\n",
      "cifar-10-batches-py/batches.meta\n",
      "cifar-10-batches-py/data_batch_2\n",
      "cifar-10-batches-py/data_batch_5\n",
      "cifar-10-batches-py/data_batch_1\n"
     ]
    }
   ],
   "source": [
    "# Download the datasets you will be using for this assignment\n",
    "\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "!mkdir -p './data/ptb'\n",
    "# Download Penn Treebank dataset\n",
    "ptb_data = \"https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.\"\n",
    "for f in ['train.txt', 'test.txt', 'valid.txt']:\n",
    "    if not os.path.exists(os.path.join('./data/ptb', f)):\n",
    "        urllib.request.urlretrieve(ptb_data + f, os.path.join('./data/ptb', f))\n",
    "\n",
    "# Download CIFAR-10 dataset\n",
    "if not os.path.isdir(\"./data/cifar-10-batches-py\"):\n",
    "    urllib.request.urlretrieve(\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\", \"./data/cifar-10-python.tar.gz\")\n",
    "    !tar -xvzf './data/cifar-10-python.tar.gz' -C './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish setting up the assignment, go ahead and fill in all the code in `python/needle/autograd.py` using your solution code from the previous homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: ND Backend [10 pts]\n",
    "\n",
    "In Homework 3 you wrote an a generic ND Array backend. Before progressing to larger, more time consuming models, we need to integrate this new ND Array backend into needle. Fill in the code for the following operations in `python/needle/nd_backend.py`:\n",
    "- `divide`\n",
    "- `divide_scalar`\n",
    "- `power_scalar`\n",
    "- `matmul`\n",
    "- `summation`\n",
    "- `broadcast_to`\n",
    "- `reshape`\n",
    "- `negate`\n",
    "- `transpose`\n",
    "- `log`\n",
    "- `exp`\n",
    "- `relu`\n",
    "- `logsoftmax`\n",
    "- `tanh`\n",
    "- `get_item`\n",
    "- `set_item`\n",
    "- `stack`\n",
    "\n",
    "This will be similar to what you wrote previously in `python/needle/numpy_backend.py`, but this time you will be using the NDArray backend for cached data and computation rather than numpy. \n",
    "\n",
    "You should also fill in the `gradient` function for the following classes in `python/needle/ops.py`:\n",
    "\n",
    "- `EWiseDivOp`\n",
    "- `DivScalarOp`\n",
    "- `PowerScalarOp`\n",
    "- `MatMulOp`\n",
    "- `SummationOp`\n",
    "- `BroadcastToOp`\n",
    "- `ReshapeOp`\n",
    "- `NegateOp`\n",
    "- `TransposeOp`\n",
    "- `LogOp`\n",
    "- `ExpOp`\n",
    "- `ReLUOp`\n",
    "- `LogSoftmaxOp`\n",
    "- `TanhOp`\n",
    "- `GetItemOp`\n",
    "- `StackOp`\n",
    "\n",
    "Note that for most of these, you already wrote the solutions in the previous homework and you should not need to change your previous solution, however `TanhOp`, `GetItemOp`, and `Stack` are newly added. You do not need to fill in the gradient function for `SetItemOp` because in-place operations are not currently supported in our computational graph, however we will be using the forward pass of set item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"nd_backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m mugrade submit \"Bjo9uucaPqkSTXyqSoEv\" -k \"new_nd_backend\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: CIFAR-10 dataset [10 points]\n",
    "\n",
    "Next, you will write support for the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) image classification dataset, which consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. There are 50k training images and 10k test images. \n",
    "\n",
    "Start by implementing the `__init__` function in the `CIFAR10Dataset` class. You can read in the link above how to properly read the CIFAR-10 dataset files you downloaded at the beginning of the homework. Also fill in `__getitem__` and `__len__`. Note that the return shape of the data from `__getitem__` should be in order (3, 32, 32).\n",
    "\n",
    "You will need implement the `collate_ndarray` function - this will be similar to the `collate_mnist` function you wrote previously, except the cached data of the returned Tensor will be ND arrays, and the dtype will be `\"float32\"` (as this is the only dtype currently supported by ND array). and `CIFAR10Dataset` in `python/needle/data.py`. \n",
    "\n",
    "You should also fill in the `fetch` function of the `_IterableDatasetFetcher` that you wrote in the previous homework. The only difference is when you call `collate_fn` in this function, you will need to pass `device` and `dtype` as arguments as well. (You do not need to bother filling in the MNIST-related code here - we will not be using the MNIST dataset for this Homework.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.9.7, pytest-6.2.4, py-1.10.0, pluggy-0.13.1 -- /home/dasongg/miniconda3/envs/py39/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/dasongg/cmu/10714/hws/needle\n",
      "plugins: anyio-3.3.4\n",
      "collected 2079 items / 2067 deselected / 12 selected                           \u001b[0m\n",
      "\n",
      "tests/hw4/test_conv.py::test_train_cifar10[device0] \u001b[31mFAILED\u001b[0m\u001b[31m               [  8%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_train_cifar10[device1] \u001b[31mFAILED\u001b[0m\u001b[31m               [ 16%]\u001b[0m\n",
      "tests/hw4/test_data.py::test_cifar10_dataset[True] \u001b[32mPASSED\u001b[0m\u001b[31m                [ 25%]\u001b[0m\n",
      "tests/hw4/test_data.py::test_cifar10_dataset[False] \u001b[32mPASSED\u001b[0m\u001b[31m               [ 33%]\u001b[0m\n",
      "tests/hw4/test_data.py::test_cifar10_loader[cpu-True-1] \u001b[32mPASSED\u001b[0m\u001b[31m           [ 41%]\u001b[0m\n",
      "tests/hw4/test_data.py::test_cifar10_loader[cpu-True-15] \u001b[32mPASSED\u001b[0m\u001b[31m          [ 50%]\u001b[0m\n",
      "tests/hw4/test_data.py::test_cifar10_loader[cpu-False-1] \u001b[32mPASSED\u001b[0m\u001b[31m          [ 58%]\u001b[0m\n",
      "tests/hw4/test_data.py::test_cifar10_loader[cpu-False-15] \u001b[32mPASSED\u001b[0m\u001b[31m         [ 66%]\u001b[0m\n",
      "tests/hw4/test_data.py::test_cifar10_loader[cuda-True-1] \u001b[32mPASSED\u001b[0m\u001b[31m          [ 75%]\u001b[0m\n",
      "tests/hw4/test_data.py::test_cifar10_loader[cuda-True-15] \u001b[32mPASSED\u001b[0m\u001b[31m         [ 83%]\u001b[0m\n",
      "tests/hw4/test_data.py::test_cifar10_loader[cuda-False-1] \u001b[32mPASSED\u001b[0m\u001b[31m         [ 91%]\u001b[0m\n",
      "tests/hw4/test_data.py::test_cifar10_loader[cuda-False-15] \u001b[32mPASSED\u001b[0m\u001b[31m        [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_________________________ test_train_cifar10[device0] __________________________\u001b[0m\n",
      "\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_train_cifar10\u001b[39;49;00m(device):\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\n",
      "        dataset = ndl.data.CIFAR10Dataset(\u001b[33m\"\u001b[39;49;00m\u001b[33m./data/cifar-10-batches-py\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, train=\u001b[94mTrue\u001b[39;49;00m)\n",
      "        dataloader = ndl.data.DataLoader(\\\n",
      "                 dataset=dataset,\n",
      "                 batch_size=\u001b[94m128\u001b[39;49;00m,\n",
      "                 shuffle=\u001b[94mTrue\u001b[39;49;00m,\n",
      "                 collate_fn=ndl.data.collate_ndarray,\n",
      "                 drop_last=\u001b[94mFalse\u001b[39;49;00m,\n",
      "                 device=device,\n",
      "                 dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                 )\n",
      "        \u001b[94mfrom\u001b[39;49;00m \u001b[04m\u001b[96mapps\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mmodels\u001b[39;49;00m \u001b[94mimport\u001b[39;49;00m ResNet9\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\n",
      ">       model = ResNet9(device=device, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "ResNet9    = <class 'apps.models.ResNet9'>\n",
      "dataloader = <needle.data.DataLoader object at 0x7f1515d00280>\n",
      "dataset    = <needle.data.CIFAR10Dataset object at 0x7f1515d002b0>\n",
      "device     = cpu(0)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:461: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <apps.models.ResNet9 object at 0x7f1515d007c0>, device = cpu(0)\n",
      "dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\n",
      "        \u001b[96msuper\u001b[39;49;00m().\u001b[92m__init__\u001b[39;49;00m()\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION ###\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m() \u001b[90m###\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'apps.models.ResNet9'>\n",
      "device     = cpu(0)\n",
      "dtype      = 'float32'\n",
      "self       = <apps.models.ResNet9 object at 0x7f1515d007c0>\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:14: NotImplementedError\n",
      "\u001b[31m\u001b[1m_________________________ test_train_cifar10[device1] __________________________\u001b[0m\n",
      "\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_train_cifar10\u001b[39;49;00m(device):\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\n",
      "        dataset = ndl.data.CIFAR10Dataset(\u001b[33m\"\u001b[39;49;00m\u001b[33m./data/cifar-10-batches-py\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, train=\u001b[94mTrue\u001b[39;49;00m)\n",
      "        dataloader = ndl.data.DataLoader(\\\n",
      "                 dataset=dataset,\n",
      "                 batch_size=\u001b[94m128\u001b[39;49;00m,\n",
      "                 shuffle=\u001b[94mTrue\u001b[39;49;00m,\n",
      "                 collate_fn=ndl.data.collate_ndarray,\n",
      "                 drop_last=\u001b[94mFalse\u001b[39;49;00m,\n",
      "                 device=device,\n",
      "                 dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                 )\n",
      "        \u001b[94mfrom\u001b[39;49;00m \u001b[04m\u001b[96mapps\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mmodels\u001b[39;49;00m \u001b[94mimport\u001b[39;49;00m ResNet9\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\n",
      ">       model = ResNet9(device=device, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "ResNet9    = <class 'apps.models.ResNet9'>\n",
      "dataloader = <needle.data.DataLoader object at 0x7f1515bf7bb0>\n",
      "dataset    = <needle.data.CIFAR10Dataset object at 0x7f1515bf7a90>\n",
      "device     = cuda(0)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:461: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <apps.models.ResNet9 object at 0x7f1515bf79d0>, device = cuda(0)\n",
      "dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\n",
      "        \u001b[96msuper\u001b[39;49;00m().\u001b[92m__init__\u001b[39;49;00m()\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION ###\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m() \u001b[90m###\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "__class__  = <class 'apps.models.ResNet9'>\n",
      "device     = cuda(0)\n",
      "dtype      = 'float32'\n",
      "self       = <apps.models.ResNet9 object at 0x7f1515bf79d0>\n",
      "\n",
      "\u001b[1m\u001b[31mapps/models.py\u001b[0m:14: NotImplementedError\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "../../../../miniconda3/envs/py39/lib/python3.9/site-packages/mugrade/mugrade.py:71\n",
      "  /home/dasongg/miniconda3/envs/py39/lib/python3.9/site-packages/mugrade/mugrade.py:71: PytestUnknownMarkWarning: Unknown pytest.mark.hookwrapper - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html\n",
      "    @pytest.mark.hookwrapper\n",
      "\n",
      "tests/hw4/test_data.py::test_cifar10_loader[cpu-True-1]\n",
      "tests/hw4/test_data.py::test_cifar10_loader[cpu-True-15]\n",
      "tests/hw4/test_data.py::test_cifar10_loader[cpu-False-1]\n",
      "tests/hw4/test_data.py::test_cifar10_loader[cpu-False-15]\n",
      "tests/hw4/test_data.py::test_cifar10_loader[cuda-True-1]\n",
      "tests/hw4/test_data.py::test_cifar10_loader[cuda-True-15]\n",
      "tests/hw4/test_data.py::test_cifar10_loader[cuda-False-1]\n",
      "tests/hw4/test_data.py::test_cifar10_loader[cuda-False-15]\n",
      "  /home/dasongg/miniconda3/envs/py39/lib/python3.9/site-packages/numpy/core/_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "    return array(a, dtype, copy=False, order=order, subok=True)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/warnings.html\n",
      "=========================== short test summary info ============================\n",
      "FAILED tests/hw4/test_conv.py::test_train_cifar10[device0] - NotImplementedError\n",
      "FAILED tests/hw4/test_conv.py::test_train_cifar10[device1] - NotImplementedError\n",
      "\u001b[31m========== \u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[32m10 passed\u001b[0m, \u001b[33m2067 deselected\u001b[0m, \u001b[33m9 warnings\u001b[0m\u001b[31m in 8.37s\u001b[0m\u001b[31m ===========\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"cifar10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m mugrade submit \"Bjo9uucaPqkSTXyqSoEv\" -k \"cifar10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 3: Convolutional neural network [40 points]\n",
    "\n",
    "Here's an outline of what you will do in this task.\n",
    "\n",
    "In `python/needle/ndarray.py`, implement:\n",
    "- `flip`\n",
    "- `pad`\n",
    "\n",
    "In `python/needle/nd_backend.py`, implement:\n",
    "- `dilate`\n",
    "- `conv`\n",
    "\n",
    "In `python/needle/ops.py`, implement the `gradient` function for the following classes:\n",
    "- `FlipOp`\n",
    "- `DilateOp`\n",
    "- `ConvOp`\n",
    "\n",
    "In `python/needle/nn.py`, implement:\n",
    "- `Flatten`\n",
    "- `Conv`\n",
    "\n",
    "In `python/apps/models.py`, fill in the `ResNet9` class.  \n",
    "\n",
    "In `apps/simple_training.py`, fill in:\n",
    "- `epoch_general_cifar10`,\n",
    "- `train_cifar10`\n",
    "- `evaluate_cifar10`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding ndarrays\n",
    "\n",
    "Convolution as typically implemented in deep learning libraries cuts down the size of inputs;\n",
    "e.g., a (1, 32, 32, 3) image convolved with a 3x3 filter would give a (1, 30, 30, c) output.\n",
    "A way around this is to pad the input ndarray before performing convolution, e.g., pad with zeros to get a (1, 34, 34, 3) ndarray so that the result is (1, 32, 32, 3). \n",
    "\n",
    "Padding is also required for the backward pass of convolution.\n",
    "\n",
    "You should implement `pad` in `ndarray.py` to closely reflect the behavior of `np.pad`.\n",
    "That is, `pad` should take a tuple of 2-tuples with length equal to the number of dimensions of the array,\n",
    "where each element in the 2-tuple corresponds to \"left padding\" and \"right padding\", respectively.\n",
    "\n",
    "For example, if `A` is a (10, 32, 32, 8) ndarray (think NHWC), then `A.pad( (0, 0), (2, 2), (2, 2), (0, 0) )` would be a (10, 36, 36, 8) ndarray where the \"spatial\" dimension has been padded by two zeros on all sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"pad_forward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flipping ndarrays & FlipOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ctypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some utility code for a demonstration below which you can probably ignore. It might be instructive to check out the `offset` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads off the underlying data array in order (i.e., offset 0, offset 1, ..., offset n)\n",
    "# i.e., ignoring strides\n",
    "def raw_data(X):\n",
    "    X = np.array(X) # copy, thus compact X\n",
    "    return np.frombuffer(ctypes.string_at(X.ctypes.data, X.nbytes), dtype=X.dtype, count=X.size)\n",
    "\n",
    "# Xold and Xnew should reference the same underlying data\n",
    "def offset(Xold, Xnew):\n",
    "    assert Xold.itemsize == Xnew.itemsize\n",
    "    # compare addresses to the beginning of the arrays\n",
    "    return (Xnew.ctypes.data - Xold.ctypes.data)//Xnew.itemsize\n",
    "\n",
    "def strides(X):\n",
    "    return ', '.join([str(x//X.itemsize) for x in X.strides])\n",
    "\n",
    "def format_array(X, shape):\n",
    "    assert len(shape) == 3, \"I only made this formatting work for ndims = 3\"\n",
    "    def chunks(l, n):\n",
    "        n = max(1, n)\n",
    "        return (l[i:i+n] for i in range(0, len(l), n))\n",
    "    a = [str(x) if x >= 10 else ' ' + str(x) for x in X]\n",
    "    a = ['(' + ' '.join(y) + ')' for y in [x for x in chunks(a, shape[-1])]]\n",
    "    a = ['|' + ' '.join(y) + '|' for y in [x for x in chunks(a, shape[-2])]]\n",
    "    return '  '.join(a)\n",
    "\n",
    "def inspect_array(X, *, is_a_copy_of):\n",
    "    # compacts X, then reads it off in order\n",
    "    print('Data: %s' % format_array(raw_data(X), X.shape))\n",
    "    # compares address of X to copy_of, thus finding X's offset\n",
    "    print('Offset: %s' % offset(is_a_copy_of, X))\n",
    "    print('Strides: %s' % strides(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In order to implement the backwards pass of 2D convolution, we will (probably) need a function which _flips_\n",
    "axes of ndarrays. We say \"probably\" because you could probably cleverly implement your convolution forward\n",
    "function to avoid this. However, we think it is easiest to think about this if you have the ability to \"flip\" the kernel along its vertical and horizontal dimensions.\n",
    "\n",
    "We will try to build up your intuition for the \"flip\" operation below in order to help you figure out how to implement it in `ndarray.py`. To do that, we explore numpy's `np.flip` function below. One thing to note is that\n",
    "`flip` is typically implemented by using negative strides and changing the _offset_ of the underlying array.\n",
    "\n",
    "For example, flipping an array on _all_ of its axes is equivalent to reversing the array. In this case, you can imagine that we would want all the strides to be negative, and the offset to be the length of the array (to start at the end of the array and \"stride\" backwards).\n",
    "\n",
    "Since we did not explicitly support negative strides in our implementation for the last homework, we will merely call `NDArray.make` with them to make our \"flipped\" array and then immediately call `.compact()`. Other than changing unsigned ints to signed ints in a few places, we suspect your existing `compact` function should not have to change at all to accomodate negative strides. In the .cc and .cu files we distributed, we have already changed the function signatures to reflect this.\n",
    "\n",
    "Alternatively, you could simply implement `flip` in the CPU backend by copying memory, which you _may_ find more intuitive. We suggest following our mini tutorial below to keep your implementation Python-focused, since we believe it is involves approximately the same amount of effort to implement it slightly more naively in C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this array as reference for the other examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(1, 25).reshape(3, 2, 4)\n",
    "inspect_array(A, is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have put brackets around each axis of the array. Notice that for this array, the offset is 0 and the strides are all positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what happens when you flip the array along the last axis below. \n",
    "Note that the `inspect_array` function compacts the array after flipping it so you can see the\n",
    "\"logical\" order of the data, and the offset is calculated by comparing the address of the **non**-compacted\n",
    "flipped array with that of `is_copy_of`, i.e., the array `A` we looked at above.\n",
    "\n",
    "That is, we are looking at how numpy calculates the strides and offset for flipped arrays in order\n",
    "to copy this behavior in our own implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_array(np.flip(A, (2,)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So flipping the last axis reverses the order of the elements within each 4-dimensional \"cell\", as you can see above. The stride corresponding to the axis we flipped has been negated. And the offset is 3 -- this makes sense, e.g., because we want the new \"first\" element of the array to be 4, which was at index 3 in `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_array(np.flip(A, (1,)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again for the middle axis: we negate the middle stride, and the offset is 4, which seems reasonable since we now want the first element to be 5, which was at index 4 in the original array `A`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_array(np.flip(A, (0,)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to infer the more general algorithm for computing the offset given the axis to flip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe what happens when we flip _all_ axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_array(np.flip(A, (0,1,2)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, the offset is then sufficient to point to the last element of the array, and this is just the \"reverse order\" version of `A`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we flip just axes 1 and 0..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_array(np.flip(A, (0,1)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The offset is 20. Looking back on our previous offset computations, do you notice something?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "With this exploration of numpy's ndarray flipping functionality, which uses negative strides and a custom offset,\n",
    "try to implement `flip` in `ndarray.py`. You also must implement \"flip\" forward and backward functions in `nd_backend.py` and `ops.py`; note that these should be extremely short.\n",
    "\n",
    "**Important:** You should call NDArray.make with the new strides and offset, and then immediately `.compact()` this array. The resulting array is then copied and has positive strides. We want this (less-than-optimal) behavior because we did not account for negative strides in our previous implementation. _Aside:_ If you want, consider where/if negative strides break your implementation. `__getitem__` definitely doesn't work due to how we processed slices; is there anything else? (_Note_: this isn't graded.)\n",
    "\n",
    "Also, if you want to instead add a `flip` operator on the CPU/CUDA backends, that's also okay.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"flip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dilation operator puts zeros between elements of an ndarray. We will need it for computing the backward pass of convolution when the stride of the convolution is greater than 1. As an example, dilation should do the following to a 2x2 matrix when dilated by 1 on both axes:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix}\n",
    "\\Longrightarrow\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 2 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "3 & 0 & 4 & 0 \\\\\n",
    "0 & 0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "To get some intuition for why we need dilation for the backward pass of strided convolution, consider a  `stride=2`, `padding=\"same\"`, `input_channels=output_channels=8` convolution applied to an input of size (10, 32, 32, 8). The resulting output will be of size (10, 16, 16, 8) due to the stride, and thus `out_grad` will have shape (10, 16, 16, 8). Yet, the gradient of the input needs to, of course, have shape (10, 32, 32, 8) -- so we must need to increase the size of `out_grad` in some way. Consider also that you could implement strided convolution as `Conv(x)[:, ::2, ::2, :]`, i.e., only keeping every other pixel in the spatial dimension.\n",
    "\n",
    "\n",
    "Implement `dilate` in `nd_backend.py`. This function takes two additional parameters (in attrs): the `dilation` amount and the `axes` to dilate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"dilate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit new ops (flip/dilation) to mugrade [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.9.7, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "rootdir: /home/dasongg/cmu/10714/hws/needle\n",
      "plugins: anyio-3.3.4\n",
      "collected 47 items / 46 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw4/test_conv.py \n",
      "Submitting new_ops...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "Grader test 9 passed\n",
      "Grader test 10 failed: Failed: incorrect output\n",
      "Grader test 11 passed\n",
      "\u001b[31mF\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________________________________ submit_new_ops ________________________________\u001b[0m\n",
      "\n",
      "=========================== short test summary info ============================\n",
      "FAILED tests/hw4/test_conv.py::submit_new_ops\n",
      "\u001b[31m====================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m46 deselected\u001b[0m\u001b[31m in 10.66s\u001b[0m\u001b[31m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"Bjo9uucaPqkSTXyqSoEv\" -k \"new_ops\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution forward\n",
    "\n",
    "Implement the forward pass of 2D multi-channel convolution in `nd_backend.py`. You should probably refer to [this notebook](https://github.com/dlsys10714/notebooks/blob/main/14_convolution_implementation.ipynb) from lecture, which implements 2D multi-channel convolution using im2col in numpy.\n",
    "\n",
    "**Note:** Your convolution op should accept tensors in the NHWC format, as in the example above, and weights in the format (kernel_size, kernel_size, input_channels, output_channels).\n",
    "\n",
    "However, you will need to add two additional features. Your convolution function should accept (in `attrs`) arguments for `padding` (default 0) and `stride` (default 1). For `padding`, you should simply apply your padding function to the spatial dimensions (i.e., axes 1 and 2). \n",
    "\n",
    "Implementing strided convolution should consist of a relatively small set of changes to your plain convolution implementation.\n",
    "\n",
    "We recommend implementing convolution without stride first, ensuring you pass some of the tests below, and then adding in stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"op_conv and forward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the gradients of 2D multi-channel convolution can be technically quite challenging (especially \"rigorously\"). We will try to provide some useful hints here. Basically, we encourage you to make use of the surprising fact that _whatever makes the dimensions work out is typically right_.\n",
    "\n",
    "Ultimately, the backward pass of convolution can be done in terms of the convolution operator itself, with some clever manipulations using `flip`, `dilate`, and multiple applications of `transpose` to both the arguments and the results.\n",
    "\n",
    "In the last section, we essentially implemented convolution as a matrix product: ignoring the various restride and reshape operations, we basically have something like `X @ W`, where `X` is the input and `W` is the weight. We also have `out_grad`, which is the same shape as `X @ W`. Now, you have already implemented the backward pass of matrix multiplication in a previous assignment, and we can use this knowledge to get some insight into the backward pass of convolution. In particular, referencing your matmul backward implementation, you may notice (heuristically speaking here):\n",
    "\n",
    "`X.grad = out_grad @ W.transpose` \\\n",
    "`W.grad = X.transpose @ out_grad`\n",
    "\n",
    "Surprisingly enough, things work out if we just assume that these are also convolutions (and now assuming that `out_grad`, `W`, and `X` are tensors amenable to 2D multi-channel convolution instead of matrices):\n",
    "\n",
    "`X.grad = ≈conv(≈out_grad, ≈W)` \\\n",
    "`W.grad = ≈conv(≈X, ≈out_grad)`\n",
    "\n",
    "In which the \"≈\" indicates that you need to apply some additional operators to these terms in order to get the dimensions to work out, such as permuting/transposing axes, dilating, changing the `padding=` argument to the convolution function, or permuting/transposing axes of the resulting convolution.\n",
    "\n",
    "As we saw on the [last few slides here](https://dlsyscourse.org/slides/conv_nets.pdf) in class, the transpose of a convolution can be found by simply flipping the kernel. Since we're working in 2D instead of 1D, this means flipping the kernel both vertically and horizontally (thus why we implemented `flip`).\n",
    "\n",
    "Summarizing some hints for both `X.grad` and `W.grad`:\n",
    "\n",
    "`X.grad`\n",
    "- The convolution of `out_grad` and `W`, with some operations applied to those\n",
    "- `W` should be flipped over both the kernel dimensions\n",
    "- If the convolution is strided, increase the size of `out_grad` with a corresponding dilation\n",
    "- Do an example to analyze dimensions: note the shape you want for `X.grad`, and think about how you must permute/transpose the arguments and add padding to the convolution to achieve this shape \n",
    "    - This padding depends on both the kernel size and the `padding` argument to the convolution\n",
    "\n",
    "`W.grad`\n",
    "- The convolution of `X` and `out_grad`, with some operations applied to those\n",
    "- The gradients of `W` must be accumulated over the batches; how can you make the conv operator itself do this accumulation?\n",
    "    - Consider turning batches into channels via transpose/permute\n",
    "- Analyze dimensions: how can you modify `X` and `out_grad` so that the shape of their convolution matches the shape of `W`? You may need to transpose/permute the result.\n",
    "    - Remember to account for the `padding` argument passed to convolution\n",
    "\n",
    "General tips\n",
    "- Deal with strided convolutions last (you should be able to just drop in `dilate` when you've passed most of the tests)\n",
    "- Start with the case where `padding=0`, then consider changing `padding` arguments\n",
    "- You can \"permute\" axes with multiple calls to `transpose`\n",
    "\n",
    "It might also be useful to skip ahead to nn.Conv, pass the forward tests, and then use both the tests below and the nn.Conv backward tests to debug your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"op_conv and backward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Fixing init._calculate_fans for convolution\n",
    "Previously, you had to implement a helper function called `_calculate_fans` for intializing parameters of modules. At the time, the function essentially assigned `fan_in = input_size` and `fan_out = output_size`.\n",
    "For convolution, this becomes somewhat more detailed, in that you should multiply both of these by the \"receptive field size\", which is in this case just the product of the kernel sizes -- which in our case are always going to be the same, i.e., $k\\times k$ kernels.\n",
    "\n",
    "You should assume that if the number of dimensions of `_calculate_fans` is 4, then we are trying to initialize the weights of a convolutional layer. Recall that we are assuming the convolution weights have the shape `(k, k, input_channels, output_channels)`. This function should still work for other cases, i.e., initializing linear layers.\n",
    "\n",
    "You can test this below; though it is not _directly_ graded, it must match ours to pass the nn.Conv mugrade tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"calculate_fans or kaiming_uniform\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing nn.Conv\n",
    "\n",
    "Essentially, nn.Conv is just a wrapper of the convolution operator we previously implemented\n",
    "which adds a bias term, initializes the weight and bias, and ensures that the padding is set so that the input and output dimensions are the same (in the `stride=1` case, anyways). \n",
    "\n",
    "Importantly, nn.Conv should support NCHW format instead of NHWC format. In particular, we think this makes more sense given our previous BatchNorm implementation. You can implement this by applying `transpose` twice to both the input and output.  \n",
    "\n",
    "- Ensure nn.Conv works for (N, C, H, W) tensors even though we implemented the conv op for (N, H, W, C) tensors\n",
    "- Initialize the (k, k, i, o) weight tensor using Kaiming uniform initialization with default settings\n",
    "- Initialize the (o,) bias tensor using uniform initialization on the interval $\\pm$`1.0/(in_channels * kernel_size**2)**0.5`\n",
    "- Calculate the appropriate padding to ensure input and output dimensions are the same\n",
    "- Calculate the convolution, then add the properly-broadcasted bias term if present\n",
    "\n",
    "You can now test your nn.Conv against PyTorch's nn.Conv2d with the two PyTest calls below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"nn_conv_forward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"nn_conv_backward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit nn.Conv to mugrade [20 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m mugrade submit \"Bjo9uucaPqkSTXyqSoEv\" -k \"conv_forward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m mugrade submit \"Bjo9uucaPqkSTXyqSoEv\" -k \"conv_backward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementing \"ResNet9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now use your convolutional layer to implement a model similar to _ResNet9_, which is known to be a reasonable model for getting good accuracy on CIFAR-10 quickly (see [here](https://github.com/davidcpage/cifar10-fast)). Our main change is that we used striding instead of pooling and divided all of the channels by 4 for the sake of performance (as our framework is not as well-optimized as industry-grade frameworks).\n",
    "\n",
    "In the figure below, before the linear layer, you should \"flatten\" the tensor. We have added a module called `Flatten` in `nn.py` that you can complete and use, or you can simply use `.reshape` in the `forward()` method of your ResNet9.\n",
    "\n",
    "Make sure that you pass the device to all modules in your model; otherwise, you will get errors about mismatched devices when trying to run with CUDA.\n",
    "\n",
    "<center><img src=\"https://github.com/dlsys10714/hw4/blob/main/ResNet9.png?raw=true\" alt=\"ResNet9\" style=\"width: 400px;\" /></center>\n",
    "\n",
    "We have tried to make it easier to pass the tests here than for previous assignments where you have implemented models. In particular, we are just going to make sure it has the right number of parameters and similar accuracy and loss after 1 or 2 batches of CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"resnet9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit ResNet9 to mugrade [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m mugrade submit \"Bjo9uucaPqkSTXyqSoEv\" -k \"resnet9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can train your model on CIFAR-10 using the following code. Note that this is likely going to be quite slow, and also  not all that accurate due to the lack of data augmentation. You should expect it to take around 500s per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./python')\n",
    "sys.path.append('./apps')\n",
    "import needle as ndl\n",
    "from models import ResNet9\n",
    "from simple_training import train_cifar10, evaluate_cifar10\n",
    "\n",
    "device = ndl.cpu()\n",
    "dataset = ndl.data.CIFAR10Dataset(\"data/cifar-10-batches-py\", train=True)\n",
    "dataloader = ndl.data.DataLoader(\\\n",
    "         dataset=dataset,\n",
    "         batch_size=128,\n",
    "         shuffle=True,\n",
    "         collate_fn=ndl.data.collate_ndarray,\n",
    "         device=device,\n",
    "         dtype=\"float32\")\n",
    "model = ResNet9(device=device, dtype=\"float32\")\n",
    "train_cifar10(model, dataloader, n_epochs=10, optimizer=ndl.optim.Adam,\n",
    "      lr=0.001, weight_decay=0.001)\n",
    "evaluate_cifar10(model, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Recurrent neural network [10 points]\n",
    "In `python/needle/nn.py`, implement `RNNCell`.\n",
    "\n",
    "$h^\\prime = \\text{tanh}(xW_{ih} + b_{ih} + hW_{hh} + b_{hh})$. If nonlinearity is 'relu', then ReLU is used in place of tanh.\n",
    "\n",
    "All weights and biases should be initialized from $\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})$ where $k=\\frac{1}{\\text{hidden_size}}$.\n",
    "\n",
    "In `python/needle/nn.py`, implement `RNN`.\n",
    "\n",
    "For each element in the input sequence, each layer computes the following function:\n",
    "\n",
    "$h_t = \\text{tanh}(x_tW_{ih} + b_{ih} + h_{(t-1)}W_{hh} + b_{hh})$\n",
    "\n",
    "where $h_t$ is the hidden state at time $t$, $x_t$ is the input at time $t$, and $h_{(t-1)}$ is the hidden state of the previous layer at time $t-1$ or the initial hidden state at time $0$. If nonlinearity is 'relu', then ReLU is used in place of tanh.\n",
    "\n",
    "In a multi-layer RNN, the input $x_t^{(l)}$ of the $l$-th layer ($l \\ge 2$) is the hidden state $h_t^{(l-1)}$ of the previous layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"test_rnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m mugrade submit \"Bjo9uucaPqkSTXyqSoEv\" -k \"rnn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Long short-term memory network [10 points]\n",
    "Implement - `Sigmoid`\n",
    "\n",
    "$\\sigma(x) = \\frac{1}{1 + \\text{exp}(-x)}$\n",
    "\n",
    "In `python/needle/nn.py`, implement `Sigmoid`, `LSTMCell` and `LSTM`.\n",
    "\n",
    "\\begin{align}\n",
    "i &= \\sigma(xW_{ii} + b_{ii} + hW_{hi} + b_{hi}) \\\\\n",
    "f &= \\sigma(xW_{if} + b_{if} + hW_{hf} + b_{hf}) \\\\\n",
    "g &= \\text{tanh}(xW_{ig} + b_{ig} + hW_{hg} + b_{hg}) \\\\\n",
    "o &= \\sigma(xW_{io} + b_{io} + hW_{ho} + b_{ho}) \\\\\n",
    "c^\\prime &= f * c + i * g \\\\\n",
    "h^\\prime &= o * \\text{tanh}(c^\\prime)\n",
    "\\end{align}\n",
    "\n",
    "where $\\sigma$ is the sigmoid function, and $i$, $f$, $g$, $o$ are the input, forget, cell, and output gates, respectively. \n",
    "\n",
    "All weights and biases should be initialized from $\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})$ where $k=\\frac{1}{\\text{hidden_size}}$.\n",
    "\n",
    "Now implement `LSTM` in `python/needle/nn.py`, which applies a multi-layer LSTM RNN to an input sequence. For each element in the input sequence, each layer computes the following function:\n",
    "\n",
    "\\begin{align}\n",
    "i_t &= \\sigma(x_tW_{ii} + b_{ii} + h_{(t-1)}W_{hi} + b_{hi}) \\\\\n",
    "f_t &= \\sigma(x_tW_{if} + b_{if} + h_{(t-1)}W_{hf} + b_{hf}) \\\\\n",
    "g_t &= \\text{tanh}(x_tW_{ig} + b_{ig} + h_{(t-1)}W_{hg} + b_{hg}) \\\\\n",
    "o_t &= \\sigma(x_tW_{io} + b_{io} + h_{(t-1)}W_{ho} + b_{ho}) \\\\\n",
    "c_t &= f * c_{(t-1)} + i * g \\\\\n",
    "h_t &= o * \\text{tanh}(c_t)\n",
    "\\end{align},\n",
    "where $h_t$ is the hidden state at time $t$, $c_t$ is the cell state at time $t$, $x_t$ is the input at time $t$, $h_{(t-1)}$ is the hidden state of the layer at time $t-1$ or the initial hidden state at time $0$, and $i_t$, $f_t$, $g_t$, $o_t$ are the input, forget, cell, and output gates at time $t$ respectively. \n",
    "\n",
    "In a multi-layer LSTM, the input $x_t^{(l)}$ of the $l$-th layer ($l \\ge 2$) is the hidden state $h_t^{(l-1)}$ of the previous layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"test_lstm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.9.7, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "rootdir: /home/dasongg/cmu/10714/hws/needle\n",
      "plugins: anyio-3.3.4\n",
      "collected 47 items / 46 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw4/test_sequence_models.py \n",
      "Submitting lstm...\n",
      "Grader test 1 failed: Failed: incorrect output\n",
      "\u001b[31mF\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_________________________________ submit_lstm __________________________________\u001b[0m\n",
      "\n",
      "=========================== short test summary info ============================\n",
      "FAILED tests/hw4/test_sequence_models.py::submit_lstm\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m46 deselected\u001b[0m\u001b[31m in 2.80s\u001b[0m\u001b[31m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"Bjo9uucaPqkSTXyqSoEv\" -k \"lstm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Penn Treebank dataset [10 points]\n",
    "\n",
    "In word-level language modeling tasks, the model predicts the probability of the next word in the sequence, based on the words already observed in the sequence. You will write support for the Penn Treebank dataset, which consists of stories from the Wall Street Journal, to train and evaluate a language model on word-level prediction.\n",
    "\n",
    "In `python/needle/data.py`, start by implementing the `Dictionary` class, which creates a dictionary from a list of words, mapping each word to a unique integer.\n",
    "\n",
    "Next, we will use this `Dictionary` class to create a corpus from the train and test txt files in the Penn Treebank dataset that you downloaded at the beginning of the notebook. Implement the `tokenize` function in the `Corpus` class to do this.\n",
    "\n",
    "In order to prepare the data for training and evaluation, you will next implement the `batchify` function. Starting from sequential data, batchify arranges the dataset into columns. For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
    "\n",
    "```\n",
    "┌ a g m s ┐\n",
    "│ b h n t │\n",
    "│ c i o u │\n",
    "│ d j p v │\n",
    "│ e k q w │\n",
    "└ f l r x ┘\n",
    "```\n",
    "\n",
    "These columns are treated as independent by the model, which means that the dependence of e. g. 'g' on 'f' cannot be learned, but allows more efficient batch processing.\n",
    "\n",
    "Next, implement the `get_batch` function. `get_batch` subdivides the source data into chunks of length `bptt`. If source is equal to the example output of the batchify function, with a bptt-limit of 2, we'd get the following two Variables for i = 0:\n",
    "```\n",
    "┌ a g m s ┐ ┌ b h n t ┐\n",
    "└ b h n t ┘ └ c i o u ┘\n",
    "```\n",
    "Note that despite the name of the function, the subdivison of data is not done along the batch dimension (i.e. dimension 1), since that was handled by the batchify function. The chunks are along dimension 0, corresponding to the seq_len dimension in the LSTM or RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"ptb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m mugrade submit \"Bjo9uucaPqkSTXyqSoEv\" -k \"ptb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Training a word-level language model [10 points]\n",
    "\n",
    "Finally, you will use the `RNN` and `LSTM` components you have written to construct a language model that we will train on the Penn Treebank dataset.\n",
    "\n",
    "First, in `python/needle/nn.py` implement `Embedding`. Consider we have a dictionary with 1000 words. Then for a word which indexes into this dictionary, we can represent this word as a one-hot vector of size 1000, and then use a linear layer to project this to a vector of some embedding size.\n",
    "\n",
    "In `apps/models.py`, you can now implement `LanguageModel`. Your language model should consist of \n",
    "\n",
    "- An embedding layer (which maps word IDs to embeddings) \n",
    "- A sequence model (either RNN or LSTM)\n",
    "- A linear layer (which outputs probabilities of the next word)\n",
    "\n",
    "In `apps/simple_training.py` implement `epoch_general_ptb`, `train_ptb`, and `evaluate_ptb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.9.7, pytest-6.2.4, py-1.10.0, pluggy-0.13.1 -- /home/dasongg/miniconda3/envs/py39/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/dasongg/cmu/10714/hws/needle\n",
      "plugins: anyio-3.3.4\n",
      "collected 2076 items / 1564 deselected / 512 selected                          \u001b[0m\n",
      "\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[33m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[33m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[33m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[33m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[33m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[33m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[33m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[33m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[33m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[33m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[33m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[33m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[33m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[33m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[33m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[33m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[33m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[33m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[33m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[33m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[33m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[33m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[33m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[33m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[33m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[33m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[33m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[33m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[33m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[33m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[33m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[33m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-False-1-1-1-1-1] _________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.29326868]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[1.8435568]]])\n",
      "h0_        = needle.Tensor([[[-0.57503206]]])\n",
      "h_         = needle.Tensor([[[-0.57503206]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dcb7f40>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[1.2129914]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.7976699]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-False-1-1-1-2-1] _________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[2.011662  ]]\n",
      "\n",
      " [[0.21351224]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.32914704]]\n",
      "\n",
      " [[-0.37666294]]])\n",
      "h0_        = needle.Tensor([[[-0.8479297 ]]\n",
      "\n",
      " [[ 0.92537916]]])\n",
      "h_         = needle.Tensor([[[-0.8479297 ]]\n",
      "\n",
      " [[ 0.92537916]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dc46f70>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.9903114]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[0.67893684]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-False-1-1-15-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.60785055]\n",
      "  [ 0.4511845 ]\n",
      "  [-0.97593117]\n",
      "  [-1.8689873 ]\n",
      "  [ 1.342022  ]\n",
      "  [ 0.585721  ]\n",
      "  [ 0.37...98 ]\n",
      "  [-1.3603503 ]\n",
      "  [ 0.14108145]\n",
      "  [ 0.5118302 ]\n",
      "  [-1.8149506 ]\n",
      "  [-0.71307695]\n",
      "  [-0.49691463]\n",
      "  [-0.95406806]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.21272802]\n",
      "  [-0.80755705]\n",
      "  [ 0.11627617]\n",
      "  [ 0.9347071 ]\n",
      "  [ 1.479132  ]\n",
      "  [ 0.21338783]\n",
      "  [-0.80...71 ]\n",
      "  [ 0.22583066]\n",
      "  [ 0.46729454]\n",
      "  [-0.722992  ]\n",
      "  [ 0.16665661]\n",
      "  [-1.5947223 ]\n",
      "  [ 0.34318048]\n",
      "  [-0.83817875]]])\n",
      "h0_        = needle.Tensor([[[0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]]])\n",
      "h_         = needle.Tensor([[[0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]\n",
      "  [0.6023827]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dc59e20>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.06938147]\n",
      " [-0.06938147]\n",
      " [-0.06938147]\n",
      " [-0.06938147]\n",
      " [-0.06938147]\n",
      " [-0.06938147]\n",
      " [-0.06938147]\n",
      " [-0.06938147]\n",
      " [-0.06938147]\n",
      " [-0.06938147]\n",
      " [-0.06938147]\n",
      " [-0.06938147]\n",
      " [-0.06938147]\n",
      " [-0.06938147]\n",
      " [-0.06938147]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.48820993]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-False-1-1-15-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.7939899 ]\n",
      "  [-0.5363315 ]\n",
      "  [-0.16898292]\n",
      "  [ 0.8013502 ]\n",
      "  [-0.30072564]\n",
      "  [-1.2213368 ]\n",
      "  [ 1.49...543]\n",
      "  [-1.1095958 ]\n",
      "  [ 1.0733852 ]\n",
      "  [-0.21358252]\n",
      "  [-0.7475623 ]\n",
      "  [-0.5491173 ]\n",
      "  [-0.6099147 ]\n",
      "  [ 1.1913463 ]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.4542767 ]\n",
      "  [-0.48077098]\n",
      "  [ 0.7974489 ]\n",
      "  [-0.20771177]\n",
      "  [-0.67950255]\n",
      "  [-0.2766371 ]\n",
      "  [-1.12...88 ]\n",
      "  [ 0.95543426]\n",
      "  [-1.2673277 ]\n",
      "  [ 0.86427015]\n",
      "  [-0.11090299]\n",
      "  [ 2.4484205 ]\n",
      "  [-0.24429938]\n",
      "  [ 0.32443774]]])\n",
      "h0_        = needle.Tensor([[[0.1941151]\n",
      "  [0.1941151]\n",
      "  [0.1941151]\n",
      "  [0.1941151]\n",
      "  [0.1941151]\n",
      "  [0.1941151]\n",
      "  [0.1941151]\n",
      "  [0.1...18 ]\n",
      "  [0.946618 ]\n",
      "  [0.946618 ]\n",
      "  [0.946618 ]\n",
      "  [0.946618 ]\n",
      "  [0.946618 ]\n",
      "  [0.946618 ]\n",
      "  [0.946618 ]\n",
      "  [0.946618 ]]])\n",
      "h_         = needle.Tensor([[[0.1941151]\n",
      "  [0.1941151]\n",
      "  [0.1941151]\n",
      "  [0.1941151]\n",
      "  [0.1941151]\n",
      "  [0.1941151]\n",
      "  [0.1941151]\n",
      "  [0.1...18 ]\n",
      "  [0.946618 ]\n",
      "  [0.946618 ]\n",
      "  [0.946618 ]\n",
      "  [0.946618 ]\n",
      "  [0.946618 ]\n",
      "  [0.946618 ]\n",
      "  [0.946618 ]\n",
      "  [0.946618 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122df1a7f0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.3410331]\n",
      " [-0.3410331]\n",
      " [-0.3410331]\n",
      " [-0.3410331]\n",
      " [-0.3410331]\n",
      " [-0.3410331]\n",
      " [-0.3410331]\n",
      " [-0.3410331]\n",
      " [-0.3410331]\n",
      " [-0.3410331]\n",
      " [-0.3410331]\n",
      " [-0.3410331]\n",
      " [-0.3410331]\n",
      " [-0.3410331]\n",
      " [-0.3410331]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[0.827971]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-False-1-34-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-2.0213668]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.8446338]]])\n",
      "h0_        = needle.Tensor([[[0.61648]]])\n",
      "h_         = needle.Tensor([[[0.61648]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122de88a00>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.9113076]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.3416322]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-False-1-34-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.48749626]]\n",
      "\n",
      " [[-0.87193197]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.4595433]]\n",
      "\n",
      " [[-2.357904 ]]])\n",
      "h0_        = needle.Tensor([[[-0.99998873]]\n",
      "\n",
      " [[-0.7696066 ]]])\n",
      "h_         = needle.Tensor([[[-0.99998873]]\n",
      "\n",
      " [[-0.7696066 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dd221c0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.3578583]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.35096633]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-1-34-15-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.07465287]\n",
      "  [ 0.22268836]\n",
      "  [ 0.25419262]\n",
      "  [ 0.6208449 ]\n",
      "  [-0.09867439]\n",
      "  [ 1.4819582 ]\n",
      "  [ 1.98...06 ]\n",
      "  [-0.77168196]\n",
      "  [ 0.15926486]\n",
      "  [ 2.309229  ]\n",
      "  [ 1.618838  ]\n",
      "  [-1.0604281 ]\n",
      "  [-0.3939162 ]\n",
      "  [ 0.4815651 ]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.258971  ]\n",
      "  [-0.7913809 ]\n",
      "  [ 0.17673828]\n",
      "  [-0.14134441]\n",
      "  [ 0.6309423 ]\n",
      "  [-0.20266406]\n",
      "  [ 0.09...11 ]\n",
      "  [ 1.1250296 ]\n",
      "  [ 0.59369993]\n",
      "  [-0.2354685 ]\n",
      "  [ 0.7025785 ]\n",
      "  [ 1.4526716 ]\n",
      "  [ 1.6821234 ]\n",
      "  [ 1.2820784 ]]])\n",
      "h0_        = needle.Tensor([[[0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]]])\n",
      "h_         = needle.Tensor([[[0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]\n",
      "  [0.7262375]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dd135b0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-1.1071557]\n",
      " [-1.1071557]\n",
      " [-1.1071557]\n",
      " [-1.1071557]\n",
      " [-1.1071557]\n",
      " [-1.1071557]\n",
      " [-1.1071557]\n",
      " [-1.1071557]\n",
      " [-1.1071557]\n",
      " [-1.1071557]\n",
      " [-1.1071557]\n",
      " [-1.1071557]\n",
      " [-1.1071557]\n",
      " [-1.1071557]\n",
      " [-1.1071557]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[0.01739693]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-1-34-15-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.545008  ]\n",
      "  [ 1.3446836 ]\n",
      "  [-1.5305166 ]\n",
      "  [ 0.4810853 ]\n",
      "  [ 0.35459965]\n",
      "  [-0.06745001]\n",
      "  [ 0.59...06 ]\n",
      "  [ 0.51931566]\n",
      "  [ 1.6073314 ]\n",
      "  [-0.6639446 ]\n",
      "  [ 0.40815282]\n",
      "  [ 1.9080818 ]\n",
      "  [ 0.8043227 ]\n",
      "  [-0.04559912]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.47489864]\n",
      "  [-0.5199686 ]\n",
      "  [ 0.6234055 ]\n",
      "  [ 0.53903174]\n",
      "  [-1.8763995 ]\n",
      "  [-1.5623101 ]\n",
      "  [-0.84...37 ]\n",
      "  [-0.36085582]\n",
      "  [-0.02383626]\n",
      "  [ 0.3467086 ]\n",
      "  [ 0.47565493]\n",
      "  [-0.17563362]\n",
      "  [-1.3542323 ]\n",
      "  [-0.25900182]]])\n",
      "h0_        = needle.Tensor([[[0.4409982 ]\n",
      "  [0.4409982 ]\n",
      "  [0.4409982 ]\n",
      "  [0.4409982 ]\n",
      "  [0.4409982 ]\n",
      "  [0.4409982 ]\n",
      "  [0.4409982 ]...0.49264324]\n",
      "  [0.49264324]\n",
      "  [0.49264324]\n",
      "  [0.49264324]\n",
      "  [0.49264324]\n",
      "  [0.49264324]\n",
      "  [0.49264324]\n",
      "  [0.49264324]]])\n",
      "h_         = needle.Tensor([[[0.4409982 ]\n",
      "  [0.4409982 ]\n",
      "  [0.4409982 ]\n",
      "  [0.4409982 ]\n",
      "  [0.4409982 ]\n",
      "  [0.4409982 ]\n",
      "  [0.4409982 ]...0.49264324]\n",
      "  [0.49264324]\n",
      "  [0.49264324]\n",
      "  [0.49264324]\n",
      "  [0.49264324]\n",
      "  [0.49264324]\n",
      "  [0.49264324]\n",
      "  [0.49264324]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122ddba160>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.45435008]\n",
      " [0.45435008]\n",
      " [0.45435008]\n",
      " [0.45435008]\n",
      " [0.45435008]\n",
      " [0.45435008]\n",
      " [0.45435008]\n",
      " [0.45435008]\n",
      " [0.45435008]\n",
      " [0.45435008]\n",
      " [0.45435008]\n",
      " [0.45435008]\n",
      " [0.45435008]\n",
      " [0.45435008]\n",
      " [0.45435008]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[0.24519388]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-False-12-1-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.12605032 -0.13269715 -0.76885307  0.083296    0.36812493\n",
      "    0.28995702 -0.18125138 -0.99405247 -0.8505054   1.0663385\n",
      "    1.7213228   1.0610417 ]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.5333065  -1.9391088  -0.2152045  -0.7724891   0.1220569\n",
      "    1.625147    0.69845265  0.10984859  0.48275787 -0.30437955\n",
      "    1.369583    0.51342344]]])\n",
      "h0_        = needle.Tensor([[[-0.14204712  0.05475304  0.48575383  0.05054758  0.05154817\n",
      "    0.04102113  0.07169812  0.23381534  0.17764434  0.12863821\n",
      "    0.3484414  -0.2898525 ]]])\n",
      "h_         = needle.Tensor([[[-0.14204712  0.05475304  0.48575383  0.05054758  0.05154817\n",
      "    0.04102113  0.07169812  0.23381534  0.17764434  0.12863821\n",
      "    0.3484414  -0.2898525 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dd72820>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.1992476]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-1.13203846e-01 -1.65554836e-01  1.08965896e-01  2.06374660e-01\n",
      "   3.17224897e-02  6.21244423e-02 -4.9...02  1.69572580e-04  2.08046824e-01 -1.34853616e-01\n",
      "   1.47435576e-01  2.42943555e-01  1.50452226e-01 -4.11742814e-02]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-rnn-1-False-12-1-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.97345227  2.3305774  -0.09431556  1.851087    0.69466305\n",
      "    1.5065721   0.00635245 -1.9287176   0...  -0.28160107 -0.08467472\n",
      "    0.78093994 -0.33953843 -1.761657    1.0965189  -0.65702224\n",
      "    0.4175345   0.18872565]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.6420829  -0.8834359   1.2027198   2.0913873   1.5133804\n",
      "    0.03377071  1.1878778  -0.9458593  -0....38  0.50282604 -0.64800954\n",
      "    0.3725924  -1.0591358   0.65909743 -0.41003606  0.9224776\n",
      "    0.23693687 -1.4631332 ]]])\n",
      "h0_        = needle.Tensor([[[ 0.1488772   0.12289143 -0.13264748 -0.2599698   0.25570276\n",
      "    0.01255101  0.3218415   0.31147856 -0...8 -0.03697181 -0.36779988\n",
      "    0.31718904 -0.36060685 -0.1397324   0.1903992   0.05775223\n",
      "    0.2392939  -0.16165978]]])\n",
      "h_         = needle.Tensor([[[ 0.1488772   0.12289143 -0.13264748 -0.2599698   0.25570276\n",
      "    0.01255101  0.3218415   0.31147856 -0...8 -0.03697181 -0.36779988\n",
      "    0.31718904 -0.36060685 -0.1397324   0.1903992   0.05775223\n",
      "    0.2392939  -0.16165978]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dd6ed60>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.03120439]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.0913582  -0.07960904 -0.07724633 -0.07487347  0.17979026 -0.16435891\n",
      "   0.12462241  0.27732205  0.1...52943  -0.16985214  0.2850854  -0.07792855\n",
      "   0.27265263  0.1319557   0.06892237 -0.14090373 -0.04410649 -0.12566738]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-12-1-15-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.59843475e-01  1.40137419e-01 -1.73447895e+00 -1.17608297e+00\n",
      "    1.00907052e+00 -1.16757855e-01  1...  1.23830736e+00  3.29426497e-01 -1.84775305e+00\n",
      "   -2.25365329e+00 -2.91062921e-01  1.02817583e+00  6.81809366e-01]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-4.06321257e-01 -1.00135469e+00  8.47881556e-01  1.76873744e+00\n",
      "   -1.84115672e+00 -4.86494273e-01 -4... -6.62250593e-02  2.16544390e+00 -1.58664688e-01\n",
      "   -2.81731665e-01  1.94115266e-01  5.29696167e-01 -2.89709091e-01]]])\n",
      "h0_        = needle.Tensor([[[ 0.03395656 -0.13477118  0.38425362  0.58476377 -0.46930405\n",
      "   -0.04729037  0.47418773 -0.46252486  0...2  0.58476377 -0.46930405\n",
      "   -0.04729037  0.47418773 -0.46252486  0.08911858 -0.05867707\n",
      "   -0.4765329  -0.10418941]]])\n",
      "h_         = needle.Tensor([[[ 0.03395656 -0.13477118  0.38425362  0.58476377 -0.46930405\n",
      "   -0.04729037  0.47418773 -0.46252486  0...2  0.58476377 -0.46930405\n",
      "   -0.04729037  0.47418773 -0.46252486  0.08911858 -0.05867707\n",
      "   -0.4765329  -0.10418941]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122de43130>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.02036022]\n",
      " [-0.02036022]\n",
      " [-0.02036022]\n",
      " [-0.02036022]\n",
      " [-0.02036022]\n",
      " [-0.02036022]\n",
      " [-0.02036022]\n",
      " [-0.02036022]\n",
      " [-0.02036022]\n",
      " [-0.02036022]\n",
      " [-0.02036022]\n",
      " [-0.02036022]\n",
      " [-0.02036022]\n",
      " [-0.02036022]\n",
      " [-0.02036022]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.01161062 -0.28124225 -0.01237847  0.17988086 -0.05027391  0.27144963\n",
      "   0.26533237  0.01425355 -0.2...68427   0.28113407 -0.02496174 -0.21567823\n",
      "   0.06922796  0.09212462 -0.2762717   0.1109058  -0.25331563 -0.13513866]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-12-1-15-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.46326154 -0.2996289  -0.87214917 -1.6366677   0.04517483\n",
      "   -1.1022269   1.7741677   0.04304155  0...63  0.8634449   0.26814732\n",
      "    0.14979778  0.77342397 -0.03980758  0.3694183   0.5448974\n",
      "    0.5319985   0.9587112 ]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.5095151  -0.2774539   0.28021005  0.4933908   0.14281304\n",
      "    0.31460834  0.24546027  1.4930043   1...766  1.4297795   0.4334529\n",
      "    1.4624423   1.1976429  -0.27909422 -0.34119853 -0.3932992\n",
      "    1.0634696   0.6244272 ]]])\n",
      "h0_        = needle.Tensor([[[ 0.22510317  0.10231102  0.20646842 -0.27009138  0.0311435\n",
      "   -0.17047285  0.21067433 -0.22337037 -0....4 -0.02748699 -0.07072543\n",
      "   -0.5139271  -0.34860545 -0.25537762 -0.41508448 -0.00673928\n",
      "   -0.25653648 -0.13676843]]])\n",
      "h_         = needle.Tensor([[[ 0.22510317  0.10231102  0.20646842 -0.27009138  0.0311435\n",
      "   -0.17047285  0.21067433 -0.22337037 -0....4 -0.02748699 -0.07072543\n",
      "   -0.5139271  -0.34860545 -0.25537762 -0.41508448 -0.00673928\n",
      "   -0.25653648 -0.13676843]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dfced90>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.17577684]\n",
      " [-0.17577684]\n",
      " [-0.17577684]\n",
      " [-0.17577684]\n",
      " [-0.17577684]\n",
      " [-0.17577684]\n",
      " [-0.17577684]\n",
      " [-0.17577684]\n",
      " [-0.17577684]\n",
      " [-0.17577684]\n",
      " [-0.17577684]\n",
      " [-0.17577684]\n",
      " [-0.17577684]\n",
      " [-0.17577684]\n",
      " [-0.17577684]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.24062932 -0.12149551  0.08561124  0.0439815   0.09330168  0.17934369\n",
      "  -0.08450946 -0.25738257 -0.0...790632  0.03702738 -0.08190806 -0.25485373\n",
      "   0.22650586  0.08482013 -0.17782205  0.2550944   0.2731918   0.26370203]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-12-34-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.36822075 -0.4322152   0.13600148 -0.725808   -1.3294495\n",
      "    1.955654   -1.368658   -0.82660353 -0.8373753  -0.22317319\n",
      "   -0.7085582   0.14642748]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.532621    0.2845657   0.0521526   0.76468265  0.25995588\n",
      "    1.7189246   0.3261896   0.29435763 -1.2502978   1.4925264\n",
      "   -0.23538704 -0.42009592]]])\n",
      "h0_        = needle.Tensor([[[ 0.75014585  0.65941215 -0.9732062  -0.9379785  -0.61266136\n",
      "   -0.46495953 -0.8455894   0.27804297  0.4583749   0.05585307\n",
      "    0.5497931   0.9541871 ]]])\n",
      "h_         = needle.Tensor([[[ 0.75014585  0.65941215 -0.9732062  -0.9379785  -0.61266136\n",
      "   -0.46495953 -0.8455894   0.27804297  0.4583749   0.05585307\n",
      "    0.5497931   0.9541871 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122de113a0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[0.72281504]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.2803992   0.28543437  0.1172392   0.15814945 -0.09285349  0.2200445\n",
      "   0.2854017   0.06660591 -0.22...356928  0.12967493  0.06612827 -0.10527766\n",
      "  -0.18418366  0.24599208 -0.15021686 -0.18220608  0.12494279 -0.25606278]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-12-34-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.9077929   0.11084462  1.1322373  -2.9511      0.22152859\n",
      "   -0.37391073 -1.2950789   1.4937488  -1...6  1.3134141   0.15361173\n",
      "   -0.5581525  -0.47842047  0.83005846 -0.4470545   0.05231119\n",
      "    0.9818027   0.34372157]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.8965073   2.987673   -0.34675282 -0.120948    0.76604474\n",
      "    0.54585207  0.51901376 -1.8881577   0...757   0.6629841   2.303969\n",
      "   -1.318434   -1.7326429  -0.73641     0.49067846  1.1077886\n",
      "   -0.10164313 -0.35102272]]])\n",
      "h0_        = needle.Tensor([[[-0.63765556 -0.7789131  -0.7246401   0.25062028 -0.4684309\n",
      "   -0.51010305 -0.4242477   0.93657386  0....  -0.23993725  0.04972903\n",
      "   -0.19437705 -0.0546322   0.05592783  0.48445535 -0.23045528\n",
      "    0.60434896 -0.2552509 ]]])\n",
      "h_         = needle.Tensor([[[-0.63765556 -0.7789131  -0.7246401   0.25062028 -0.4684309\n",
      "   -0.51010305 -0.4242477   0.93657386  0....  -0.23993725  0.04972903\n",
      "   -0.19437705 -0.0546322   0.05592783  0.48445535 -0.23045528\n",
      "    0.60434896 -0.2552509 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dfdd160>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.3998774]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.1824025  -0.06373816  0.1996378  -0.07406111 -0.28826937  0.11889145\n",
      "   0.08832554  0.25283018 -0.1...76925   0.01716956  0.12656532 -0.20856546\n",
      "   0.11962641  0.21170531  0.03485699 -0.07372369  0.23504904  0.1816166 ]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-12-34-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.02217078 -1.9369348   0.47846255  1.8494425   1.0462418\n",
      "   -1.092913   -0.28254342  0.2350068  -0....8   0.52427787 -0.7129484\n",
      "    0.637924   -0.34748858 -1.3564931  -1.1717035  -0.41038984\n",
      "    0.2915498  -1.0048225 ]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.4186224   0.46758848 -1.3634768   1.7923911  -0.41884902\n",
      "    1.1855688  -0.46275353  0.6416566   0...73  0.9680057   1.0552963\n",
      "   -0.40902886 -0.42025712  1.2464242   1.4776366  -0.90033054\n",
      "   -0.03990179  1.2594926 ]]])\n",
      "h0_        = needle.Tensor([[[ 0.85445607 -0.3476023   0.73973185  0.83344823  0.70868045\n",
      "   -0.05185916 -0.842114   -0.5676784  -0...85  0.83344823  0.70868045\n",
      "   -0.05185916 -0.842114   -0.5676784  -0.77902293 -0.6524961\n",
      "    0.18309753 -0.7736685 ]]])\n",
      "h_         = needle.Tensor([[[ 0.85445607 -0.3476023   0.73973185  0.83344823  0.70868045\n",
      "   -0.05185916 -0.842114   -0.5676784  -0...85  0.83344823  0.70868045\n",
      "   -0.05185916 -0.842114   -0.5676784  -0.77902293 -0.6524961\n",
      "    0.18309753 -0.7736685 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122df159a0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.32489082]\n",
      " [-0.32489082]\n",
      " [-0.32489082]\n",
      " [-0.32489082]\n",
      " [-0.32489082]\n",
      " [-0.32489082]\n",
      " [-0.32489082]\n",
      " [-0.32489082]\n",
      " [-0.32489082]\n",
      " [-0.32489082]\n",
      " [-0.32489082]\n",
      " [-0.32489082]\n",
      " [-0.32489082]\n",
      " [-0.32489082]\n",
      " [-0.32489082]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.19255894  0.17069763 -0.19517615 -0.251682   -0.28806195 -0.24944784\n",
      "  -0.12383085  0.04767568  0.2...040486 -0.18446696 -0.13968147  0.04419103\n",
      "   0.22563891  0.2610963   0.11108743  0.03614728  0.19780204  0.10851426]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1-False-12-34-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.28196490e+00 -2.47670054e-01 -3.81524563e-01 -9.57439482e-01\n",
      "   -1.61227584e-01 -2.09346986e+00  1... -9.69735801e-01 -2.68890977e-01 -2.50614494e-01\n",
      "    1.18145478e+00  4.72588480e-01  8.21963370e-01  1.23833799e+00]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.04377437e+00 -5.22213042e-01  2.27970052e+00  5.54164648e-01\n",
      "    1.30622125e+00 -2.74444044e-01  1...  8.08057785e-01 -2.18626469e-01 -4.22418416e-01\n",
      "   -2.11805272e+00  2.77987599e-01  2.53531992e-01 -1.34545195e+00]]])\n",
      "h0_        = needle.Tensor([[[-0.9174898   0.8555725   0.9461949   0.4480195  -0.7519298\n",
      "    0.12514153 -0.7109976  -0.02829203 -0....95 -0.15205584 -0.3321865\n",
      "    0.0997605  -0.33492514 -0.5184915  -0.411762    0.41158175\n",
      "   -0.3257623  -0.0680244 ]]])\n",
      "h_         = needle.Tensor([[[-0.9174898   0.8555725   0.9461949   0.4480195  -0.7519298\n",
      "    0.12514153 -0.7109976  -0.02829203 -0....95 -0.15205584 -0.3321865\n",
      "    0.0997605  -0.33492514 -0.5184915  -0.411762    0.41158175\n",
      "   -0.3257623  -0.0680244 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dd31250>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.023456]\n",
      " [0.023456]\n",
      " [0.023456]\n",
      " [0.023456]\n",
      " [0.023456]\n",
      " [0.023456]\n",
      " [0.023456]\n",
      " [0.023456]\n",
      " [0.023456]\n",
      " [0.023456]\n",
      " [0.023456]\n",
      " [0.023456]\n",
      " [0.023456]\n",
      " [0.023456]\n",
      " [0.023456]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.18342912 -0.04313763  0.173931    0.13797955 -0.1990109   0.2510043\n",
      "  -0.18362017 -0.03663669  0.21...4298643 -0.22261159  0.14884903 -0.2311455\n",
      "  -0.02080098  0.10203142  0.25722805  0.19412436 -0.13967991  0.07124995]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1000-False-1-1-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.5885466]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.59116614]]])\n",
      "h0_        = needle.Tensor([[[-0.9111411]]])\n",
      "h_         = needle.Tensor([[[-0.9111411]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122da0ee20>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-7.14600384e-01 -4.56040502e-01 -6.44893050e-02 -2.54263699e-01\n",
      "  -6.47646487e-02 -2.27494448e-01  9.0...00 -1.09316492e+00 -5.66050768e-01 -2.19952047e-01\n",
      "  -9.95242596e-02 -1.05467045e+00 -2.58527249e-02 -3.44106972e-01]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.67942655]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[825.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-rnn-1000-False-1-1-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.02927703]]\n",
      "\n",
      " [[-1.2085629 ]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.6091201]]\n",
      "\n",
      " [[ 1.9567541]]])\n",
      "h0_        = needle.Tensor([[[ 0.43633145]]\n",
      "\n",
      " [[-0.3002754 ]]])\n",
      "h_         = needle.Tensor([[[ 0.43633145]]\n",
      "\n",
      " [[-0.3002754 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122da0adc0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.23239884 -0.14019056  0.36806095  0.35975337 -0.8659517   0.35665956\n",
      "  -0.25380382  0.7169068  -0.9...150613  -0.69423795 -0.7806363   0.79010296 -0.90085316 -0.7450235\n",
      "  -0.90929997  0.74500036  0.21445644  0.74901295]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[0.05760355]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[894.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-1-1-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.31731117]\n",
      "  [-0.70671004]\n",
      "  [-0.15041098]\n",
      "  [-0.4838613 ]\n",
      "  [ 1.8663257 ]\n",
      "  [ 1.2776271 ]\n",
      "  [-0.66...567]\n",
      "  [ 0.7369942 ]\n",
      "  [ 0.01955737]\n",
      "  [-0.59469426]\n",
      "  [ 0.35976428]\n",
      "  [ 0.57096416]\n",
      "  [ 1.6333071 ]\n",
      "  [ 1.3117055 ]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 2.265099  ]\n",
      "  [-0.4351803 ]\n",
      "  [ 0.18558781]\n",
      "  [-1.4842352 ]\n",
      "  [ 0.5789472 ]\n",
      "  [ 1.5689392 ]\n",
      "  [ 1.03...68 ]\n",
      "  [ 0.02622696]\n",
      "  [ 0.7728013 ]\n",
      "  [ 2.7187753 ]\n",
      "  [ 0.00674832]\n",
      "  [-0.19338122]\n",
      "  [-1.4112735 ]\n",
      "  [ 0.6964277 ]]])\n",
      "h0_        = needle.Tensor([[[-0.25295398]\n",
      "  [ 0.24689388]\n",
      "  [ 0.4023076 ]\n",
      "  [-0.35097036]\n",
      "  [-0.24503927]\n",
      "  [-0.5188815 ]\n",
      "  [ 0.63...423]\n",
      "  [-0.01788533]\n",
      "  [-0.48459643]\n",
      "  [-0.44849494]\n",
      "  [-0.23496093]\n",
      "  [ 0.2895054 ]\n",
      "  [ 0.57012326]\n",
      "  [-0.23496093]]])\n",
      "h_         = needle.Tensor([[[-0.25295398]\n",
      "  [ 0.24689388]\n",
      "  [ 0.4023076 ]\n",
      "  [-0.35097036]\n",
      "  [-0.24503927]\n",
      "  [-0.5188815 ]\n",
      "  [ 0.63...423]\n",
      "  [-0.01788533]\n",
      "  [-0.48459643]\n",
      "  [-0.44849494]\n",
      "  [-0.23496093]\n",
      "  [ 0.2895054 ]\n",
      "  [ 0.57012326]\n",
      "  [-0.23496093]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dd31820>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[ 0.23222312 -0.5738182   0.3971668  ... -0.8518859   0.3734849\n",
      "   1.1231369 ]\n",
      " [ 0.64339674 -1.0322471....0507113   0.82362103\n",
      "   0.46632326]\n",
      " [ 0.24702416 -0.59032035  0.3840893  ... -0.85623235  0.38332522\n",
      "   1.1087785 ]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.08932714]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[318., 320., 175., 342., 837., 199., 186., 463., 109., 903., 658.,\n",
      "        678., 877.,  93., 678.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-1-1-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.191161  ]\n",
      "  [-0.79283345]\n",
      "  [ 1.388464  ]\n",
      "  [-0.50075525]\n",
      "  [-1.0897357 ]\n",
      "  [ 0.6964079 ]\n",
      "  [ 0.03...04 ]\n",
      "  [-1.6367608 ]\n",
      "  [ 0.57228947]\n",
      "  [ 0.4663207 ]\n",
      "  [-0.47175193]\n",
      "  [ 0.18616864]\n",
      "  [-1.9710004 ]\n",
      "  [ 0.926268  ]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.3605945 ]\n",
      "  [-0.7663221 ]\n",
      "  [-0.05949903]\n",
      "  [ 0.5414774 ]\n",
      "  [ 1.2860581 ]\n",
      "  [ 0.41364518]\n",
      "  [-0.05...32 ]\n",
      "  [ 0.26566797]\n",
      "  [-0.39224958]\n",
      "  [ 0.7263736 ]\n",
      "  [ 0.17271397]\n",
      "  [ 0.5263178 ]\n",
      "  [-0.25075835]\n",
      "  [ 0.341768  ]]])\n",
      "h0_        = needle.Tensor([[[ 0.55548364]\n",
      "  [ 0.44698128]\n",
      "  [ 0.44311213]\n",
      "  [ 0.3162732 ]\n",
      "  [ 0.3964507 ]\n",
      "  [ 0.5667611 ]\n",
      "  [ 0.58...48 ]\n",
      "  [-0.08007749]\n",
      "  [-0.07090706]\n",
      "  [-0.08785968]\n",
      "  [-0.08368956]\n",
      "  [-0.07406399]\n",
      "  [-0.11262662]\n",
      "  [-0.05696757]]])\n",
      "h_         = needle.Tensor([[[ 0.55548364]\n",
      "  [ 0.44698128]\n",
      "  [ 0.44311213]\n",
      "  [ 0.3162732 ]\n",
      "  [ 0.3964507 ]\n",
      "  [ 0.5667611 ]\n",
      "  [ 0.58...48 ]\n",
      "  [-0.08007749]\n",
      "  [-0.07090706]\n",
      "  [-0.08785968]\n",
      "  [-0.08368956]\n",
      "  [-0.07406399]\n",
      "  [-0.11262662]\n",
      "  [-0.05696757]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dca51f0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.67461455 -0.7733948   0.07199764 ...  0.43549386  0.17955254\n",
      "   0.13448395]\n",
      " [-0.66874576 -0.763808....47653413  0.15322933\n",
      "   0.13715364]\n",
      " [-0.6795868  -0.7815171   0.07769348 ...  0.42666438  0.18521577\n",
      "   0.13390958]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.8201884]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[450., 251., 312., 431., 924., 290., 832., 114., 847., 987., 860.,\n",
      "        986., 823., 765., 843.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-1-34-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.96912]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.07925984]]])\n",
      "h0_        = needle.Tensor([[[0.36259863]]])\n",
      "h_         = needle.Tensor([[[0.36259863]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122de7b6d0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[ 0.47635788 -0.535648    0.26651233 -0.3598664  -0.5925706   0.6133077\n",
      "   0.54949796  0.49412757  0.08...264097   0.61712825 -0.24133113  0.50522435 -0.13126701  0.7412445\n",
      "   0.05065006  0.2511128  -0.28325582 -0.21842821]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[0.68755215]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[584.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-1-34-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.5118083]]\n",
      "\n",
      " [[1.2717899]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.1663182]]\n",
      "\n",
      " [[-1.0497377]]])\n",
      "h0_        = needle.Tensor([[[-0.99222517]]\n",
      "\n",
      " [[ 0.07719008]]])\n",
      "h_         = needle.Tensor([[[-0.99222517]]\n",
      "\n",
      " [[ 0.07719008]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dd95be0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[ 0.43460885  0.752588   -0.35077035  0.01678654  0.54222655  0.90986454\n",
      "   0.43171257  0.08956762 -0.0...38896233 -0.2335713   0.58151686 -0.57877564  0.75253755 -0.422038\n",
      "  -0.01336411  0.57107586 -0.13524963 -0.8485847 ]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[0.52805114]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[339.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-1-34-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.7802572 ]\n",
      "  [ 1.4892373 ]\n",
      "  [-0.38189054]\n",
      "  [-0.98291564]\n",
      "  [-1.4604722 ]\n",
      "  [-0.4289063 ]\n",
      "  [ 1.65...44 ]\n",
      "  [-1.0107304 ]\n",
      "  [-0.35229763]\n",
      "  [ 0.10975828]\n",
      "  [-2.4690814 ]\n",
      "  [ 0.96562177]\n",
      "  [-0.40624884]\n",
      "  [ 1.1139092 ]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.03230542]\n",
      "  [ 0.9047343 ]\n",
      "  [ 1.0523841 ]\n",
      "  [ 1.1581618 ]\n",
      "  [-0.32730085]\n",
      "  [ 0.43059623]\n",
      "  [ 0.14...93 ]\n",
      "  [ 0.8703259 ]\n",
      "  [-0.19380064]\n",
      "  [-1.1275209 ]\n",
      "  [ 0.21406119]\n",
      "  [ 0.19883013]\n",
      "  [-0.16592897]\n",
      "  [-0.2236249 ]]])\n",
      "h0_        = needle.Tensor([[[-0.18512356]\n",
      "  [ 0.9257073 ]\n",
      "  [-0.9610331 ]\n",
      "  [ 0.99991775]\n",
      "  [ 0.83189297]\n",
      "  [-0.18512356]\n",
      "  [ 0.99...48 ]\n",
      "  [ 0.99992007]\n",
      "  [-0.7581511 ]\n",
      "  [-0.99996346]\n",
      "  [ 0.9620917 ]\n",
      "  [-0.53236794]\n",
      "  [-0.9999207 ]\n",
      "  [ 0.9999452 ]]])\n",
      "h_         = needle.Tensor([[[-0.18512356]\n",
      "  [ 0.9257073 ]\n",
      "  [-0.9610331 ]\n",
      "  [ 0.99991775]\n",
      "  [ 0.83189297]\n",
      "  [-0.18512356]\n",
      "  [ 0.99...48 ]\n",
      "  [ 0.99992007]\n",
      "  [-0.7581511 ]\n",
      "  [-0.99996346]\n",
      "  [ 0.9620917 ]\n",
      "  [-0.53236794]\n",
      "  [-0.9999207 ]\n",
      "  [ 0.9999452 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122de415e0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.05053794  0.10699496  0.82250196 ... -0.6443037   0.20428263\n",
      "  -1.0921661 ]\n",
      " [-1.1216199   0.318124...1.2860423   0.6352256\n",
      "  -1.5453404 ]\n",
      " [-1.1932013   0.33223477  0.1612882  ...  0.28906286 -0.42249548\n",
      "  -0.4330539 ]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[0.36999688]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[404., 794., 117., 526., 569., 404., 373., 478., 870., 903., 690.,\n",
      "        222., 784., 421., 898.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-1-34-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.569017  ]\n",
      "  [-1.9082855 ]\n",
      "  [ 0.04490864]\n",
      "  [ 0.48367605]\n",
      "  [-0.88388354]\n",
      "  [-0.9100036 ]\n",
      "  [ 0.52...785]\n",
      "  [ 0.47454885]\n",
      "  [-1.2584603 ]\n",
      "  [ 0.29211393]\n",
      "  [-0.2647533 ]\n",
      "  [-1.2555606 ]\n",
      "  [ 0.32270807]\n",
      "  [ 0.5425863 ]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.67784154]\n",
      "  [ 1.2473531 ]\n",
      "  [-0.574275  ]\n",
      "  [ 1.0528044 ]\n",
      "  [-0.7486727 ]\n",
      "  [ 0.30380037]\n",
      "  [-0.48...04 ]\n",
      "  [ 0.7545898 ]\n",
      "  [-0.05056139]\n",
      "  [-0.10917802]\n",
      "  [-0.10732011]\n",
      "  [-0.48260665]\n",
      "  [ 0.6033458 ]\n",
      "  [ 0.5934572 ]]])\n",
      "h0_        = needle.Tensor([[[-0.9856218 ]\n",
      "  [-0.999982  ]\n",
      "  [-0.9999985 ]\n",
      "  [ 0.9917673 ]\n",
      "  [-0.9999879 ]\n",
      "  [-0.9999985 ]\n",
      "  [ 0.75...212]\n",
      "  [ 0.54102075]\n",
      "  [ 0.6960618 ]\n",
      "  [-0.6711533 ]\n",
      "  [-0.671126  ]\n",
      "  [-0.6665289 ]\n",
      "  [ 0.7286294 ]\n",
      "  [ 0.52353704]]])\n",
      "h_         = needle.Tensor([[[-0.9856218 ]\n",
      "  [-0.999982  ]\n",
      "  [-0.9999985 ]\n",
      "  [ 0.9917673 ]\n",
      "  [-0.9999879 ]\n",
      "  [-0.9999985 ]\n",
      "  [ 0.75...212]\n",
      "  [ 0.54102075]\n",
      "  [ 0.6960618 ]\n",
      "  [-0.6711533 ]\n",
      "  [-0.671126  ]\n",
      "  [-0.6665289 ]\n",
      "  [ 0.7286294 ]\n",
      "  [ 0.52353704]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dd6eeb0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.47788066 -1.2705841   0.78809136 ...  0.3280028  -0.6293955\n",
      "   0.19981465]\n",
      " [-0.47483027 -1.2730365... 0.32404876 -0.632643\n",
      "   0.19970095]\n",
      " [-0.5809431  -1.1877247   0.6533611  ...  0.47011447 -0.51267713\n",
      "   0.20390104]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.2723283]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[432., 303., 775., 996., 403., 775.,  47., 428., 152., 189., 681.,\n",
      "        919.,  49., 653., 570.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-12-1-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.08638526 -0.12351386  0.06016655 -1.4162515  -0.3527432\n",
      "   -1.344847   -0.08698065 -0.00384302  1.2914582  -0.7431856\n",
      "   -0.00348957 -1.44906   ]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.4576621   0.6073602   1.3037037   0.88034534  0.8442443\n",
      "   -0.5901894   0.01361308 -0.20811205 -0.42674553 -0.4191604\n",
      "   -0.6276987   0.42472452]]])\n",
      "h0_        = needle.Tensor([[[ 0.03599443 -0.0805682  -0.00252529  0.06333043 -0.01732776\n",
      "    0.22112525  0.427568    0.19205163 -0.22992325  0.11497983\n",
      "    0.09807999 -0.03657291]]])\n",
      "h_         = needle.Tensor([[[ 0.03599443 -0.0805682  -0.00252529  0.06333043 -0.01732776\n",
      "    0.22112525  0.427568    0.19205163 -0.22992325  0.11497983\n",
      "    0.09807999 -0.03657291]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122df8cd90>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.4367669  -0.05765345 -0.2212713   0.37575132  0.18298367  0.1731609\n",
      "  -0.1483957   0.10714065  0.20...872247 -0.0178804  -0.22786099 -0.37146437  0.12456062  0.06144828\n",
      "  -0.03674874 -0.12849402 -0.40923637 -0.10374658]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 0.10728522 -0.21099937 -0.26585418 -0.27739066  0.0954182   0.17093392\n",
      "  -0.19639212  0.28053746 -0.1...24267  -0.22205581 -0.02382132 -0.09026743\n",
      "  -0.02712284  0.09090975  0.13469133  0.16478969 -0.15938017 -0.11415675]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[468.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-12-1-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.88500327  0.82224756  0.6216915  -0.84612286  0.55242205\n",
      "   -1.8359128   0.02384042 -0.2949961   0...24 -1.2135142   0.7644443\n",
      "   -0.56176585 -0.29774967  0.31041175  0.8045834  -0.37893224\n",
      "   -0.02133044  0.13772896]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.76481086 -0.02935282  0.5862696   0.86743116  0.23117928\n",
      "   -0.0461402  -1.0727973   0.33904678 -0...7  -0.76677054  0.8706293\n",
      "   -0.57822406  1.035906    0.35478142  0.26313442  0.49137452\n",
      "   -0.3074166  -0.0495177 ]]])\n",
      "h0_        = needle.Tensor([[[ 0.08972633  0.2783295   0.3162977   0.31706864  0.17175007\n",
      "    0.24430855 -0.00563403 -0.10215671  0...587 -0.30086005  0.21108904\n",
      "   -0.16839343 -0.18227187  0.11537894 -0.3923455   0.461124\n",
      "    0.29451627 -0.22485244]]])\n",
      "h_         = needle.Tensor([[[ 0.08972633  0.2783295   0.3162977   0.31706864  0.17175007\n",
      "    0.24430855 -0.00563403 -0.10215671  0...587 -0.30086005  0.21108904\n",
      "   -0.16839343 -0.18227187  0.11537894 -0.3923455   0.461124\n",
      "    0.29451627 -0.22485244]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dd561c0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[ 3.68577600e-01 -2.03031063e-01 -2.51565814e-01 -1.77166402e-01\n",
      "  -2.41369933e-01  8.58036280e-02  5.0...01 -1.97335243e-01 -1.44094780e-01 -3.29319537e-02\n",
      "   4.41423833e-01  3.75229120e-01  1.03950746e-01 -2.88330883e-01]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.22244579  0.2145541   0.11240144 -0.26388362 -0.02029757  0.00195582\n",
      "   0.0015626  -0.24682961 -0.1...199996  0.21677339 -0.20577376 -0.07304998\n",
      "  -0.12247203  0.0100443  -0.059868   -0.18802986  0.2037514  -0.01013807]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[502.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-12-1-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-8.5540903e-01  4.4370303e-01 -7.6163656e-01  6.0251045e-01\n",
      "    7.0847161e-02 -1.6730833e+00 -2.57564...954e+00  1.6546804e-01  1.4356370e+00 -1.8399782e+00\n",
      "    8.9336967e-01  2.3890589e-01  5.6055272e-01  5.5420560e-01]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.35493413  0.07272949 -0.7673467   0.26258498 -0.70219296\n",
      "   -0.29824877  0.5829878   1.7595944  -0...62  1.9966251   0.68137956\n",
      "   -0.7741732   0.8208146  -1.4751223  -0.10929222  1.1168675\n",
      "    0.2664176   0.7132607 ]]])\n",
      "h0_        = needle.Tensor([[[ 0.23021713 -0.00629077 -0.2962298  -0.02285025 -0.45796084\n",
      "    0.05367421 -0.23143916  0.30350164 -0...4  0.18272261 -0.16415393\n",
      "   -0.15029009 -0.47969726  0.27118403 -0.20233674 -0.25029236\n",
      "   -0.10103372 -0.11975037]]])\n",
      "h_         = needle.Tensor([[[ 0.23021713 -0.00629077 -0.2962298  -0.02285025 -0.45796084\n",
      "    0.05367421 -0.23143916  0.30350164 -0...4  0.18272261 -0.16415393\n",
      "   -0.15029009 -0.47969726  0.27118403 -0.20233674 -0.25029236\n",
      "   -0.10103372 -0.11975037]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d9ac3a0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.0206423  -0.2182722  -0.07399649 ...  0.17839907  0.24025029\n",
      "  -0.08155483]\n",
      " [ 0.10343121 -0.038452...0.17485094  0.25079486\n",
      "  -0.07129215]\n",
      " [ 0.0472927  -0.12119697 -0.01401066 ...  0.1901237   0.1633982\n",
      "  -0.14879994]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.18653177  0.03252568 -0.10664546 -0.1237528   0.1817897   0.2823901\n",
      "   0.127049    0.12206888  0.05...628982  0.11110293 -0.17078453  0.22855887\n",
      "  -0.14191389 -0.27922153 -0.23551238 -0.08603416 -0.07908925 -0.2612543 ]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[403., 182.,  91., 891., 758., 299., 647., 978., 911.,  82., 745.,\n",
      "        576., 415., 331., 494.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-12-1-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.25357747  0.33417568  1.4496782   1.3519182  -0.12178834\n",
      "   -1.2257018   1.6977062   0.40070388 -0...286  1.4689485   0.4769761\n",
      "    1.6187106  -1.2896318   1.0579133  -1.5913031  -1.1898028\n",
      "   -0.6389734  -0.9237121 ]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 8.90405536e-01  2.64950228e+00 -2.74407953e-01 -2.05994904e-01\n",
      "    2.05920911e+00  1.03278649e+00  2... -2.47668529e+00  2.85047978e-01 -3.50772917e-01\n",
      "    6.41843602e-02 -3.26394975e-01 -4.86046463e-01 -1.30318964e+00]]])\n",
      "h0_        = needle.Tensor([[[-1.51859775e-01  4.77238089e-01 -5.88941097e-01 -6.80518076e-02\n",
      "   -1.11915678e-01 -2.24452183e-01 -3... -2.10651278e-01  3.15829128e-01  2.25515798e-01\n",
      "    9.74345207e-02 -3.38010490e-02 -2.34131277e-01 -3.09847921e-01]]])\n",
      "h_         = needle.Tensor([[[-1.51859775e-01  4.77238089e-01 -5.88941097e-01 -6.80518076e-02\n",
      "   -1.11915678e-01 -2.24452183e-01 -3... -2.10651278e-01  3.15829128e-01  2.25515798e-01\n",
      "    9.74345207e-02 -3.38010490e-02 -2.34131277e-01 -3.09847921e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dec7c40>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.07643408 -0.17742881 -0.08088374 ...  0.01179679 -0.06459104\n",
      "  -0.04691502]\n",
      " [-0.05642573 -0.133251....02293785 -0.03960972\n",
      "  -0.04638505]\n",
      " [-0.069499   -0.16256668 -0.12791139 ...  0.04644011 -0.08930437\n",
      "  -0.0473401 ]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 0.28462    -0.04343122 -0.10462344 -0.18833017 -0.23835333 -0.20843947\n",
      "   0.22291039 -0.09445819  0.1...021232 -0.12937321 -0.2412113   0.17306428\n",
      "   0.0801211   0.15027282  0.13055204 -0.1908214  -0.17752337 -0.17244244]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[267., 738., 552., 321., 926., 663.,  90., 506., 413., 292., 934.,\n",
      "        594., 214., 412., 900.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-12-34-1-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.46470928 -1.3138033   0.7564402   0.33627728 -0.0697104\n",
      "    0.75421286  2.1045568   0.22899184  1.0295489   3.0653882\n",
      "    2.3366036   0.18595941]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.65903467  0.9816441   0.6959086  -0.2105315  -0.9186664\n",
      "    0.03747138 -2.875043    1.1109762  -0.7053395  -0.04157678\n",
      "   -0.5676992  -2.1143577 ]]])\n",
      "h0_        = needle.Tensor([[[ 9.5123184e-01  9.2199022e-01 -9.4120085e-01  8.1560636e-01\n",
      "    4.8130697e-01 -1.5519807e-01  2.8294042e-01 -4.9415681e-01\n",
      "    2.4182813e-01 -3.1619713e-01  2.1042533e-02  4.0772927e-04]]])\n",
      "h_         = needle.Tensor([[[ 9.5123184e-01  9.2199022e-01 -9.4120085e-01  8.1560636e-01\n",
      "    4.8130697e-01 -1.5519807e-01  2.8294042e-01 -4.9415681e-01\n",
      "    2.4182813e-01 -3.1619713e-01  2.1042533e-02  4.0772927e-04]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122de43850>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[ 3.97906899e-02  3.90785962e-01 -1.54720932e-01  3.30948919e-01\n",
      "   9.05200467e-02  3.14646512e-02 -4.3...01  4.50952321e-01 -7.71896005e-01  5.87042153e-01\n",
      "   7.24118412e-01  5.90880930e-01 -6.52591288e-02 -5.54936707e-01]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 0.07724939 -0.26948547 -0.03088507  0.08519609 -0.21183759 -0.10756084\n",
      "   0.16323416 -0.21331294  0.0...8261197  0.03859434  0.04576625 -0.2512651\n",
      "   0.2374769   0.16313061  0.151233   -0.2726831  -0.23903747 -0.27541474]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[502.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-rnn-1000-False-12-34-1-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.9820861  -0.46115747 -1.1734014  -0.39257315 -1.4238683\n",
      "    0.29956898 -0.09174305 -0.6188333  -0....334 -1.778382   -1.7055097\n",
      "   -0.337261   -0.20596147  0.08242182 -0.42912352 -0.3573548\n",
      "    1.3314124   0.9222994 ]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.9530807  -0.1440293   0.06245726  1.7318245   0.72350806\n",
      "   -0.5024733  -0.6574565   1.7355586   0...4  -0.73896056 -0.45022598\n",
      "    0.58797014  0.7037393   1.1976168  -0.23216543  1.2628387\n",
      "   -1.4424902  -1.0860338 ]]])\n",
      "h0_        = needle.Tensor([[[ 0.9491062   0.6759128   0.4082381  -0.991881   -0.6524648\n",
      "   -0.23431472 -0.59610325 -0.60880905 -0....093 -0.0540102  -0.688188\n",
      "    0.08737633  0.3833177   0.37432572 -0.08393618 -0.36451158\n",
      "    0.12875919 -0.53901047]]])\n",
      "h_         = needle.Tensor([[[ 0.9491062   0.6759128   0.4082381  -0.991881   -0.6524648\n",
      "   -0.23431472 -0.59610325 -0.60880905 -0....093 -0.0540102  -0.688188\n",
      "    0.08737633  0.3833177   0.37432572 -0.08393618 -0.36451158\n",
      "    0.12875919 -0.53901047]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122db95ca0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[ 1.35418728e-01 -8.65988135e-02 -4.12998348e-01 -4.14612681e-01\n",
      "   2.20338881e-01  8.69576484e-02 -3.3...01 -1.23446673e-01 -5.70329130e-02  3.39864999e-01\n",
      "   2.00655252e-01  1.93346635e-01  6.70028478e-03  1.44374460e-01]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 4.47293334e-02  1.88699991e-01  1.08581707e-01 -2.56447136e-01\n",
      "  -2.02320173e-01  1.80870265e-01 -6.8...02  7.61711672e-02 -1.40204012e-01 -2.84101009e-01\n",
      "   1.87596008e-01  1.00104168e-01 -2.56262632e-04  4.19155171e-04]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[30.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-rnn-1000-False-12-34-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.524738    0.56673586  0.71069205  0.9793861  -0.18948719\n",
      "    1.7291704  -0.89865184  0.80170137 -0...08  0.65782195  0.41646913\n",
      "    0.40698525 -0.09411138  1.2365885   1.5719892  -0.0504591\n",
      "    0.42939827 -0.29980865]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 6.8213153e-01 -8.8328683e-01 -7.5116867e-01  3.7107939e-01\n",
      "    1.3937710e-01 -8.4923822e-01 -2.32481...311e-01 -1.1630884e+00  1.7646936e+00  7.5770527e-01\n",
      "    4.5261818e-01  7.2824717e-01  1.7735331e+00  2.8485596e-01]]])\n",
      "h0_        = needle.Tensor([[[ 0.03215751  0.03780812  0.7024853   0.95981824 -0.88978416\n",
      "   -0.3326386  -0.013694   -0.8298318  -0...73  0.57735485  0.63834393\n",
      "    0.3948249  -0.5251958   0.52399904  0.6887597   0.8962224\n",
      "   -0.5987504  -0.10536723]]])\n",
      "h_         = needle.Tensor([[[ 0.03215751  0.03780812  0.7024853   0.95981824 -0.88978416\n",
      "   -0.3326386  -0.013694   -0.8298318  -0...73  0.57735485  0.63834393\n",
      "    0.3948249  -0.5251958   0.52399904  0.6887597   0.8962224\n",
      "   -0.5987504  -0.10536723]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122debb8e0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.2900106  -0.18442677  0.00582217 ...  0.41078424 -0.04700571\n",
      "   0.5775409 ]\n",
      " [ 0.46741936  0.339659....8058907   0.02403221\n",
      "   0.26205382]\n",
      " [-0.799191   -0.72776073 -0.33341822 ... -0.44411314  0.03785726\n",
      "   0.11059465]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 0.22922485 -0.14703344 -0.15165284 -0.06262986  0.14436612 -0.26135504\n",
      "  -0.23862997  0.1862912   0.1...386256 -0.13444835  0.00845069 -0.12842189\n",
      "  -0.25773507 -0.03131416 -0.18423414 -0.19209062  0.267818   -0.22931488]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[962.,  83., 857., 903., 622., 161., 474., 712., 703., 705., 318.,\n",
      "        470., 439., 233., 173.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-rnn-1000-False-12-34-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.36534190e+00 -6.45626903e-01 -3.21524441e-01  9.44027722e-01\n",
      "    6.73059225e-01 -1.11783594e-01  1... -1.62651849e+00 -4.35301661e-01  7.39494758e-03\n",
      "    2.59877056e-01  1.36196911e-01 -1.62810051e+00 -7.83972263e-01]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-9.59741652e-01  1.26827478e+00 -5.07312477e-01 -1.95233238e+00\n",
      "    1.27197063e+00 -8.81098509e-01  2... -4.24854577e-01 -6.83941543e-01 -4.33922350e-01\n",
      "    2.37020433e-01 -1.56444892e-01 -6.04870915e-01  1.00802243e+00]]])\n",
      "h0_        = needle.Tensor([[[-5.06005228e-01 -5.57158254e-02 -1.34010531e-03 -3.10081035e-01\n",
      "    2.99399942e-01  6.89342558e-01 -2...  5.37238479e-01 -5.76854758e-02 -3.72022867e-01\n",
      "   -1.56656653e-01  4.53905374e-01  2.85772711e-01  1.21205807e-01]]])\n",
      "h_         = needle.Tensor([[[-5.06005228e-01 -5.57158254e-02 -1.34010531e-03 -3.10081035e-01\n",
      "    2.99399942e-01  6.89342558e-01 -2...  5.37238479e-01 -5.76854758e-02 -3.72022867e-01\n",
      "   -1.56656653e-01  4.53905374e-01  2.85772711e-01  1.21205807e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122de76fa0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[ 0.0431506   0.06531367 -0.35861975 ... -0.0512204  -0.2815398\n",
      "   0.05203171]\n",
      " [-0.10543296 -0.2652790...-0.5436817  -0.22373824\n",
      "  -0.07049744]\n",
      " [-0.09659138 -0.27983457 -0.34347484 ... -0.30153376 -0.528287\n",
      "  -0.14510849]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 0.26964855 -0.23435582 -0.15788649  0.2600334  -0.16293974 -0.22433662\n",
      "   0.17961495 -0.2782219   0.2...3301686  0.06487323 -0.09836644  0.2835929\n",
      "  -0.15145278 -0.21500772 -0.0186088  -0.22560936 -0.19562338 -0.1142535 ]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[145.,  48., 758., 532., 387., 962., 278., 399., 840., 411., 483.,\n",
      "        542., 392., 436., 520.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-lstm-1-False-1-1-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.8550703]]])\n",
      "c0_        = needle.Tensor([[[0.5615749]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[1.7829822]]])\n",
      "h0_        = needle.Tensor([[[0.35441804]]])\n",
      "h_         = (needle.Tensor([[[0.35441804]]]), needle.Tensor([[[0.5615749]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122de7d1c0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[1.2534088]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.51229554 -0.58117044 -0.7103983   0.41457784]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cpu-lstm-1-False-1-1-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.8949644 ]]\n",
      "\n",
      " [[ 0.57014173]]])\n",
      "c0_        = needle.Tensor([[[-0.43632674]]\n",
      "\n",
      " [[ 0.43323332]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[0.14615983]]\n",
      "\n",
      " [[0.261945  ]]])\n",
      "h0_        = needle.Tensor([[[-0.27135104]]\n",
      "\n",
      " [[ 0.23972775]]])\n",
      "h_         = (needle.Tensor([[[-0.27135104]]\n",
      "\n",
      " [[ 0.23972775]]]), needle.Tensor([[[-0.43632674]]\n",
      "\n",
      " [[ 0.43323332]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d8e05e0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.21577561]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.90448403  0.12322192 -0.28604746 -0.7345714 ]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-1-1-15-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-2.044855  ]\n",
      "  [ 1.4506521 ]\n",
      "  [-0.56158495]\n",
      "  [ 0.3565853 ]\n",
      "  [ 0.19550738]\n",
      "  [ 0.51770705]\n",
      "  [-1.09...35 ]\n",
      "  [ 0.7551809 ]\n",
      "  [ 0.49440104]\n",
      "  [-0.12071193]\n",
      "  [-0.7783428 ]\n",
      "  [-0.15048751]\n",
      "  [-1.37135   ]\n",
      "  [ 0.09784983]]])\n",
      "c0_        = needle.Tensor([[[0.15199639]\n",
      "  [0.15199639]\n",
      "  [0.15199639]\n",
      "  [0.15199639]\n",
      "  [0.15199639]\n",
      "  [0.15199639]\n",
      "  [0.15199639]...0.15199639]\n",
      "  [0.15199639]\n",
      "  [0.15199639]\n",
      "  [0.15199639]\n",
      "  [0.15199639]\n",
      "  [0.15199639]\n",
      "  [0.15199639]\n",
      "  [0.15199639]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.12849161]\n",
      "  [-0.62995297]\n",
      "  [-0.5449615 ]\n",
      "  [-0.15545483]\n",
      "  [-0.9044963 ]\n",
      "  [-0.93597955]\n",
      "  [-1.60...96 ]\n",
      "  [-0.38522795]\n",
      "  [ 0.70699894]\n",
      "  [ 1.2880499 ]\n",
      "  [ 1.7931963 ]\n",
      "  [ 0.38233736]\n",
      "  [-0.05922179]\n",
      "  [-0.8037028 ]]])\n",
      "h0_        = needle.Tensor([[[0.08081482]\n",
      "  [0.08081482]\n",
      "  [0.08081482]\n",
      "  [0.08081482]\n",
      "  [0.08081482]\n",
      "  [0.08081482]\n",
      "  [0.08081482]...0.08081482]\n",
      "  [0.08081482]\n",
      "  [0.08081482]\n",
      "  [0.08081482]\n",
      "  [0.08081482]\n",
      "  [0.08081482]\n",
      "  [0.08081482]\n",
      "  [0.08081482]]])\n",
      "h_         = (needle.Tensor([[[0.08081482]\n",
      "  [0.08081482]\n",
      "  [0.08081482]\n",
      "  [0.08081482]\n",
      "  [0.08081482]\n",
      "  [0.08081482]\n",
      "  [0.08081482....15199639]\n",
      "  [0.15199639]\n",
      "  [0.15199639]\n",
      "  [0.15199639]\n",
      "  [0.15199639]\n",
      "  [0.15199639]\n",
      "  [0.15199639]\n",
      "  [0.15199639]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dcc1f40>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.48255384]\n",
      " [-0.48255384]\n",
      " [-0.48255384]\n",
      " [-0.48255384]\n",
      " [-0.48255384]\n",
      " [-0.48255384]\n",
      " [-0.48255384]\n",
      " [-0.48255384]\n",
      " [-0.48255384]\n",
      " [-0.48255384]\n",
      " [-0.48255384]\n",
      " [-0.48255384]\n",
      " [-0.48255384]\n",
      " [-0.48255384]\n",
      " [-0.48255384]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.8887566 -0.8732868 -0.9353479 -0.7239959]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-1-1-15-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.5134762 ]\n",
      "  [-2.4152381 ]\n",
      "  [-0.06337524]\n",
      "  [-0.09255464]\n",
      "  [-1.3091673 ]\n",
      "  [ 0.9062045 ]\n",
      "  [-0.19...307]\n",
      "  [ 0.09895427]\n",
      "  [-0.14905424]\n",
      "  [-0.880142  ]\n",
      "  [ 1.8870052 ]\n",
      "  [-0.79261   ]\n",
      "  [ 1.4794813 ]\n",
      "  [-0.6550248 ]]])\n",
      "c0_        = needle.Tensor([[[-0.12764187]\n",
      "  [-0.12764187]\n",
      "  [-0.12764187]\n",
      "  [-0.12764187]\n",
      "  [-0.12764187]\n",
      "  [-0.12764187]\n",
      "  [-0.12...702]\n",
      "  [-0.44113702]\n",
      "  [-0.44113702]\n",
      "  [-0.44113702]\n",
      "  [-0.44113702]\n",
      "  [-0.44113702]\n",
      "  [-0.44113702]\n",
      "  [-0.44113702]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.92719716]\n",
      "  [-0.8673312 ]\n",
      "  [-0.8027474 ]\n",
      "  [ 0.56125104]\n",
      "  [ 0.31572622]\n",
      "  [-0.9278664 ]\n",
      "  [ 0.31...37 ]\n",
      "  [-1.2202635 ]\n",
      "  [-0.9080992 ]\n",
      "  [-1.1176665 ]\n",
      "  [-0.8309612 ]\n",
      "  [ 1.5102162 ]\n",
      "  [-0.20611688]\n",
      "  [ 1.2675965 ]]])\n",
      "h0_        = needle.Tensor([[[-0.0394311]\n",
      "  [-0.0394311]\n",
      "  [-0.0394311]\n",
      "  [-0.0394311]\n",
      "  [-0.0394311]\n",
      "  [-0.0394311]\n",
      "  [-0.0394311]...-0.2983066]\n",
      "  [-0.2983066]\n",
      "  [-0.2983066]\n",
      "  [-0.2983066]\n",
      "  [-0.2983066]\n",
      "  [-0.2983066]\n",
      "  [-0.2983066]\n",
      "  [-0.2983066]]])\n",
      "h_         = (needle.Tensor([[[-0.0394311]\n",
      "  [-0.0394311]\n",
      "  [-0.0394311]\n",
      "  [-0.0394311]\n",
      "  [-0.0394311]\n",
      "  [-0.0394311]\n",
      "  [-0.0394311...02]\n",
      "  [-0.44113702]\n",
      "  [-0.44113702]\n",
      "  [-0.44113702]\n",
      "  [-0.44113702]\n",
      "  [-0.44113702]\n",
      "  [-0.44113702]\n",
      "  [-0.44113702]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d65e7f0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.28496474]\n",
      " [0.28496474]\n",
      " [0.28496474]\n",
      " [0.28496474]\n",
      " [0.28496474]\n",
      " [0.28496474]\n",
      " [0.28496474]\n",
      " [0.28496474]\n",
      " [0.28496474]\n",
      " [0.28496474]\n",
      " [0.28496474]\n",
      " [0.28496474]\n",
      " [0.28496474]\n",
      " [0.28496474]\n",
      " [0.28496474]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.80215937  0.8282145  -0.58947295 -0.79932666]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-1-34-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.36054054]]])\n",
      "c0_        = needle.Tensor([[[-0.7320215]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.7187912]]])\n",
      "h0_        = needle.Tensor([[[-0.01791939]]])\n",
      "h_         = (needle.Tensor([[[-0.01791939]]]), needle.Tensor([[[-0.7320215]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122da4b9a0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.10661492]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.439405   -0.5895221  -0.1215824  -0.05259315]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-1-34-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[1.2827716 ]]\n",
      "\n",
      " [[0.07992088]]])\n",
      "c0_        = needle.Tensor([[[-0.30637184]]\n",
      "\n",
      " [[ 0.137739  ]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.3441306]]\n",
      "\n",
      " [[ 1.2658675]]])\n",
      "h0_        = needle.Tensor([[[-0.12823817]]\n",
      "\n",
      " [[ 0.07228149]]])\n",
      "h_         = (needle.Tensor([[[-0.12823817]]\n",
      "\n",
      " [[ 0.07228149]]]), needle.Tensor([[[-0.30637184]]\n",
      "\n",
      " [[ 0.137739  ]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122da2e640>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.49551582]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.15977086  0.13271812  0.17748137 -0.22520362]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-1-34-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.4218426 ]\n",
      "  [ 1.761242  ]\n",
      "  [ 1.1031429 ]\n",
      "  [-2.97961   ]\n",
      "  [-0.24389163]\n",
      "  [-0.10097734]\n",
      "  [ 2.36...49 ]\n",
      "  [ 1.2100176 ]\n",
      "  [-0.74522936]\n",
      "  [ 0.20494774]\n",
      "  [-1.3139709 ]\n",
      "  [-0.11698417]\n",
      "  [-0.74438465]\n",
      "  [-0.05101067]]])\n",
      "c0_        = needle.Tensor([[[0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.3798162 ]\n",
      "  [-0.10645344]\n",
      "  [-0.4978488 ]\n",
      "  [-0.8432864 ]\n",
      "  [-0.5916273 ]\n",
      "  [-0.20218793]\n",
      "  [ 1.09...577]\n",
      "  [-0.72288775]\n",
      "  [ 0.035677  ]\n",
      "  [ 0.76475096]\n",
      "  [ 0.5592483 ]\n",
      "  [-1.8584983 ]\n",
      "  [ 1.6475115 ]\n",
      "  [ 0.7697375 ]]])\n",
      "h0_        = needle.Tensor([[[0.07312981]\n",
      "  [0.07312981]\n",
      "  [0.07312981]\n",
      "  [0.07312981]\n",
      "  [0.07312981]\n",
      "  [0.07312981]\n",
      "  [0.07312981]...0.07312981]\n",
      "  [0.07312981]\n",
      "  [0.07312981]\n",
      "  [0.07312981]\n",
      "  [0.07312981]\n",
      "  [0.07312981]\n",
      "  [0.07312981]\n",
      "  [0.07312981]]])\n",
      "h_         = (needle.Tensor([[[0.07312981]\n",
      "  [0.07312981]\n",
      "  [0.07312981]\n",
      "  [0.07312981]\n",
      "  [0.07312981]\n",
      "  [0.07312981]\n",
      "  [0.07312981...68]\n",
      "  [0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]\n",
      "  [0.8144568]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dc59c10>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[0.3346154]\n",
      " [0.3346154]\n",
      " [0.3346154]\n",
      " [0.3346154]\n",
      " [0.3346154]\n",
      " [0.3346154]\n",
      " [0.3346154]\n",
      " [0.3346154]\n",
      " [0.3346154]\n",
      " [0.3346154]\n",
      " [0.3346154]\n",
      " [0.3346154]\n",
      " [0.3346154]\n",
      " [0.3346154]\n",
      " [0.3346154]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.67577     0.565554    0.54716635  0.801231  ]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-1-34-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.3183068 ]\n",
      "  [-1.412611  ]\n",
      "  [ 0.78824204]\n",
      "  [-0.34507367]\n",
      "  [ 0.3700051 ]\n",
      "  [-0.185109  ]\n",
      "  [ 0.28...045]\n",
      "  [ 0.5854406 ]\n",
      "  [ 0.18153483]\n",
      "  [-1.065997  ]\n",
      "  [-1.0412005 ]\n",
      "  [-0.46361044]\n",
      "  [-0.21923536]\n",
      "  [-0.2607608 ]]])\n",
      "c0_        = needle.Tensor([[[0.03129221]\n",
      "  [0.03129221]\n",
      "  [0.03129221]\n",
      "  [0.03129221]\n",
      "  [0.03129221]\n",
      "  [0.03129221]\n",
      "  [0.03129221]...0.25626218]\n",
      "  [0.25626218]\n",
      "  [0.25626218]\n",
      "  [0.25626218]\n",
      "  [0.25626218]\n",
      "  [0.25626218]\n",
      "  [0.25626218]\n",
      "  [0.25626218]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.12624109]\n",
      "  [-0.4031596 ]\n",
      "  [-0.81495017]\n",
      "  [ 0.275435  ]\n",
      "  [-0.26394942]\n",
      "  [-1.5634166 ]\n",
      "  [-0.52...33 ]\n",
      "  [-1.2348064 ]\n",
      "  [ 1.0855086 ]\n",
      "  [ 0.3263224 ]\n",
      "  [ 1.2430916 ]\n",
      "  [ 0.59340066]\n",
      "  [-0.19302131]\n",
      "  [-0.37423408]]])\n",
      "h0_        = needle.Tensor([[[0.01438864]\n",
      "  [0.01438864]\n",
      "  [0.01438864]\n",
      "  [0.01438864]\n",
      "  [0.01438864]\n",
      "  [0.01438864]\n",
      "  [0.01438864]...0.20223217]\n",
      "  [0.20223217]\n",
      "  [0.20223217]\n",
      "  [0.20223217]\n",
      "  [0.20223217]\n",
      "  [0.20223217]\n",
      "  [0.20223217]\n",
      "  [0.20223217]]])\n",
      "h_         = (needle.Tensor([[[0.01438864]\n",
      "  [0.01438864]\n",
      "  [0.01438864]\n",
      "  [0.01438864]\n",
      "  [0.01438864]\n",
      "  [0.01438864]\n",
      "  [0.01438864....25626218]\n",
      "  [0.25626218]\n",
      "  [0.25626218]\n",
      "  [0.25626218]\n",
      "  [0.25626218]\n",
      "  [0.25626218]\n",
      "  [0.25626218]\n",
      "  [0.25626218]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d9fc160>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-1.0775427]\n",
      " [-1.0775427]\n",
      " [-1.0775427]\n",
      " [-1.0775427]\n",
      " [-1.0775427]\n",
      " [-1.0775427]\n",
      " [-1.0775427]\n",
      " [-1.0775427]\n",
      " [-1.0775427]\n",
      " [-1.0775427]\n",
      " [-1.0775427]\n",
      " [-1.0775427]\n",
      " [-1.0775427]\n",
      " [-1.0775427]\n",
      " [-1.0775427]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.83522266  0.37008965  0.5293821   0.78867596]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-12-1-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.18967943  1.4763085   2.6170633   0.68023705 -1.6537302\n",
      "    0.6352373  -2.3035395   0.92472035  0.6492514  -0.9685388\n",
      "    0.5293781  -0.21042468]]])\n",
      "c0_        = needle.Tensor([[[ 0.05906614  0.17339723 -0.07767668 -0.14409043 -0.06105975\n",
      "   -0.15397328 -0.09134941  0.01138177  0.17759156 -0.03614035\n",
      "    0.0655271  -0.24241754]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.5127919  -1.2774785  -0.58640975 -1.3183948  -0.27989215\n",
      "   -1.5825279   0.8465982   0.5880021  -0.6396587   0.8126484\n",
      "   -0.7171499   1.0676821 ]]])\n",
      "h0_        = needle.Tensor([[[ 0.03091752  0.07719685 -0.04146164 -0.06611093 -0.03485483\n",
      "   -0.0899146  -0.04803839  0.00538372  0.1046202  -0.01955095\n",
      "    0.02931161 -0.14804307]]])\n",
      "h_         = (needle.Tensor([[[ 0.03091752  0.07719685 -0.04146164 -0.06611093 -0.03485483\n",
      "   -0.0899146  -0.04803839  0.00538372  ... -0.14409043 -0.06105975\n",
      "   -0.15397328 -0.09134941  0.01138177  0.17759156 -0.03614035\n",
      "    0.0655271  -0.24241754]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dda6c10>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[0.05918363]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-2.40739077e-01 -2.29714692e-01 -2.72482596e-02  1.36302471e-01\n",
      "  -8.91909003e-02 -2.97017265e-02 -1.2...01  7.50289783e-02  2.03922853e-01  4.37069647e-02\n",
      "  -5.07708173e-03 -1.01140127e-01 -2.33415607e-02 -1.32422671e-01]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-12-1-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.9126116   0.531802   -0.21990316  1.0345556  -0.2705147\n",
      "    0.9735158   1.1641331  -0.5841703  -0....99   0.7421124   0.51577187\n",
      "   -0.07565715  0.69562256 -0.54358715 -1.5635577  -1.559376\n",
      "   -1.6395679   2.4094212 ]]])\n",
      "c0_        = needle.Tensor([[[-0.04109801  0.03482636  0.08160333 -0.10584863  0.40475875\n",
      "   -0.18733461  0.04176962 -0.11554958 -0...  -0.04841496 -0.03677167\n",
      "   -0.02861005 -0.12146638 -0.01133581 -0.028176   -0.08801953\n",
      "   -0.0057913  -0.03190799]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.49581876  1.0620494  -0.28384417  1.0430008   0.65181017\n",
      "    1.3589938  -0.49975917  1.1053926  -0...52   0.6031803  -0.8139572\n",
      "   -0.72287756  0.675893   -1.7940065   2.2795508   1.1040263\n",
      "    0.85039264  0.4313579 ]]])\n",
      "h0_        = needle.Tensor([[[-0.02206957  0.0155663   0.02733864 -0.03037419  0.2688013\n",
      "   -0.11425293  0.01748688 -0.04923823 -0....7 -0.02651951 -0.02190882\n",
      "   -0.01270251 -0.05600385 -0.00553561 -0.0156839  -0.04217004\n",
      "   -0.0034365  -0.01452385]]])\n",
      "h_         = (needle.Tensor([[[-0.02206957  0.0155663   0.02733864 -0.03037419  0.2688013\n",
      "   -0.11425293  0.01748688 -0.04923823 -0... -0.04841496 -0.03677167\n",
      "   -0.02861005 -0.12146638 -0.01133581 -0.028176   -0.08801953\n",
      "   -0.0057913  -0.03190799]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122da6ae20>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.14801203]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 4.87042038e-04 -2.05790430e-01  3.74347717e-02 -1.63960770e-01\n",
      "  -2.32070182e-02 -1.19229034e-01 -2.0...01 -2.02788800e-01 -2.84515649e-01 -5.60799520e-03\n",
      "   8.79985020e-02 -1.19119972e-01 -2.21913740e-01 -1.45688310e-01]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-12-1-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.8246599   0.42930037  0.02223547  0.99326754 -1.2322329\n",
      "   -0.9759111   0.95591575  3.2554123   0....4  -1.9553559   0.44063875\n",
      "   -1.0337387   1.1714112   0.49328372 -1.7849954   0.8509065\n",
      "   -1.0611734  -0.6671703 ]]])\n",
      "c0_        = needle.Tensor([[[-0.11514235  0.10969285  0.18498017  0.01141524 -0.16856079\n",
      "   -0.08985919  0.13953604  0.12577021 -0...7  0.01141524 -0.16856079\n",
      "   -0.08985919  0.13953604  0.12577021 -0.04726186 -0.00168735\n",
      "   -0.02733245  0.08474921]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.1503855  -0.99732834 -0.26153463  0.9668508   0.20422834\n",
      "    1.6293652   0.97512    -0.61487246  1...1   0.41148987  0.49540144\n",
      "   -0.1981369  -0.27755973 -0.6452938   1.0321227   0.7004095\n",
      "   -3.1789742   0.13081628]]])\n",
      "h0_        = needle.Tensor([[[-0.05097091  0.04695053  0.10351218  0.00653036 -0.09518782\n",
      "   -0.04060753  0.07486395  0.0597131  -0...8  0.00653036 -0.09518782\n",
      "   -0.04060753  0.07486395  0.0597131  -0.0215979  -0.00090436\n",
      "   -0.01468523  0.04582259]]])\n",
      "h_         = (needle.Tensor([[[-0.05097091  0.04695053  0.10351218  0.00653036 -0.09518782\n",
      "   -0.04060753  0.07486395  0.0597131  -...  0.01141524 -0.16856079\n",
      "   -0.08985919  0.13953604  0.12577021 -0.04726186 -0.00168735\n",
      "   -0.02733245  0.08474921]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122de26460>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[0.19878545]\n",
      " [0.19878545]\n",
      " [0.19878545]\n",
      " [0.19878545]\n",
      " [0.19878545]\n",
      " [0.19878545]\n",
      " [0.19878545]\n",
      " [0.19878545]\n",
      " [0.19878545]\n",
      " [0.19878545]\n",
      " [0.19878545]\n",
      " [0.19878545]\n",
      " [0.19878545]\n",
      " [0.19878545]\n",
      " [0.19878545]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.13504611 -0.10138836  0.20849647  0.10859344  0.23049812 -0.14978527\n",
      "   0.28750685 -0.07799425 -0.0...2188792  0.17236608  0.14678848  0.1161856\n",
      "   0.09134472  0.08347779  0.12089238 -0.08577305 -0.24019505 -0.11806676]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-12-1-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.0410694  -0.18978992  1.0452832   0.70702636 -2.239273\n",
      "    1.2474356   0.18269067  1.0666105   0.0...    -1.3162466  -0.3777788\n",
      "    1.4444796  -0.5263034   1.3289186   1.1753168   2.3106277\n",
      "    0.11059309 -1.8572935 ]]])\n",
      "c0_        = needle.Tensor([[[ 0.2093348  -0.10213885 -0.10269115 -0.25433642  0.04185012\n",
      "   -0.16191278 -0.04054204  0.37600487 -0...92  0.04829462 -0.1239557\n",
      "    0.0233947   0.0594948  -0.00995867 -0.05458009  0.13657585\n",
      "   -0.07809445 -0.02838054]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.0898908   1.6864179   0.57135874 -0.10897094  0.45009878\n",
      "    0.9371101   0.08887577 -0.92805666  0...7 -0.24654002 -0.12314059\n",
      "   -0.17991263  0.14310582  0.45967036  0.62061065  0.22723898\n",
      "    0.24824727  0.4020941 ]]])\n",
      "h0_        = needle.Tensor([[[ 0.08518746 -0.05659853 -0.05715704 -0.09348509  0.01580246\n",
      "   -0.08188509 -0.019208    0.21106702 -0...3  0.02434945 -0.06186988\n",
      "    0.01138829  0.03148913 -0.00427739 -0.03058697  0.07698454\n",
      "   -0.04470495 -0.01459771]]])\n",
      "h_         = (needle.Tensor([[[ 0.08518746 -0.05659853 -0.05715704 -0.09348509  0.01580246\n",
      "   -0.08188509 -0.019208    0.21106702 -...2  0.04829462 -0.1239557\n",
      "    0.0233947   0.0594948  -0.00995867 -0.05458009  0.13657585\n",
      "   -0.07809445 -0.02838054]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122da5c280>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.11631557]\n",
      " [0.11631557]\n",
      " [0.11631557]\n",
      " [0.11631557]\n",
      " [0.11631557]\n",
      " [0.11631557]\n",
      " [0.11631557]\n",
      " [0.11631557]\n",
      " [0.11631557]\n",
      " [0.11631557]\n",
      " [0.11631557]\n",
      " [0.11631557]\n",
      " [0.11631557]\n",
      " [0.11631557]\n",
      " [0.11631557]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.11367371  0.05668161 -0.2153088   0.24316075  0.15353128  0.2712482\n",
      "   0.2608446  -0.06949578  0.25...244467  0.03912139  0.21613143 -0.00291777\n",
      "   0.2253403   0.08490264 -0.1738044  -0.17825656  0.255974   -0.01696827]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-12-34-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.41189334  1.094393    1.0519143  -0.70395166 -0.18919694\n",
      "   -0.03586109 -0.02428221  0.04794399  0.49162447  0.3246757\n",
      "   -0.24733989  0.76103604]]])\n",
      "c0_        = needle.Tensor([[[ 0.62161195 -0.11720523 -0.25528723  0.3999799  -0.18010297\n",
      "   -0.12280419  0.69496995  0.20232815 -0.13051037  0.11301816\n",
      "    0.3547837  -0.12423132]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.2843684   1.0387267  -0.904876    0.43212977 -1.3669736\n",
      "    1.0824605   0.7221504  -0.6442682  -0.38166818  0.9782409\n",
      "    0.20311254  1.9003118 ]]])\n",
      "h0_        = needle.Tensor([[[ 0.3329589  -0.08148075 -0.06170978  0.22262476 -0.13643827\n",
      "   -0.02679897  0.10669231  0.05682325 -0.07832196  0.08265155\n",
      "    0.11128227 -0.07738509]]])\n",
      "h_         = (needle.Tensor([[[ 0.3329589  -0.08148075 -0.06170978  0.22262476 -0.13643827\n",
      "   -0.02679897  0.10669231  0.05682325 -...  0.3999799  -0.18010297\n",
      "   -0.12280419  0.69496995  0.20232815 -0.13051037  0.11301816\n",
      "    0.3547837  -0.12423132]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d9f9d00>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[0.14326404]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.06801174 -0.06970073  0.21686056  0.25479177  0.20554635  0.10316193\n",
      "   0.10519584  0.09422988 -0.1...980004 -0.19995606  0.18044199 -0.16990528\n",
      "  -0.22187798 -0.05017862 -0.209379   -0.12260136  0.00051191 -0.07918098]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cpu-lstm-1-False-12-34-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.6887639  -0.72777945  0.5853048   0.01361961 -1.4156268\n",
      "   -0.5642493   1.716021   -0.31939656 -0....924 -0.60057026  2.058097\n",
      "   -0.76501054  1.605318    0.909848    0.5058929   0.09284066\n",
      "    2.099555   -0.29240856]]])\n",
      "c0_        = needle.Tensor([[[-0.17449489 -0.20145603  0.36042926  0.19096355 -0.45159605\n",
      "    0.33168763  0.25124553  0.26188412  0...6  0.23163381 -0.12489195\n",
      "    0.00360524 -0.06737036  0.04288437  0.06850412  0.10997438\n",
      "   -0.10740312  0.13420317]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.3139309   0.7815061   0.1270035  -1.2680494   0.04665148\n",
      "    0.34028348 -0.34206963  0.82740706 -0...5 -0.7858737   0.96982217\n",
      "   -0.97258556 -1.5173963  -1.2191815  -1.6709989   0.19677646\n",
      "    0.49690983  0.13619812]]])\n",
      "h0_        = needle.Tensor([[[-0.14823803 -0.08966029  0.05440697  0.08410729 -0.11231875\n",
      "    0.17355321  0.15986173  0.16858435  0...5  0.10747864 -0.07082812\n",
      "    0.00204445 -0.03712656  0.02413424  0.03794578  0.05147804\n",
      "   -0.05186553  0.06243571]]])\n",
      "h_         = (needle.Tensor([[[-0.14823803 -0.08966029  0.05440697  0.08410729 -0.11231875\n",
      "    0.17355321  0.15986173  0.16858435  ...  0.23163381 -0.12489195\n",
      "    0.00360524 -0.06737036  0.04288437  0.06850412  0.10997438\n",
      "   -0.10740312  0.13420317]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122db310d0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.12810439]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 8.00999925e-02  2.23997787e-01  2.99140625e-02 -1.50285847e-02\n",
      "   2.45697677e-01 -7.34811276e-02 -2.1...01 -1.11582346e-01 -2.76486874e-01  1.64791897e-01\n",
      "   1.25684187e-01  1.98042065e-01 -5.73605411e-02 -1.66491151e-01]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1-False-12-34-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.4120364  -0.52377784  1.3199469   1.9511591  -0.40546\n",
      "    0.7837297   2.519404    0.6263446  -0.90...167 -1.2457261  -1.7211527\n",
      "   -0.837636    1.1793915  -0.02057874  1.4862999  -1.2619847\n",
      "    0.6726342  -1.7086017 ]]])\n",
      "c0_        = needle.Tensor([[[ 0.19162811 -0.1680512   0.0977233  -0.50476617  0.25132626\n",
      "   -0.1303625  -0.11988425  0.5053007   0...  -0.50476617  0.25132626\n",
      "   -0.1303625  -0.11988425  0.5053007   0.18987283 -0.03444486\n",
      "    0.32620332 -0.48696297]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.2669345   0.9311122  -0.9988056  -1.7670124  -0.70157045\n",
      "   -0.0556951  -0.48582003 -1.0958709  -0...82  0.6998142   0.17036527\n",
      "    0.7364034   0.2919871  -1.063819   -1.6423047  -1.6549811\n",
      "   -0.35900903 -1.010863  ]]])\n",
      "h0_        = needle.Tensor([[[ 0.15882564 -0.0997761   0.00864406 -0.25207335  0.15879074\n",
      "   -0.09210649 -0.084419    0.23403671  0...06 -0.25207335  0.15879074\n",
      "   -0.09210649 -0.084419    0.23403671  0.03193722 -0.0108212\n",
      "    0.1748325  -0.27522442]]])\n",
      "h_         = (needle.Tensor([[[ 0.15882564 -0.0997761   0.00864406 -0.25207335  0.15879074\n",
      "   -0.09210649 -0.084419    0.23403671  ... -0.50476617  0.25132626\n",
      "   -0.1303625  -0.11988425  0.5053007   0.18987283 -0.03444486\n",
      "    0.32620332 -0.48696297]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d7fbfd0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.06388333]\n",
      " [-0.06388333]\n",
      " [-0.06388333]\n",
      " [-0.06388333]\n",
      " [-0.06388333]\n",
      " [-0.06388333]\n",
      " [-0.06388333]\n",
      " [-0.06388333]\n",
      " [-0.06388333]\n",
      " [-0.06388333]\n",
      " [-0.06388333]\n",
      " [-0.06388333]\n",
      " [-0.06388333]\n",
      " [-0.06388333]\n",
      " [-0.06388333]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 2.39484817e-01 -9.30777192e-02 -4.57058139e-02  1.12285614e-01\n",
      "  -8.03938881e-03 -9.74825472e-02 -1.3...01  1.61153153e-01 -2.50690170e-02 -2.40690336e-01\n",
      "  -2.16458172e-01  2.82667279e-01  2.62732863e-01 -2.40282968e-01]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1-False-12-34-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-8.24366435e-02  1.01804025e-01  2.44836032e-01 -9.59872305e-01\n",
      "    4.59094614e-01 -1.17319846e+00  9...  2.38179713e-02  2.20236659e+00  4.28381056e-01\n",
      "   -7.78465420e-02  1.28084469e+00  3.61976326e-01 -8.15963149e-01]]])\n",
      "c0_        = needle.Tensor([[[-0.76981306  0.07248765  0.01372614  0.3674061  -0.56906897\n",
      "    0.28236318  0.07605451 -0.19263017 -0...4 -0.0580961  -0.00623089\n",
      "    0.05638919 -0.03363522 -0.0403887  -0.1952691  -0.12318699\n",
      "    0.01196026 -0.21798018]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.20043726  0.71021074 -1.8776608   0.38167492  0.402827\n",
      "   -1.4224011  -0.37370935  0.2184876   0.3...27  0.796709    0.98305863\n",
      "   -0.4856627   1.0893601  -0.2150165  -0.22052921 -0.3103965\n",
      "   -0.91315484 -0.7968409 ]]])\n",
      "h0_        = needle.Tensor([[[-0.3972147   0.0143921   0.00185173  0.13889988 -0.24725924\n",
      "    0.09103038  0.021316   -0.0908232  -0...4 -0.02670218 -0.00286623\n",
      "    0.02876806 -0.01335383 -0.01943341 -0.09565882 -0.07347319\n",
      "    0.00538739 -0.11622752]]])\n",
      "h_         = (needle.Tensor([[[-0.3972147   0.0143921   0.00185173  0.13889988 -0.24725924\n",
      "    0.09103038  0.021316   -0.0908232  -... -0.0580961  -0.00623089\n",
      "    0.05638919 -0.03363522 -0.0403887  -0.1952691  -0.12318699\n",
      "    0.01196026 -0.21798018]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122de65730>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.21641324]\n",
      " [0.21641324]\n",
      " [0.21641324]\n",
      " [0.21641324]\n",
      " [0.21641324]\n",
      " [0.21641324]\n",
      " [0.21641324]\n",
      " [0.21641324]\n",
      " [0.21641324]\n",
      " [0.21641324]\n",
      " [0.21641324]\n",
      " [0.21641324]\n",
      " [0.21641324]\n",
      " [0.21641324]\n",
      " [0.21641324]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.27487832  0.06119824  0.2330201   0.03598872 -0.06412884  0.2145683\n",
      "   0.1786777  -0.22101203  0.15...39046  -0.12514609  0.288368    0.23262472\n",
      "  -0.1514778   0.26796708 -0.04936662  0.03979442 -0.16876104  0.04246954]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-False-1-1-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[2.2868433]]])\n",
      "c0_        = needle.Tensor([[[-0.10074994]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.00843181]]])\n",
      "h0_        = needle.Tensor([[[-0.04065619]]])\n",
      "h_         = (needle.Tensor([[[-0.04065619]]]), needle.Tensor([[[-0.10074994]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d957970>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[ 8.56875837e-01  5.23071408e-01 -6.50754929e-01  4.15064603e-01\n",
      "  -2.58032113e-01  4.18411404e-01  1.4...01  1.13792159e-01 -1.83146924e-01  9.07130718e-01\n",
      "  -8.49633574e-01 -8.86031032e-01 -1.97223917e-01  6.91714168e-01]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[0.7626421  0.57358325 0.15048835 0.8213606 ]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[898.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-False-1-1-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.8406643]]\n",
      "\n",
      " [[ 1.380872 ]]])\n",
      "c0_        = needle.Tensor([[[-0.04076395]]\n",
      "\n",
      " [[ 0.09644502]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[0.7534533]]\n",
      "\n",
      " [[0.649591 ]]])\n",
      "h0_        = needle.Tensor([[[-0.02028245]]\n",
      "\n",
      " [[ 0.04998587]]])\n",
      "h_         = (needle.Tensor([[[-0.02028245]]\n",
      "\n",
      " [[ 0.04998587]]]), needle.Tensor([[[-0.04076395]]\n",
      "\n",
      " [[ 0.09644502]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d9f9c40>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[ 8.35367203e-01  1.96887702e-01 -6.21167660e-01  6.13766968e-01\n",
      "  -9.37017560e-01 -2.30840445e-01 -4.0...01  7.03367054e-01  5.11964560e-01  5.68249285e-01\n",
      "   8.96216750e-01 -3.18092108e-01 -5.20015061e-01  5.79487443e-01]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 0.8981354   0.9313698  -0.30373216  0.7010578 ]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[523.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-False-1-1-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.68075544]\n",
      "  [ 0.45044824]\n",
      "  [-0.09322364]\n",
      "  [ 0.02851737]\n",
      "  [-0.40756598]\n",
      "  [-0.8153601 ]\n",
      "  [ 0.08...606]\n",
      "  [-0.9080947 ]\n",
      "  [-0.23110923]\n",
      "  [-1.3017433 ]\n",
      "  [-1.9192232 ]\n",
      "  [-0.90845346]\n",
      "  [-1.2534592 ]\n",
      "  [-0.00827901]]])\n",
      "c0_        = needle.Tensor([[[0.21391778]\n",
      "  [0.20445119]\n",
      "  [0.2412382 ]\n",
      "  [0.25218642]\n",
      "  [0.25587282]\n",
      "  [0.2387722 ]\n",
      "  [0.25779375]...0.22117575]\n",
      "  [0.22643717]\n",
      "  [0.2571979 ]\n",
      "  [0.2513558 ]\n",
      "  [0.21095568]\n",
      "  [0.24110751]\n",
      "  [0.23461209]\n",
      "  [0.17453049]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.8691031 ]\n",
      "  [-2.5515335 ]\n",
      "  [-1.1027298 ]\n",
      "  [-1.4635736 ]\n",
      "  [-1.0482495 ]\n",
      "  [-0.32312602]\n",
      "  [ 0.05...89 ]\n",
      "  [ 0.10959694]\n",
      "  [ 1.026099  ]\n",
      "  [-0.7567361 ]\n",
      "  [ 0.8797729 ]\n",
      "  [-1.4374007 ]\n",
      "  [-0.09845311]\n",
      "  [-1.3490924 ]]])\n",
      "h0_        = needle.Tensor([[[0.10006203]\n",
      "  [0.14836639]\n",
      "  [0.12646092]\n",
      "  [0.14073932]\n",
      "  [0.14752792]\n",
      "  [0.12371542]\n",
      "  [0.15643896]...0.10641501]\n",
      "  [0.15807986]\n",
      "  [0.15865059]\n",
      "  [0.1626366 ]\n",
      "  [0.15153049]\n",
      "  [0.12631254]\n",
      "  [0.16075999]\n",
      "  [0.13166751]]])\n",
      "h_         = (needle.Tensor([[[0.10006203]\n",
      "  [0.14836639]\n",
      "  [0.12646092]\n",
      "  [0.14073932]\n",
      "  [0.14752792]\n",
      "  [0.12371542]\n",
      "  [0.15643896....22117575]\n",
      "  [0.22643717]\n",
      "  [0.2571979 ]\n",
      "  [0.2513558 ]\n",
      "  [0.21095568]\n",
      "  [0.24110751]\n",
      "  [0.23461209]\n",
      "  [0.17453049]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d988520>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.24696192  0.73426217 -0.9557619  ...  0.8822076  -0.43615887\n",
      "  -0.18952559]\n",
      " [-0.21789567  0.773067....90177727 -0.38839787\n",
      "  -0.1387944 ]\n",
      " [-0.22794391  0.7596524  -0.9449786  ...  0.8923975  -0.41128966\n",
      "  -0.16310981]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 0.04237146 -0.8915159   0.2557737  -0.2358189 ]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[615., 380., 400., 646., 730., 756., 881., 290., 643., 990., 680.,\n",
      "        687., 655., 567., 226.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-False-1-1-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.2540884 ]\n",
      "  [-0.76872605]\n",
      "  [ 0.132522  ]\n",
      "  [-1.9496727 ]\n",
      "  [-0.43328583]\n",
      "  [-1.148113  ]\n",
      "  [ 1.68...96 ]\n",
      "  [-0.27699736]\n",
      "  [-0.43096015]\n",
      "  [ 0.8010576 ]\n",
      "  [ 0.25520816]\n",
      "  [-0.15963285]\n",
      "  [-1.614522  ]\n",
      "  [ 0.5282824 ]]])\n",
      "c0_        = needle.Tensor([[[-0.19893812]\n",
      "  [-0.17020845]\n",
      "  [ 0.14455783]\n",
      "  [-0.10187928]\n",
      "  [-0.11580089]\n",
      "  [-0.14566834]\n",
      "  [-0.19...21 ]\n",
      "  [ 0.403233  ]\n",
      "  [ 0.406448  ]\n",
      "  [ 0.42227748]\n",
      "  [ 0.40295798]\n",
      "  [ 0.40816608]\n",
      "  [ 0.41473526]\n",
      "  [ 0.41066083]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.06226378]\n",
      "  [ 3.4308116 ]\n",
      "  [ 0.7529617 ]\n",
      "  [ 1.4363595 ]\n",
      "  [-1.8064586 ]\n",
      "  [-0.19900256]\n",
      "  [ 0.28...63 ]\n",
      "  [-0.32719523]\n",
      "  [ 0.90813714]\n",
      "  [ 1.705609  ]\n",
      "  [-0.30483374]\n",
      "  [ 0.7214496 ]\n",
      "  [-0.86180395]\n",
      "  [-0.34276316]]])\n",
      "h0_        = needle.Tensor([[[-0.12246922]\n",
      "  [-0.10332245]\n",
      "  [ 0.08293808]\n",
      "  [-0.06106261]\n",
      "  [-0.06955057]\n",
      "  [-0.08793114]\n",
      "  [-0.12...509]\n",
      "  [ 0.14521778]\n",
      "  [ 0.14371282]\n",
      "  [ 0.13603128]\n",
      "  [ 0.14534555]\n",
      "  [ 0.14290024]\n",
      "  [ 0.13974346]\n",
      "  [ 0.14171045]]])\n",
      "h_         = (needle.Tensor([[[-0.12246922]\n",
      "  [-0.10332245]\n",
      "  [ 0.08293808]\n",
      "  [-0.06106261]\n",
      "  [-0.06955057]\n",
      "  [-0.08793114]\n",
      "  [-0.1...1 ]\n",
      "  [ 0.403233  ]\n",
      "  [ 0.406448  ]\n",
      "  [ 0.42227748]\n",
      "  [ 0.40295798]\n",
      "  [ 0.40816608]\n",
      "  [ 0.41473526]\n",
      "  [ 0.41066083]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122ddd5040>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[ 0.30317086  0.82777804 -0.5181157  ...  0.0245659  -0.88497216\n",
      "  -0.5901984 ]\n",
      " [ 0.3039087   0.828038...0.01995312 -0.8892339\n",
      "  -0.5877419 ]\n",
      " [ 0.30653507  0.8289652  -0.5171146  ...  0.02155637 -0.88775265\n",
      "  -0.5885957 ]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.63250864  0.80974466  0.24497047 -0.5408407 ]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[752., 369., 259., 891., 906., 719., 802., 759., 709., 468., 231.,\n",
      "        800., 822., 883., 533.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-False-1-34-1-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.248258]]])\n",
      "c0_        = needle.Tensor([[[-0.15864822]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.5512851]]])\n",
      "h0_        = needle.Tensor([[[-8.466041e-05]]])\n",
      "h_         = (needle.Tensor([[[-8.466041e-05]]]), needle.Tensor([[[-0.15864822]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dc11730>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-9.13672924e-01 -1.43352360e-01  6.62541091e-01 -4.11221415e-01\n",
      "  -6.91137493e-01  6.39674425e-01 -9.5...01  3.57917368e-01 -4.32128996e-01  8.85112584e-02\n",
      "   4.77474123e-01  9.84014273e-01 -4.77351159e-01  5.78737140e-01]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.8144847  0.7091247 -0.7808119 -0.5494747]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[522.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-False-1-34-1-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[2.3733463]]\n",
      "\n",
      " [[0.271804 ]]])\n",
      "c0_        = needle.Tensor([[[0.50412285]]\n",
      "\n",
      " [[0.28995755]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.01326111]]\n",
      "\n",
      " [[ 0.06775159]]])\n",
      "h0_        = needle.Tensor([[[0.46176466]]\n",
      "\n",
      " [[0.10405283]]])\n",
      "h_         = (needle.Tensor([[[0.46176466]]\n",
      "\n",
      " [[0.10405283]]]), needle.Tensor([[[0.50412285]]\n",
      "\n",
      " [[0.28995755]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122ddddb80>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[ 0.38621402 -0.7483031   0.00485292 -0.780202   -0.8545891  -0.87574077\n",
      "   0.6004798   0.97482526  0.2...1051447 -0.60710317 -0.8761324   0.09774674  0.23309779 -0.6112292\n",
      "   0.72687596  0.740943    0.16104385  1.0104258 ]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 0.92303735  0.66186976 -0.18010335 -0.61558175]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[433.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-1-34-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.5005977 ]\n",
      "  [ 1.4819824 ]\n",
      "  [-1.7172986 ]\n",
      "  [-0.70042366]\n",
      "  [-0.20739341]\n",
      "  [ 0.23176655]\n",
      "  [-1.41...66 ]\n",
      "  [ 1.0676833 ]\n",
      "  [-1.4189289 ]\n",
      "  [-0.25210845]\n",
      "  [-0.3591424 ]\n",
      "  [-2.3137994 ]\n",
      "  [ 1.6433022 ]\n",
      "  [ 0.39785072]]])\n",
      "c0_        = needle.Tensor([[[-0.849191  ]\n",
      "  [-0.2357505 ]\n",
      "  [ 0.03624261]\n",
      "  [ 0.7657536 ]\n",
      "  [-0.05752557]\n",
      "  [-0.33356866]\n",
      "  [-0.01...44 ]\n",
      "  [ 0.44803232]\n",
      "  [ 0.94312775]\n",
      "  [-0.4759857 ]\n",
      "  [-0.8641093 ]\n",
      "  [ 0.9240141 ]\n",
      "  [ 0.9983556 ]\n",
      "  [-0.01628492]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.38589   ]\n",
      "  [-0.11415165]\n",
      "  [-0.3590386 ]\n",
      "  [ 0.8398342 ]\n",
      "  [-0.79640865]\n",
      "  [-0.19269426]\n",
      "  [ 0.07...064]\n",
      "  [ 1.6877986 ]\n",
      "  [-0.11117288]\n",
      "  [-0.93842506]\n",
      "  [-1.0896931 ]\n",
      "  [-1.7047902 ]\n",
      "  [ 2.2721446 ]\n",
      "  [-1.3555864 ]]])\n",
      "h0_        = needle.Tensor([[[-1.4504379e-02]\n",
      "  [-1.4368655e-02]\n",
      "  [ 1.3073097e-05]\n",
      "  [ 5.2586776e-01]\n",
      "  [-8.6748466e-04]\n",
      "  [-1.861...3]\n",
      "  [ 3.8355289e-04]\n",
      "  [-1.2466354e-01]\n",
      "  [-3.9961568e-01]\n",
      "  [ 3.0076903e-01]\n",
      "  [ 7.4869889e-01]\n",
      "  [-1.6241278e-02]]])\n",
      "h_         = (needle.Tensor([[[-1.4504379e-02]\n",
      "  [-1.4368655e-02]\n",
      "  [ 1.3073097e-05]\n",
      "  [ 5.2586776e-01]\n",
      "  [-8.6748466e-04]\n",
      "  [-1.86...4 ]\n",
      "  [ 0.44803232]\n",
      "  [ 0.94312775]\n",
      "  [-0.4759857 ]\n",
      "  [-0.8641093 ]\n",
      "  [ 0.9240141 ]\n",
      "  [ 0.9983556 ]\n",
      "  [-0.01628492]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122db16ac0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.8833544  -0.6990693   0.98246586 ...  0.94966716  0.09493938\n",
      "   0.05327991]\n",
      " [-0.8832787  -0.698953....6505989  -0.48854828\n",
      "  -0.36794275]\n",
      " [-0.8843232  -0.70055187  0.9825022  ...  0.94807196  0.09626728\n",
      "   0.05423853]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 0.17054214  0.50490355 -0.7627383  -0.6525455 ]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[973., 520., 177., 266., 699.,  18., 248., 468., 106., 418., 970.,\n",
      "        220., 755.,  13., 641.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-1-34-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.21824095]\n",
      "  [ 0.5612626 ]\n",
      "  [ 1.5088111 ]\n",
      "  [ 0.14325249]\n",
      "  [ 0.33986396]\n",
      "  [ 0.15421079]\n",
      "  [ 0.21...224]\n",
      "  [-1.8522576 ]\n",
      "  [-1.2948381 ]\n",
      "  [ 0.81566226]\n",
      "  [ 0.83754224]\n",
      "  [-1.4115248 ]\n",
      "  [ 1.1815319 ]\n",
      "  [ 1.1818043 ]]])\n",
      "c0_        = needle.Tensor([[[ 6.2537551e-02]\n",
      "  [ 8.0618918e-02]\n",
      "  [ 1.4114557e-01]\n",
      "  [-2.0195645e-01]\n",
      "  [ 1.6519545e-01]\n",
      "  [-1.082...1]\n",
      "  [ 4.3371812e-01]\n",
      "  [ 4.5535627e-01]\n",
      "  [ 4.3024230e-01]\n",
      "  [ 2.9533774e-01]\n",
      "  [ 4.0988037e-01]\n",
      "  [ 4.5518309e-01]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.39932483]\n",
      "  [-0.36127555]\n",
      "  [-0.5662421 ]\n",
      "  [ 1.0127418 ]\n",
      "  [-0.69463   ]\n",
      "  [ 0.44194108]\n",
      "  [ 0.38...214]\n",
      "  [ 1.6642296 ]\n",
      "  [-1.7054058 ]\n",
      "  [-1.0113155 ]\n",
      "  [-0.69303787]\n",
      "  [-1.2836556 ]\n",
      "  [ 0.34064114]\n",
      "  [-0.93456286]]])\n",
      "h0_        = needle.Tensor([[[ 2.75719240e-02]\n",
      "  [ 4.62539820e-03]\n",
      "  [ 1.23306513e-01]\n",
      "  [-6.45940527e-02]\n",
      "  [ 1.05878440e-04]\n",
      "  [-... 7.52986446e-02]\n",
      "  [ 8.12260434e-02]\n",
      "  [ 7.43746534e-02]\n",
      "  [ 4.35327590e-02]\n",
      "  [ 6.91097826e-02]\n",
      "  [ 8.11773688e-02]]])\n",
      "h_         = (needle.Tensor([[[ 2.75719240e-02]\n",
      "  [ 4.62539820e-03]\n",
      "  [ 1.23306513e-01]\n",
      "  [-6.45940527e-02]\n",
      "  [ 1.05878440e-04]\n",
      "  [...]\n",
      "  [ 4.3371812e-01]\n",
      "  [ 4.5535627e-01]\n",
      "  [ 4.3024230e-01]\n",
      "  [ 2.9533774e-01]\n",
      "  [ 4.0988037e-01]\n",
      "  [ 4.5518309e-01]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dbfdcd0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[ 0.8791349  -0.4881082  -0.6895558  ...  0.2517715  -0.95567137\n",
      "   0.6150155 ]\n",
      " [ 0.87822986 -0.486694... 0.25455037 -0.9550844\n",
      "   0.61544895]\n",
      " [ 0.8742422  -0.4804672  -0.6948519  ...  0.24444415 -0.9572191\n",
      "   0.61387265]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.22487497 -0.04481367 -0.7685772  -0.40715465]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[266., 231., 428., 835., 710., 988., 448., 619., 716., 199., 688.,\n",
      "        687., 712., 318., 871.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-False-12-1-1-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.86132765  1.1624569  -1.6095171  -0.5313751  -0.00484511\n",
      "    0.03026352  1.6083381  -1.111372   -0.10054209  1.3226051\n",
      "    1.3004568  -2.5293336 ]]])\n",
      "c0_        = needle.Tensor([[[-0.1667062   0.19387598 -0.08811933  0.08020198 -0.08298789\n",
      "    0.1546158   0.19251168  0.07135609 -0.22113852  0.09200504\n",
      "   -0.09448951  0.11344089]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.32680053 -1.3586564  -0.653114   -0.9032102  -1.7445456\n",
      "    0.61329174 -0.34720564  0.30023015  0.6316155   0.08546234\n",
      "   -0.39222932  0.7858838 ]]])\n",
      "h0_        = needle.Tensor([[[-0.06852131  0.06728446 -0.03332244  0.04524837 -0.04011293\n",
      "    0.07455691  0.07995506  0.03577115 -0.11315881  0.03253922\n",
      "   -0.05787986  0.06936924]]])\n",
      "h_         = (needle.Tensor([[[-0.06852131  0.06728446 -0.03332244  0.04524837 -0.04011293\n",
      "    0.07455691  0.07995506  0.03577115 -...  0.08020198 -0.08298789\n",
      "    0.1546158   0.19251168  0.07135609 -0.22113852  0.09200504\n",
      "   -0.09448951  0.11344089]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122db42130>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-1.31678790e-01 -1.24539733e-02 -9.45356637e-02 -4.32008319e-02\n",
      "   3.19920480e-02  1.35864109e-01  1.0...01 -9.66448337e-04  1.89887941e-01  7.69511983e-02\n",
      "   9.27170813e-02  1.44362882e-01 -1.15315370e-01  4.83628251e-02]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 1.31311223e-01  2.86957920e-01  1.25431687e-01 -1.61998093e-01\n",
      "   2.25087702e-01  2.29002774e-01 -2.0...02 -3.11577343e-03 -1.56400388e-03  4.79501598e-02\n",
      "  -1.99644398e-02  2.95019336e-02  1.90318853e-01  1.25274345e-01]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[767.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cpu-lstm-1000-False-12-1-1-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 1.7547652e-02 -4.3500417e-01  3.4021369e-01  3.3687305e-01\n",
      "   -2.7486610e-01 -1.6495509e-01 -6.54865...385e-03  3.8680029e-01  8.1171834e-01  8.1421542e-01\n",
      "    1.7226548e+00  6.8827945e-01  1.5752771e-01  5.2603084e-01]]])\n",
      "c0_        = needle.Tensor([[[-0.1917875   0.16022861  0.0980419  -0.17101361  0.14405474\n",
      "   -0.21479698  0.14743353  0.07021083  0...3  0.01373546 -0.00560774\n",
      "   -0.0899163   0.05130729  0.01499544  0.06272861  0.00234643\n",
      "    0.14215107 -0.04503035]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.856178    0.86741847  0.23131199 -0.71070445 -0.24085753\n",
      "   -0.63239     1.1009686  -0.409173   -1...3   0.6398387   0.3916632\n",
      "   -1.8543923  -0.34422907  0.17603144  0.59648025 -0.83870083\n",
      "   -0.3519585  -1.4534897 ]]])\n",
      "h0_        = needle.Tensor([[[-0.09756951  0.08536886  0.04178212 -0.0886653   0.08785482\n",
      "   -0.10210807  0.07092512  0.03215507  0...6  0.00646442 -0.00282612\n",
      "   -0.03962383  0.01873091  0.00739846  0.03726393  0.00117832\n",
      "    0.05677301 -0.02420474]]])\n",
      "h_         = (needle.Tensor([[[-0.09756951  0.08536886  0.04178212 -0.0886653   0.08785482\n",
      "   -0.10210807  0.07092512  0.03215507  ...  0.01373546 -0.00560774\n",
      "   -0.0899163   0.05130729  0.01499544  0.06272861  0.00234643\n",
      "    0.14215107 -0.04503035]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122de30d60>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-2.35664830e-01 -7.19935447e-02 -5.60919940e-02 -2.29963243e-01\n",
      "   1.20754190e-01 -1.05767041e-01 -2.3...01  1.79479480e-01  1.47281185e-01 -2.30656058e-01\n",
      "  -2.66712874e-01  2.84861196e-02  1.57842606e-01 -4.64531183e-02]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-1.25493824e-01  2.29283585e-03 -5.46249188e-02  2.83430994e-01\n",
      "   8.01390558e-02  1.31125882e-01  2.4...01 -1.08243480e-01 -1.10331573e-01 -5.93445487e-02\n",
      "  -2.88651496e-01 -3.15184407e-02 -2.30663210e-01 -2.68224865e-01]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[437.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-12-1-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.21451892 -0.99164194  1.5659552  -0.3190614   1.1543838\n",
      "    0.02943322  1.0897567  -0.5767692   1....5   0.9257327   0.7325134\n",
      "   -0.2555935   0.39235026  0.7706551   1.1819888   0.33983272\n",
      "   -1.3122813  -0.5430818 ]]])\n",
      "c0_        = needle.Tensor([[[-0.08702047  0.08334131 -0.08367486 -0.15550502 -0.10316359\n",
      "   -0.03546939 -0.03094613  0.05904808  0...3 -0.15001385  0.05576105\n",
      "    0.13520537 -0.17412181 -0.08317319 -0.01578326 -0.07844051\n",
      "   -0.25951073 -0.03231251]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.8564639  -0.09309065  1.0874836  -1.7063708   0.27136707\n",
      "    0.27487096 -1.0974503  -0.41260445  1...6   1.643608   -0.9041776\n",
      "   -0.33055085  0.5335941   0.7310933  -1.1169306  -0.99529773\n",
      "    2.2391093   0.7320599 ]]])\n",
      "h0_        = needle.Tensor([[[-0.04452307  0.03639167 -0.0475876  -0.07489046 -0.0620397\n",
      "   -0.02013185 -0.01250382  0.03795677  0....2 -0.07454718  0.03533749\n",
      "    0.0823793  -0.07582406 -0.04764285 -0.00899753 -0.04740217\n",
      "   -0.11484695 -0.01621041]]])\n",
      "h_         = (needle.Tensor([[[-0.04452307  0.03639167 -0.0475876  -0.07489046 -0.0620397\n",
      "   -0.02013185 -0.01250382  0.03795677  0... -0.15001385  0.05576105\n",
      "    0.13520537 -0.17412181 -0.08317319 -0.01578326 -0.07844051\n",
      "   -0.25951073 -0.03231251]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122db30f40>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.20101564 -0.06130351  0.12712194 ... -0.05652492  0.19002303\n",
      "  -0.15193821]\n",
      " [-0.20116399 -0.072366....06958207  0.18214373\n",
      "  -0.1723089 ]\n",
      " [-0.19122402 -0.06414357  0.12254684 ... -0.08093137  0.17003128\n",
      "  -0.1934846 ]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 0.14168607  0.00543119 -0.02394707  0.25114805 -0.15402958  0.08703156\n",
      "  -0.05569615  0.2615563   0.1...135102  0.12324824 -0.16803901  0.07476601\n",
      "   0.0753292  -0.09768843  0.06669863  0.21662758  0.23071991 -0.04162484]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[867., 965., 957., 936., 457., 667., 287., 347., 897., 734., 527.,\n",
      "        301., 760., 469., 119.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-12-1-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 3.02390099e-01  8.81617665e-01 -1.09382987e+00  3.71491760e-01\n",
      "   -9.40120518e-01  7.84956694e-01  2... -5.12036324e-01  1.35039437e+00  6.72200084e-01\n",
      "   -4.39664692e-01  1.81289330e-01 -2.75164098e-01  1.69109726e+00]]])\n",
      "c0_        = needle.Tensor([[[ 0.0097894   0.17255056 -0.0596453   0.21392825  0.08599679\n",
      "    0.12154552 -0.01212632 -0.04430509 -0...1  -0.02338255 -0.1325967\n",
      "    0.12380712  0.0954083   0.0865228  -0.09194554  0.19798319\n",
      "   -0.21264026  0.05941641]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.38517374 -1.786379    0.6218066  -1.346216   -0.12357853\n",
      "    0.26821095  0.5057261   1.4323913  -0...7  -1.3699617  -0.33947286\n",
      "    0.10865135 -0.4401376  -1.1199685   0.2970602   1.4375706\n",
      "    1.001507   -0.7362194 ]]])\n",
      "h0_        = needle.Tensor([[[ 0.00443113  0.08680314 -0.0259605   0.0836575   0.03646083\n",
      "    0.04755232 -0.00696482 -0.02275761 -0...  -0.01232735 -0.07621801\n",
      "    0.066278    0.04899662  0.04277612 -0.05627158  0.08289362\n",
      "   -0.08635072  0.02437937]]])\n",
      "h_         = (needle.Tensor([[[ 0.00443113  0.08680314 -0.0259605   0.0836575   0.03646083\n",
      "    0.04755232 -0.00696482 -0.02275761 -...  -0.02338255 -0.1325967\n",
      "    0.12380712  0.0954083   0.0865228  -0.09194554  0.19798319\n",
      "   -0.21264026  0.05941641]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dbaad90>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.11465099 -0.0032944  -0.06283008 ... -0.2500992  -0.18590054\n",
      "  -0.2930233 ]\n",
      " [-0.11746609 -0.000501....25575268 -0.18641761\n",
      "  -0.29707968]\n",
      " [-0.11767457 -0.00031962 -0.06529725 ... -0.25456625 -0.18623872\n",
      "  -0.29589477]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.25178126 -0.01791181 -0.01551766  0.24133779  0.03984699 -0.12258356\n",
      "  -0.2870229   0.01115071 -0.0...183656  0.1276107   0.25309426 -0.15972935\n",
      "  -0.2809969  -0.22644964 -0.19901957  0.27846268 -0.18583241  0.20723012]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[793., 502.,  25.,  96., 317., 908., 586., 129., 635.,  51., 642.,\n",
      "        580., 121., 643., 210.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-12-34-1-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.0319989   0.15132535  0.41114125  0.20861688  0.60561\n",
      "    0.18158512 -1.0750039   0.14423561 -0.23915882 -1.2032626\n",
      "   -0.24082719  0.68570036]]])\n",
      "c0_        = needle.Tensor([[[-0.14334092  0.15756671 -0.11733257  0.36255866  0.22585262\n",
      "   -0.26624864  0.49050564  0.41588652  0.0615671   0.00976015\n",
      "   -0.05414547 -0.55777526]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.49349612  0.22274715 -0.2695235  -0.22790669 -1.3162262\n",
      "    1.0342302   2.516497   -0.8291748   0.3985074  -0.31728426\n",
      "   -0.16738477  1.4255476 ]]])\n",
      "h0_        = needle.Tensor([[[-0.06438075  0.10832966 -0.05032169  0.08074789  0.14066495\n",
      "   -0.17791133  0.21595038  0.1845247   0.00838081  0.00319045\n",
      "   -0.03393427 -0.36561963]]])\n",
      "h_         = (needle.Tensor([[[-0.06438075  0.10832966 -0.05032169  0.08074789  0.14066495\n",
      "   -0.17791133  0.21595038  0.1845247   ...  0.36255866  0.22585262\n",
      "   -0.26624864  0.49050564  0.41588652  0.0615671   0.00976015\n",
      "   -0.05414547 -0.55777526]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122da27340>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-4.29956466e-01  4.16501574e-02 -2.75067508e-01 -2.56539643e-01\n",
      "  -2.09133476e-01 -1.32312048e-02 -1.6...02 -1.98145866e-01 -1.53506309e-01 -1.85487002e-01\n",
      "  -2.41639242e-01 -2.04392165e-01  3.38159353e-01  1.81991272e-02]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.23571914  0.02200019  0.19772461 -0.2827683  -0.14234948  0.26630262\n",
      "   0.01064341 -0.19720015 -0.0...095984 -0.05011069  0.10240952 -0.08984279\n",
      "   0.18707669  0.19785582 -0.22410186  0.05470227  0.27070162 -0.01683598]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[207.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-12-34-1-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.9402945   1.2369075   0.97715384  1.1674253  -1.4906834\n",
      "    2.522577   -0.6647658  -1.2946124   1....6   2.4754362   1.0176687\n",
      "   -0.5524255   0.09784736  0.39807084 -0.9481464   0.03862971\n",
      "   -1.4024464   1.0264336 ]]])\n",
      "c0_        = needle.Tensor([[[-1.29572138e-01 -2.14993641e-01  1.97928771e-01  9.08010155e-02\n",
      "   -1.88569292e-01 -1.97750941e-01 -7... -2.34681264e-01 -2.99185216e-02  9.51603800e-02\n",
      "    1.22019805e-01  5.62296733e-02  1.97660062e-03  3.57708670e-02]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.7457306  -0.3681525  -0.2801908  -0.07783683  0.11837469\n",
      "   -0.27345768  1.3213496   0.36328804 -1...2   1.1407893  -0.5943206\n",
      "    2.1208467   1.637672   -0.27775323  0.1847229   0.19094436\n",
      "    0.18483873  0.8204826 ]]])\n",
      "h0_        = needle.Tensor([[[-1.09594665e-01 -1.45933390e-01  1.53843015e-01  6.57739788e-02\n",
      "   -7.05444366e-02 -5.67095429e-02 -4... -1.15536578e-01 -1.40736522e-02  4.69107255e-02\n",
      "    5.58230951e-02  3.18349190e-02  8.78196675e-04  1.93173289e-02]]])\n",
      "h_         = (needle.Tensor([[[-1.09594665e-01 -1.45933390e-01  1.53843015e-01  6.57739788e-02\n",
      "   -7.05444366e-02 -5.67095429e-02 -...-2.34681264e-01 -2.99185216e-02  9.51603800e-02\n",
      "    1.22019805e-01  5.62296733e-02  1.97660062e-03  3.57708670e-02]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dfdd250>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.10265254 -0.08667848  0.18241867 -0.01469808  0.28019404 -0.17580497\n",
      "   0.06829323  0.26484862  0.1...672372 -0.04917093 -0.02342601  0.22538829 -0.14832163 -0.03713315\n",
      "  -0.31316465 -0.21870768 -0.25500748 -0.14916217]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 5.61173968e-02 -6.06113300e-02  1.22148566e-01  1.34682089e-01\n",
      "   1.22108288e-01 -8.49399641e-02  1.8...02  6.67432547e-02  1.21836334e-01  1.71069354e-01\n",
      "   9.97600108e-02  1.84711561e-01  1.54412165e-01 -8.49287808e-02]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[798.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-12-34-15-1-1] _____\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.5812442  -0.4877129   0.09154187  2.2151859  -1.4062638\n",
      "   -0.92435235  0.7209431   0.10030217 -1....8   0.3280668  -0.05370492\n",
      "   -1.3091202  -1.370343   -0.99592215  0.6868698  -0.1006926\n",
      "    0.3904092  -0.801389  ]]])\n",
      "c0_        = needle.Tensor([[[ 0.6101132  -0.3009187  -0.25590956  0.06577239 -0.18592754\n",
      "   -0.18640223 -0.50269616  0.07684415  0...9 -0.00753675 -0.31128913\n",
      "    0.29280436 -0.04484381 -0.43263566  0.15548266  0.03850682\n",
      "    0.326953   -0.07052191]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.1880525   0.25912225  0.52111155 -1.8918611  -0.19328827\n",
      "    0.33327168 -0.28291467 -1.2232108   1...3  -0.02265243  0.73468924\n",
      "   -1.9103174   1.4182816   0.6649374   1.3489041   1.0725024\n",
      "    0.771559   -0.83810997]]])\n",
      "h0_        = needle.Tensor([[[ 0.09336379 -0.11203042 -0.1755685   0.03566574 -0.07100286\n",
      "   -0.11220535 -0.34949008  0.04397271  0...06 -0.00347308 -0.1280087\n",
      "    0.03346877 -0.03388737 -0.2815647   0.0400691   0.02639039\n",
      "    0.25122622 -0.04289236]]])\n",
      "h_         = (needle.Tensor([[[ 0.09336379 -0.11203042 -0.1755685   0.03566574 -0.07100286\n",
      "   -0.11220535 -0.34949008  0.04397271  ... -0.00753675 -0.31128913\n",
      "    0.29280436 -0.04484381 -0.43263566  0.15548266  0.03850682\n",
      "    0.326953   -0.07052191]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122da9bd30>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[ 0.19886479 -0.09451754  0.16714674 ...  0.06285975  0.15125507\n",
      "   0.13719027]\n",
      " [ 0.16726708 -0.109154...0.25004047  0.01925014\n",
      "   0.07343847]\n",
      " [ 0.22213054 -0.10402475  0.13968094 ... -0.16201541  0.0736068\n",
      "   0.09512947]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.27149478 -0.22902717  0.10713584  0.28047144 -0.04195605  0.28694195\n",
      "  -0.1195965  -0.00371677 -0.2...554823  0.0190662  -0.2317826  -0.07454344\n",
      "   0.1231078  -0.09809937  0.00328175  0.2717451  -0.2506153  -0.2790672 ]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[498.,  85., 903., 203., 581.,  95., 399., 811., 111., 922.,  42.,\n",
      "        117., 523., 372., 108.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cpu-lstm-1000-False-12-34-15-2-1] _____\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cpu(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 2.241672   -1.6450157   0.65092576  0.34930572  0.472102\n",
      "   -1.3942277   1.7014155  -0.36190686 -1.0...    0.13384813  0.0082982\n",
      "    0.5748776   1.0414238  -0.5973798   1.01623    -0.49829817\n",
      "    0.35004577 -0.9053646 ]]])\n",
      "c0_        = needle.Tensor([[[ 2.08495855e-01  3.50687265e-01  4.94712681e-01  4.66394536e-02\n",
      "   -3.62678081e-01  7.73842409e-02 -2... -7.45557323e-02  2.20890660e-02 -6.30412810e-03\n",
      "   -1.55735686e-01  1.15810454e-01  1.37201473e-01  1.16263041e-02]]])\n",
      "device     = cpu(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.1192268e+00  9.4061750e-01  8.5190350e-01 -6.5421063e-01\n",
      "   -5.0592071e-01  4.3438032e-01 -3.00162...661e-02 -1.0579097e+00  4.9945825e-01 -2.8141204e-02\n",
      "    9.1402465e-01  4.2813140e-01  1.6327559e+00  3.6009699e-01]]])\n",
      "h0_        = needle.Tensor([[[ 1.07448988e-01  1.64087951e-01  3.16732496e-01  8.65667500e-03\n",
      "   -2.76472807e-01  4.77725640e-02 -9... -2.93484759e-02  9.37298220e-03 -3.21725151e-03\n",
      "   -7.59183243e-02  5.28639406e-02  8.37467313e-02  6.35254383e-03]]])\n",
      "h_         = (needle.Tensor([[[ 1.07448988e-01  1.64087951e-01  3.16732496e-01  8.65667500e-03\n",
      "   -2.76472807e-01  4.77725640e-02 -...-7.45557323e-02  2.20890660e-02 -6.30412810e-03\n",
      "   -1.55735686e-01  1.15810454e-01  1.37201473e-01  1.16263041e-02]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d989070>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[ 0.19180888  0.0367406   0.07323545 ... -0.26797932  0.1803172\n",
      "  -0.15386292]\n",
      " [ 0.20505868  0.0612318....24191602  0.20691592\n",
      "  -0.14043179]\n",
      " [ 0.19836104  0.04775704  0.079024   ... -0.25722677  0.16393808\n",
      "  -0.15867947]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 2.64195740e-01 -2.57615179e-01  8.75180513e-02  1.18961655e-01\n",
      "  -2.63118058e-01 -4.65729572e-02  1.3...02  1.86812013e-01 -1.22664601e-01  1.28551081e-01\n",
      "  -1.98979795e-01  4.40092012e-02 -1.97357200e-02  2.12596565e-01]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[480., 348., 233., 931., 957., 808., 929., 337., 802., 167., 591.,\n",
      "        638., 659., 313., 473.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cuda-rnn-1-False-1-1-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.8306282]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.94139606]]])\n",
      "h0_        = needle.Tensor([[[-0.66747075]]])\n",
      "h_         = needle.Tensor([[[-0.66747075]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d85feb0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[0.07502709]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.87390643]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m________ test_language_model_implementation[cuda-rnn-1-False-1-1-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.00214505]]\n",
      "\n",
      " [[-1.2615972 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.26975104]]\n",
      "\n",
      " [[ 1.4389945 ]]])\n",
      "h0_        = needle.Tensor([[[0.15911269]]\n",
      "\n",
      " [[0.4350582 ]]])\n",
      "h_         = needle.Tensor([[[0.15911269]]\n",
      "\n",
      " [[0.4350582 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d91ac70>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.37056538]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.05939015]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-rnn-1-False-1-1-15-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.3296318 ]\n",
      "  [ 1.6187917 ]\n",
      "  [ 0.49552777]\n",
      "  [-0.61855245]\n",
      "  [-0.28399822]\n",
      "  [ 1.0622959 ]\n",
      "  [ 0.76...22 ]\n",
      "  [-0.54006284]\n",
      "  [-0.1244092 ]\n",
      "  [-1.3687565 ]\n",
      "  [ 0.07483133]\n",
      "  [-0.3918571 ]\n",
      "  [-0.71652746]\n",
      "  [ 2.0087588 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.323851  ]\n",
      "  [-1.1463938 ]\n",
      "  [-0.53063387]\n",
      "  [-0.1707225 ]\n",
      "  [-0.05465777]\n",
      "  [ 0.8456837 ]\n",
      "  [ 1.50...47 ]\n",
      "  [ 0.8318272 ]\n",
      "  [ 1.7348602 ]\n",
      "  [-1.5667279 ]\n",
      "  [-1.5483322 ]\n",
      "  [ 0.06628756]\n",
      "  [-0.03533422]\n",
      "  [ 2.0457475 ]]])\n",
      "h0_        = needle.Tensor([[[-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01...417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]]])\n",
      "h_         = needle.Tensor([[[-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01...417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]\n",
      "  [-0.01346417]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122ddd8310>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[0.00549114]\n",
      " [0.00549114]\n",
      " [0.00549114]\n",
      " [0.00549114]\n",
      " [0.00549114]\n",
      " [0.00549114]\n",
      " [0.00549114]\n",
      " [0.00549114]\n",
      " [0.00549114]\n",
      " [0.00549114]\n",
      " [0.00549114]\n",
      " [0.00549114]\n",
      " [0.00549114]\n",
      " [0.00549114]\n",
      " [0.00549114]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.6788338]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-rnn-1-False-1-1-15-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.798894  ]\n",
      "  [ 0.83110034]\n",
      "  [ 0.58687234]\n",
      "  [-0.54691213]\n",
      "  [-0.6397531 ]\n",
      "  [-0.7152643 ]\n",
      "  [-0.36...016]\n",
      "  [-0.79628706]\n",
      "  [-0.3817971 ]\n",
      "  [-0.40643242]\n",
      "  [ 1.5100414 ]\n",
      "  [-0.41208857]\n",
      "  [ 0.2469796 ]\n",
      "  [ 2.1718879 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.7509957 ]\n",
      "  [ 0.44079238]\n",
      "  [-0.39042932]\n",
      "  [-1.2170278 ]\n",
      "  [-1.5525209 ]\n",
      "  [-0.022469  ]\n",
      "  [-0.19...23 ]\n",
      "  [-0.27917472]\n",
      "  [ 0.3142235 ]\n",
      "  [-1.2030392 ]\n",
      "  [-0.7217864 ]\n",
      "  [ 0.3352162 ]\n",
      "  [ 1.3753862 ]\n",
      "  [ 0.09471475]]])\n",
      "h0_        = needle.Tensor([[[0.7672499]\n",
      "  [0.7672499]\n",
      "  [0.7672499]\n",
      "  [0.7672499]\n",
      "  [0.7672499]\n",
      "  [0.7672499]\n",
      "  [0.7672499]\n",
      "  [0.7...143]\n",
      "  [0.8967143]\n",
      "  [0.8967143]\n",
      "  [0.8967143]\n",
      "  [0.8967143]\n",
      "  [0.8967143]\n",
      "  [0.8967143]\n",
      "  [0.8967143]\n",
      "  [0.8967143]]])\n",
      "h_         = needle.Tensor([[[0.7672499]\n",
      "  [0.7672499]\n",
      "  [0.7672499]\n",
      "  [0.7672499]\n",
      "  [0.7672499]\n",
      "  [0.7672499]\n",
      "  [0.7672499]\n",
      "  [0.7...143]\n",
      "  [0.8967143]\n",
      "  [0.8967143]\n",
      "  [0.8967143]\n",
      "  [0.8967143]\n",
      "  [0.8967143]\n",
      "  [0.8967143]\n",
      "  [0.8967143]\n",
      "  [0.8967143]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d7fd0a0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.5666163]\n",
      " [-0.5666163]\n",
      " [-0.5666163]\n",
      " [-0.5666163]\n",
      " [-0.5666163]\n",
      " [-0.5666163]\n",
      " [-0.5666163]\n",
      " [-0.5666163]\n",
      " [-0.5666163]\n",
      " [-0.5666163]\n",
      " [-0.5666163]\n",
      " [-0.5666163]\n",
      " [-0.5666163]\n",
      " [-0.5666163]\n",
      " [-0.5666163]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.17609265]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-rnn-1-False-1-34-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.6962698]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[0.68593806]]])\n",
      "h0_        = needle.Tensor([[[-0.99897546]]])\n",
      "h_         = needle.Tensor([[[-0.99897546]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dfcea90>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[1.6854458]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[0.6257377]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-rnn-1-False-1-34-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.46128953]]\n",
      "\n",
      " [[-0.14875878]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.42415956]]\n",
      "\n",
      " [[ 0.5497725 ]]])\n",
      "h0_        = needle.Tensor([[[0.5086352]]\n",
      "\n",
      " [[0.5952436]]])\n",
      "h_         = needle.Tensor([[[0.5086352]]\n",
      "\n",
      " [[0.5952436]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122db19e80>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.14754874]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.9593524]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-rnn-1-False-1-34-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.4132935 ]\n",
      "  [ 1.5004687 ]\n",
      "  [ 0.7811376 ]\n",
      "  [-0.06036689]\n",
      "  [-0.23478018]\n",
      "  [-1.4310644 ]\n",
      "  [-0.14...535]\n",
      "  [-1.8342994 ]\n",
      "  [ 0.8467089 ]\n",
      "  [ 0.38480482]\n",
      "  [ 1.2014885 ]\n",
      "  [-0.7122513 ]\n",
      "  [-0.31375223]\n",
      "  [ 0.6820196 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 6.3709486e-01]\n",
      "  [ 1.0860739e+00]\n",
      "  [-8.7961141e-04]\n",
      "  [ 1.2840123e-01]\n",
      "  [ 8.6999750e-01]\n",
      "  [-1.150...1]\n",
      "  [ 1.9211839e+00]\n",
      "  [-4.3515795e-01]\n",
      "  [ 7.5350195e-01]\n",
      "  [-6.6035978e-02]\n",
      "  [ 3.1801119e-01]\n",
      "  [ 7.9038495e-01]]])\n",
      "h0_        = needle.Tensor([[[0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]]])\n",
      "h_         = needle.Tensor([[[0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]\n",
      "  [0.9967284]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dfa1cd0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.7315371]\n",
      " [-0.7315371]\n",
      " [-0.7315371]\n",
      " [-0.7315371]\n",
      " [-0.7315371]\n",
      " [-0.7315371]\n",
      " [-0.7315371]\n",
      " [-0.7315371]\n",
      " [-0.7315371]\n",
      " [-0.7315371]\n",
      " [-0.7315371]\n",
      " [-0.7315371]\n",
      " [-0.7315371]\n",
      " [-0.7315371]\n",
      " [-0.7315371]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.42332774]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-rnn-1-False-1-34-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.06680518]\n",
      "  [-0.8800858 ]\n",
      "  [-0.35171598]\n",
      "  [-0.19618334]\n",
      "  [ 0.6812288 ]\n",
      "  [-0.7209746 ]\n",
      "  [ 0.20...02 ]\n",
      "  [-0.24503072]\n",
      "  [ 1.3410505 ]\n",
      "  [-1.552993  ]\n",
      "  [ 0.09082337]\n",
      "  [ 1.575004  ]\n",
      "  [-1.2009718 ]\n",
      "  [ 0.4042091 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.285912  ]\n",
      "  [ 1.7155638 ]\n",
      "  [ 1.8157223 ]\n",
      "  [-0.40720442]\n",
      "  [-0.19597124]\n",
      "  [-0.7445137 ]\n",
      "  [ 1.72...557]\n",
      "  [ 0.03431786]\n",
      "  [ 0.61612636]\n",
      "  [-0.05067447]\n",
      "  [-0.32475922]\n",
      "  [ 1.8208793 ]\n",
      "  [-0.3787504 ]\n",
      "  [ 1.0408944 ]]])\n",
      "h0_        = needle.Tensor([[[-0.9016433 ]\n",
      "  [-0.9016433 ]\n",
      "  [-0.9016433 ]\n",
      "  [-0.9016433 ]\n",
      "  [-0.9016433 ]\n",
      "  [-0.9016433 ]\n",
      "  [-0.90...663]\n",
      "  [ 0.86303663]\n",
      "  [ 0.86303663]\n",
      "  [ 0.86303663]\n",
      "  [ 0.86303663]\n",
      "  [ 0.86303663]\n",
      "  [ 0.86303663]\n",
      "  [ 0.86303663]]])\n",
      "h_         = needle.Tensor([[[-0.9016433 ]\n",
      "  [-0.9016433 ]\n",
      "  [-0.9016433 ]\n",
      "  [-0.9016433 ]\n",
      "  [-0.9016433 ]\n",
      "  [-0.9016433 ]\n",
      "  [-0.90...663]\n",
      "  [ 0.86303663]\n",
      "  [ 0.86303663]\n",
      "  [ 0.86303663]\n",
      "  [ 0.86303663]\n",
      "  [ 0.86303663]\n",
      "  [ 0.86303663]\n",
      "  [ 0.86303663]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122df327c0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.0052985]\n",
      " [0.0052985]\n",
      " [0.0052985]\n",
      " [0.0052985]\n",
      " [0.0052985]\n",
      " [0.0052985]\n",
      " [0.0052985]\n",
      " [0.0052985]\n",
      " [0.0052985]\n",
      " [0.0052985]\n",
      " [0.0052985]\n",
      " [0.0052985]\n",
      " [0.0052985]\n",
      " [0.0052985]\n",
      " [0.0052985]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[0.14658664]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-rnn-1-False-12-1-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.43311763 -0.9001869   0.5121274  -0.9614157  -0.3857661\n",
      "   -1.426187   -1.5803194   0.42155027 -0.56305075 -0.9960174\n",
      "   -0.96466243 -1.2075561 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.07081232 -1.1181523  -0.23773582 -0.01825837  2.051079\n",
      "   -1.0351365  -0.06920383 -0.24481793  0.267247   -0.8058907\n",
      "    1.3451494  -0.464721  ]]])\n",
      "h0_        = needle.Tensor([[[ 0.09745868 -0.32277712  0.27766272  0.39166352  0.2726832\n",
      "    0.45243004  0.43676096  0.01205405 -0.18874094 -0.12112951\n",
      "    0.28532836 -0.0552718 ]]])\n",
      "h_         = needle.Tensor([[[ 0.09745868 -0.32277712  0.27766272  0.39166352  0.2726832\n",
      "    0.45243004  0.43676096  0.01205405 -0.18874094 -0.12112951\n",
      "    0.28532836 -0.0552718 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122ddb95b0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.20687315]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.1684625  -0.05045555 -0.10870422 -0.04649141 -0.08361021 -0.07400099\n",
      "  -0.2596058  -0.23183383  0.2...903378  0.02134732  0.11830968  0.02701889\n",
      "   0.19155367  0.28694856 -0.2555847   0.2470563  -0.07304308  0.20545559]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-rnn-1-False-12-1-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.465623   -0.42341915  0.01867505 -0.3844738   1.3027147\n",
      "    1.2956696  -0.22893386  0.05534231  0....656 -0.54862577 -1.087898\n",
      "    0.9836992  -0.17891309 -0.16047911  0.5145984   0.89659214\n",
      "   -0.9496254  -0.27737132]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.41616875  1.4585998  -0.0186072  -0.0557192  -0.32423493\n",
      "   -0.3555217   0.6473574   0.7576286  -0...25  -1.2064707  -0.7136542\n",
      "   -1.6291138  -2.261151    0.7650219  -1.0704271   0.4312838\n",
      "    1.3444822   1.053048  ]]])\n",
      "h0_        = needle.Tensor([[[-0.60949576 -0.15695824 -0.48880813 -0.49745205  0.15046144\n",
      "    0.5552541  -0.6019047  -0.33801612 -0...9  -0.23774776 -0.1338536\n",
      "    0.24473312 -0.2425399   0.5584785   0.21698527 -0.46363387\n",
      "    0.40325963 -0.08189887]]])\n",
      "h_         = needle.Tensor([[[-0.60949576 -0.15695824 -0.48880813 -0.49745205  0.15046144\n",
      "    0.5552541  -0.6019047  -0.33801612 -0...9  -0.23774776 -0.1338536\n",
      "    0.24473312 -0.2425399   0.5584785   0.21698527 -0.46363387\n",
      "    0.40325963 -0.08189887]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122df27730>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.01919948]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.28546485 -0.28023866  0.0446464  -0.119316    0.21158427 -0.1954268\n",
      "   0.28712898  0.05440365 -0.13...538707  0.18541433 -0.21754377 -0.18310058\n",
      "  -0.19002603 -0.1804887   0.18917356  0.04099529 -0.2091879  -0.14528424]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-rnn-1-False-12-1-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 5.12847118e-02 -1.82275522e+00 -3.46965760e-01  3.23226541e-01\n",
      "    1.09996188e+00  1.11774814e+00 -1... -2.82388955e-01  1.30042338e+00  8.25336501e-02\n",
      "   -1.27634442e+00 -1.70152819e+00 -1.30123413e+00 -9.76208568e-01]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.6011561   0.63364553  1.1691425  -1.8175894  -0.03302764\n",
      "   -0.46214178  2.338479   -2.3060415   1...   0.3365401  -0.30662265\n",
      "   -1.7275493  -0.38894573 -0.01866268  0.35610554 -0.43476933\n",
      "   -0.10527928  0.34029222]]])\n",
      "h0_        = needle.Tensor([[[-0.15292628  0.21744637  0.37417734  0.270991    0.38459915\n",
      "   -0.25356433 -0.41071886 -0.17700323  0...4  0.270991    0.38459915\n",
      "   -0.25356433 -0.41071886 -0.17700323  0.3733628   0.25297442\n",
      "    0.09874398  0.19845916]]])\n",
      "h_         = needle.Tensor([[[-0.15292628  0.21744637  0.37417734  0.270991    0.38459915\n",
      "   -0.25356433 -0.41071886 -0.17700323  0...4  0.270991    0.38459915\n",
      "   -0.25356433 -0.41071886 -0.17700323  0.3733628   0.25297442\n",
      "    0.09874398  0.19845916]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d9a1d00>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.16059734]\n",
      " [-0.16059734]\n",
      " [-0.16059734]\n",
      " [-0.16059734]\n",
      " [-0.16059734]\n",
      " [-0.16059734]\n",
      " [-0.16059734]\n",
      " [-0.16059734]\n",
      " [-0.16059734]\n",
      " [-0.16059734]\n",
      " [-0.16059734]\n",
      " [-0.16059734]\n",
      " [-0.16059734]\n",
      " [-0.16059734]\n",
      " [-0.16059734]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 1.50823236e-01  2.12661207e-01  2.61535365e-02 -7.94190913e-02\n",
      "  -1.94659173e-01 -8.80966112e-02  2.1...01  1.76160112e-01 -7.06872866e-02 -2.18236387e-01\n",
      "   3.98076437e-02 -1.54132858e-01 -2.06917122e-01  2.06580117e-01]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-rnn-1-False-12-1-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.35340258  0.20721515  0.8197301   0.9411958   0.02206815\n",
      "   -0.36456925  1.215162   -0.26527333 -0...72  -0.26878226  0.3442191\n",
      "    0.73020333  0.29691392 -1.3001513  -0.09019447  0.9235345\n",
      "    0.6511524  -0.927026  ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.9991545  -2.1067069   0.75017595  0.43066037  0.08206663\n",
      "    0.6117683   0.16105251 -0.35357705  1...8  -0.79501045 -1.8175242\n",
      "   -0.8305693   0.46056598 -1.1534863   0.13242795 -0.63760173\n",
      "    1.5926144   2.7401881 ]]])\n",
      "h0_        = needle.Tensor([[[-0.13674125 -0.10067159 -0.02341209  0.1439826  -0.5332476\n",
      "    0.2599328  -0.33680812 -0.11846959 -0....   0.4861871   0.05891401\n",
      "   -0.34598553  0.17247206  0.45242065 -0.19074549  0.08388635\n",
      "    0.05927802 -0.21259607]]])\n",
      "h_         = needle.Tensor([[[-0.13674125 -0.10067159 -0.02341209  0.1439826  -0.5332476\n",
      "    0.2599328  -0.33680812 -0.11846959 -0....   0.4861871   0.05891401\n",
      "   -0.34598553  0.17247206  0.45242065 -0.19074549  0.08388635\n",
      "    0.05927802 -0.21259607]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122debbfd0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.0432438]\n",
      " [-0.0432438]\n",
      " [-0.0432438]\n",
      " [-0.0432438]\n",
      " [-0.0432438]\n",
      " [-0.0432438]\n",
      " [-0.0432438]\n",
      " [-0.0432438]\n",
      " [-0.0432438]\n",
      " [-0.0432438]\n",
      " [-0.0432438]\n",
      " [-0.0432438]\n",
      " [-0.0432438]\n",
      " [-0.0432438]\n",
      " [-0.0432438]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.01444871 -0.12262548 -0.18469337 -0.02079541 -0.11493532  0.20433329\n",
      "   0.11892578  0.12606356 -0.2...802081 -0.09037383 -0.00509178 -0.01518998\n",
      "  -0.09155697 -0.00759296  0.2835748   0.0089371  -0.0875725  -0.09980756]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-rnn-1-False-12-34-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.1999017  -1.1685243   0.4825386   0.66047287  0.9020349\n",
      "   -0.38234022  0.28192946 -0.07139707 -0.31437114  2.1918428\n",
      "   -0.2776457  -0.9002702 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.9760734  -1.2026215   0.7190208   0.92777026 -0.42837033\n",
      "    0.33125     1.3622699   0.77215636 -0.05291558 -0.10517642\n",
      "    0.15022054  0.10348608]]])\n",
      "h0_        = needle.Tensor([[[ 0.78817356 -0.88336706 -0.5534066  -0.51483154 -0.9010302\n",
      "   -0.11468454 -0.28704455 -0.10408976  0.83530533 -0.3429913\n",
      "    0.31362993 -0.637648  ]]])\n",
      "h_         = needle.Tensor([[[ 0.78817356 -0.88336706 -0.5534066  -0.51483154 -0.9010302\n",
      "   -0.11468454 -0.28704455 -0.10408976  0.83530533 -0.3429913\n",
      "    0.31362993 -0.637648  ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122da460a0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.19389208]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 1.78170905e-01 -2.56010771e-01  1.60330310e-01  2.41333008e-01\n",
      "   2.22975686e-01 -2.68025577e-01 -2.1...02 -1.13741472e-01 -2.68977523e-01 -1.84475347e-01\n",
      "   1.04341447e-01 -7.69838840e-02 -1.90977678e-01 -2.60050714e-01]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-rnn-1-False-12-34-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.06505891 -0.5816848   0.42995426  0.6548285   0.20171751\n",
      "    0.9063035  -0.62474585 -0.1823739   1...168 -0.248391    0.6306389\n",
      "    1.4654213   1.8448615   2.5479054   3.181738   -1.6331854\n",
      "    0.3882873   0.18653809]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.8418932   0.46945933  1.3429673  -0.6122533  -2.02624\n",
      "    1.2233632  -1.0920364  -0.538909    1.28...8  -0.28899962 -0.52166474\n",
      "    0.72078854  0.47868976  0.79657865  0.4080112  -0.8326603\n",
      "   -1.8114277  -0.42203882]]])\n",
      "h0_        = needle.Tensor([[[-0.13417546 -0.8220561  -0.99656177 -0.84174716 -0.7633223\n",
      "    0.99303466  0.02215089 -0.66957116 -0....   0.10590018 -0.13841318\n",
      "   -0.00844777 -0.4122655   0.7592084  -0.09964945 -0.73590535\n",
      "    0.41166303 -0.4075139 ]]])\n",
      "h_         = needle.Tensor([[[-0.13417546 -0.8220561  -0.99656177 -0.84174716 -0.7633223\n",
      "    0.99303466  0.02215089 -0.66957116 -0....   0.10590018 -0.13841318\n",
      "   -0.00844777 -0.4122655   0.7592084  -0.09964945 -0.73590535\n",
      "    0.41166303 -0.4075139 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dfda2e0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.2586357]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.02017247 -0.1629555   0.20020865 -0.06884705 -0.11336875 -0.17295767\n",
      "   0.08935964 -0.251151   -0.0...64954  -0.27193466  0.1422722   0.25020164\n",
      "  -0.20455371 -0.07549601 -0.10675371 -0.27346185 -0.22414866  0.16581066]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-rnn-1-False-12-34-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.30810905 -1.3134834   1.1765579  -0.40347964  2.088096\n",
      "    0.14403215 -1.4591942  -0.06021987  0.1...8    0.8548557   0.23133083\n",
      "   -1.2616848   0.9713349   0.5484222   1.1903455   0.529083\n",
      "    1.0980269  -1.2787318 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.0767266  -1.0396546  -0.65991294  0.9005208  -0.00376946\n",
      "   -1.5620102  -0.68324715  1.1263589  -0...48  -0.34500805 -1.1130458\n",
      "   -0.63332635 -0.19050287 -1.3323629  -1.1247569  -0.4759704\n",
      "    0.99204016 -1.6728058 ]]])\n",
      "h0_        = needle.Tensor([[[-0.32285538  0.7054394  -0.874673    0.31705114  0.8329237\n",
      "   -0.5468279  -0.203307   -0.40647563  0....    0.31705114  0.8329237\n",
      "   -0.5468279  -0.203307   -0.40647563  0.44088498 -0.88766515\n",
      "    0.23402137  0.00126937]]])\n",
      "h_         = needle.Tensor([[[-0.32285538  0.7054394  -0.874673    0.31705114  0.8329237\n",
      "   -0.5468279  -0.203307   -0.40647563  0....    0.31705114  0.8329237\n",
      "   -0.5468279  -0.203307   -0.40647563  0.44088498 -0.88766515\n",
      "    0.23402137  0.00126937]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dbdf8b0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[0.7258113]\n",
      " [0.7258113]\n",
      " [0.7258113]\n",
      " [0.7258113]\n",
      " [0.7258113]\n",
      " [0.7258113]\n",
      " [0.7258113]\n",
      " [0.7258113]\n",
      " [0.7258113]\n",
      " [0.7258113]\n",
      " [0.7258113]\n",
      " [0.7258113]\n",
      " [0.7258113]\n",
      " [0.7258113]\n",
      " [0.7258113]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.18236315 -0.28033903  0.08148023  0.01049509 -0.16571386 -0.17412634\n",
      "  -0.16654012  0.25686005 -0.1...90254   0.23718135 -0.27896795  0.11647984\n",
      "  -0.28217906  0.20658608 -0.25610632  0.07771464  0.17244774 -0.09036036]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-rnn-1-False-12-34-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.86486959e-01 -5.22002876e-01 -1.90048024e-01  3.46362734e+00\n",
      "   -7.29832590e-01 -8.10161412e-01  1...  8.94261181e-01 -4.85267937e-01  6.71761990e-01\n",
      "   -2.53992140e-01  6.89140737e-01 -6.20774508e-01  1.88305870e-01]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 9.2838371e-01  1.8972339e-02 -4.5348364e-01 -1.2141746e+00\n",
      "    2.7627864e-01  1.2945593e-03  1.18790...387e+00  1.2548579e+00  9.6346492e-01 -1.0062275e+00\n",
      "    1.5170859e+00  1.7149696e+00 -3.5276732e-01 -2.4295621e+00]]])\n",
      "h0_        = needle.Tensor([[[ 0.04450003 -0.69543517  0.93250513  0.6556764  -0.7812254\n",
      "    0.63754076  0.18317406  0.02161032  0....074  0.05219356 -0.4486422\n",
      "    0.34950045 -0.25991586  0.3878335   0.5202354  -0.5646024\n",
      "    0.38590816 -0.11010896]]])\n",
      "h_         = needle.Tensor([[[ 0.04450003 -0.69543517  0.93250513  0.6556764  -0.7812254\n",
      "    0.63754076  0.18317406  0.02161032  0....074  0.05219356 -0.4486422\n",
      "    0.34950045 -0.25991586  0.3878335   0.5202354  -0.5646024\n",
      "    0.38590816 -0.11010896]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dbdd2e0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.2403426]\n",
      " [0.2403426]\n",
      " [0.2403426]\n",
      " [0.2403426]\n",
      " [0.2403426]\n",
      " [0.2403426]\n",
      " [0.2403426]\n",
      " [0.2403426]\n",
      " [0.2403426]\n",
      " [0.2403426]\n",
      " [0.2403426]\n",
      " [0.2403426]\n",
      " [0.2403426]\n",
      " [0.2403426]\n",
      " [0.2403426]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.05058904  0.1787839   0.13634005 -0.05814183  0.2557097   0.00355425\n",
      "  -0.27101755 -0.191644    0.1...409565  0.27827054 -0.22728775 -0.25574532\n",
      "  -0.18128689  0.26096636  0.24211207  0.1798549   0.21016671  0.26145414]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-rnn-1000-False-1-1-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[1.09211]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.79807913]]])\n",
      "h0_        = needle.Tensor([[[-0.34105057]]])\n",
      "h_         = needle.Tensor([[[-0.34105057]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122ddeeac0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[ 2.22578168e-01  5.26941657e-01  7.68156886e-01 -7.84020066e-01\n",
      "   6.65771663e-01 -5.69696128e-01  9.5...01 -8.07996631e-01  9.71366644e-01  8.29019547e-01\n",
      "  -5.59425354e-01  5.20674706e-01 -4.79538769e-01 -6.53277278e-01]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[0.9947536]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[885.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-rnn-1000-False-1-1-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.5103288]]\n",
      "\n",
      " [[-1.3161839]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.69503033]]\n",
      "\n",
      " [[-1.7293751 ]]])\n",
      "h0_        = needle.Tensor([[[0.04163367]]\n",
      "\n",
      " [[0.9498707 ]]])\n",
      "h_         = needle.Tensor([[[0.04163367]]\n",
      "\n",
      " [[0.9498707 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122ddb3610>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-1.24791479e+00 -5.30695379e-01 -8.14381659e-01 -3.43023837e-01\n",
      "  -1.88267231e-02  1.05300212e+00  2.8...02 -5.13631761e-01  5.78820467e-01 -1.10855162e+00\n",
      "   1.60006332e+00 -2.86675036e-01  1.01695514e+00  2.15940088e-01]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.16074106]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[985.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-rnn-1000-False-1-1-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.719078  ]\n",
      "  [-0.5688927 ]\n",
      "  [-0.8327531 ]\n",
      "  [-0.5079215 ]\n",
      "  [-2.3916147 ]\n",
      "  [-0.47807136]\n",
      "  [ 0.37...14 ]\n",
      "  [ 0.01027126]\n",
      "  [ 0.5250566 ]\n",
      "  [ 1.7241498 ]\n",
      "  [-0.25115263]\n",
      "  [ 0.33670855]\n",
      "  [-1.1655124 ]\n",
      "  [-1.2696726 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-2.0930412 ]\n",
      "  [ 2.35235   ]\n",
      "  [-0.19976161]\n",
      "  [-1.0772634 ]\n",
      "  [ 0.822141  ]\n",
      "  [ 0.98917717]\n",
      "  [ 0.15...95 ]\n",
      "  [ 0.50065374]\n",
      "  [ 1.0891174 ]\n",
      "  [-1.0411205 ]\n",
      "  [-0.6750241 ]\n",
      "  [-0.2718388 ]\n",
      "  [ 2.7441409 ]\n",
      "  [ 0.5333341 ]]])\n",
      "h0_        = needle.Tensor([[[-0.40161097]\n",
      "  [ 0.76207817]\n",
      "  [ 0.3170863 ]\n",
      "  [ 0.61579335]\n",
      "  [ 0.9699805 ]\n",
      "  [ 0.94671166]\n",
      "  [-0.30...5  ]\n",
      "  [ 0.8674181 ]\n",
      "  [-0.7974299 ]\n",
      "  [ 0.82758135]\n",
      "  [ 0.8620412 ]\n",
      "  [ 0.93167937]\n",
      "  [ 0.99154806]\n",
      "  [ 0.98078793]]])\n",
      "h_         = needle.Tensor([[[-0.40161097]\n",
      "  [ 0.76207817]\n",
      "  [ 0.3170863 ]\n",
      "  [ 0.61579335]\n",
      "  [ 0.9699805 ]\n",
      "  [ 0.94671166]\n",
      "  [-0.30...5  ]\n",
      "  [ 0.8674181 ]\n",
      "  [-0.7974299 ]\n",
      "  [ 0.82758135]\n",
      "  [ 0.8620412 ]\n",
      "  [ 0.93167937]\n",
      "  [ 0.99154806]\n",
      "  [ 0.98078793]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dc098e0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[ 0.2264469  -0.9157759  -0.4151481  ... -0.13450065  0.71788824\n",
      "   0.31500313]\n",
      " [ 1.3065827   0.234964...-1.1180274   1.5097084\n",
      "   1.5154784 ]\n",
      " [ 1.5095891   0.45124108 -0.25498375 ... -1.1104312   1.5035927\n",
      "   1.5062065 ]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.70413077]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[660.,  90.,  56., 387., 442., 154.,  81., 182., 441., 595.,  26.,\n",
      "        227., 654., 625., 910.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-rnn-1000-False-1-1-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.10446992]\n",
      "  [ 0.1224308 ]\n",
      "  [ 0.750903  ]\n",
      "  [ 0.09987859]\n",
      "  [-1.5670862 ]\n",
      "  [ 1.3950077 ]\n",
      "  [-2.66...737]\n",
      "  [-0.43730432]\n",
      "  [-0.5592252 ]\n",
      "  [-1.5868963 ]\n",
      "  [-0.62476605]\n",
      "  [-0.37195858]\n",
      "  [ 1.1345567 ]\n",
      "  [ 2.0102763 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.27102178]\n",
      "  [-0.49176902]\n",
      "  [-1.0655701 ]\n",
      "  [-0.13077417]\n",
      "  [-1.1243649 ]\n",
      "  [-0.43671337]\n",
      "  [-0.23...36 ]\n",
      "  [ 0.00796217]\n",
      "  [ 0.6705948 ]\n",
      "  [ 0.1611692 ]\n",
      "  [-1.3560649 ]\n",
      "  [-0.01230881]\n",
      "  [-0.24454221]\n",
      "  [ 1.4438348 ]]])\n",
      "h0_        = needle.Tensor([[[0.9553827 ]\n",
      "  [0.9799987 ]\n",
      "  [0.97384775]\n",
      "  [0.99294776]\n",
      "  [0.88949406]\n",
      "  [0.95085824]\n",
      "  [0.99838424]...0.20746881]\n",
      "  [0.22233234]\n",
      "  [0.22458032]\n",
      "  [0.21964549]\n",
      "  [0.22199985]\n",
      "  [0.21920763]\n",
      "  [0.21829732]\n",
      "  [0.22417851]]])\n",
      "h_         = needle.Tensor([[[0.9553827 ]\n",
      "  [0.9799987 ]\n",
      "  [0.97384775]\n",
      "  [0.99294776]\n",
      "  [0.88949406]\n",
      "  [0.95085824]\n",
      "  [0.99838424]...0.20746881]\n",
      "  [0.22233234]\n",
      "  [0.22458032]\n",
      "  [0.21964549]\n",
      "  [0.22199985]\n",
      "  [0.21920763]\n",
      "  [0.21829732]\n",
      "  [0.22417851]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122de99b80>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[ 0.18856692 -1.0339062   0.7935038  ... -0.14893259  0.19825989\n",
      "  -1.0218501 ]\n",
      " [ 0.18817604 -1.034300...0.15175764  0.1963624\n",
      "  -1.020702  ]\n",
      " [ 0.188135   -1.0343424   0.7934614  ... -0.14832596  0.19866733\n",
      "  -1.0220966 ]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.04252006]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[791., 723., 864., 612., 369., 667., 969.,  29.,  68.,  61., 212.,\n",
      "        232., 209., 974., 330.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-rnn-1000-False-1-34-1-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.5218616]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[0.01987375]]])\n",
      "h0_        = needle.Tensor([[[0.8500293]]])\n",
      "h_         = needle.Tensor([[[0.8500293]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d8cc6a0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[ 3.26358974e-01  4.12092388e-01 -6.15407288e-01 -9.94369864e-01\n",
      "  -1.47292838e-01  2.35352993e-01  2.3...01 -3.01489085e-01 -4.90472138e-01  7.93816626e-01\n",
      "  -8.43266964e-01 -2.69753784e-01 -6.63712621e-01  4.93018121e-01]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[0.7107829]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[244.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-rnn-1000-False-1-34-1-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[1.063765  ]]\n",
      "\n",
      " [[0.42215642]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.09402225]]\n",
      "\n",
      " [[-0.75726515]]])\n",
      "h0_        = needle.Tensor([[[0.9999823]]\n",
      "\n",
      " [[0.571084 ]]])\n",
      "h_         = needle.Tensor([[[0.9999823]]\n",
      "\n",
      " [[0.571084 ]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122df1a370>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-4.40732449e-01 -6.36169434e-01 -2.30722710e-01 -4.91843134e-01\n",
      "   7.48047829e-01  1.43142939e+00 -1.0...01 -4.83209908e-01 -9.80711997e-01 -7.72244453e-01\n",
      "   4.53557968e-01 -1.35640717e+00  4.53123420e-01  9.43075299e-01]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[0.9930369]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[150.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-rnn-1000-False-1-34-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.4266834 ]\n",
      "  [-1.0125366 ]\n",
      "  [ 1.6104017 ]\n",
      "  [-1.5148375 ]\n",
      "  [-0.6591183 ]\n",
      "  [-0.08372437]\n",
      "  [-0.73...795]\n",
      "  [ 0.18935749]\n",
      "  [ 0.58058566]\n",
      "  [-1.498264  ]\n",
      "  [-1.3652824 ]\n",
      "  [-0.54210395]\n",
      "  [ 1.4177713 ]\n",
      "  [-2.1133456 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-2.0528386e+00]\n",
      "  [ 1.0574380e+00]\n",
      "  [-9.2119747e-01]\n",
      "  [-1.2388990e+00]\n",
      "  [-1.4104801e+00]\n",
      "  [ 1.098...1]\n",
      "  [ 9.7752884e-02]\n",
      "  [-1.3822283e+00]\n",
      "  [-2.1841240e+00]\n",
      "  [ 1.2336777e+00]\n",
      "  [-1.6145551e-01]\n",
      "  [-1.3144275e+00]]])\n",
      "h0_        = needle.Tensor([[[ 0.9870071 ]\n",
      "  [ 0.9999455 ]\n",
      "  [ 0.99292165]\n",
      "  [-0.9701888 ]\n",
      "  [-0.994269  ]\n",
      "  [ 0.99881995]\n",
      "  [ 0.61...096]\n",
      "  [-0.32981855]\n",
      "  [-0.994269  ]\n",
      "  [ 0.99999994]\n",
      "  [ 0.99951625]\n",
      "  [-0.21837251]\n",
      "  [-0.48709542]\n",
      "  [ 0.97666746]]])\n",
      "h_         = needle.Tensor([[[ 0.9870071 ]\n",
      "  [ 0.9999455 ]\n",
      "  [ 0.99292165]\n",
      "  [-0.9701888 ]\n",
      "  [-0.994269  ]\n",
      "  [ 0.99881995]\n",
      "  [ 0.61...096]\n",
      "  [-0.32981855]\n",
      "  [-0.994269  ]\n",
      "  [ 0.99999994]\n",
      "  [ 0.99951625]\n",
      "  [-0.21837251]\n",
      "  [-0.48709542]\n",
      "  [ 0.97666746]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122de8c2b0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[ 0.2173096   0.42405975 -0.39351058 ...  1.4142706  -1.2919257\n",
      "   0.9712261 ]\n",
      " [ 0.22842062  0.4368642... 0.44292104  0.01079598\n",
      "   0.85802203]\n",
      " [ 0.20843035  0.41382724 -0.39952344 ...  1.4074574  -1.282788\n",
      "   0.9704321 ]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[0.4182733]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[666., 851., 142., 947., 739., 504., 353., 929., 291., 739., 590.,\n",
      "        329., 856., 546., 799.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-rnn-1000-False-1-34-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.62447995]\n",
      "  [ 0.05301731]\n",
      "  [-0.11985818]\n",
      "  [-1.2735823 ]\n",
      "  [-0.72873986]\n",
      "  [-1.218037  ]\n",
      "  [ 0.62...98 ]\n",
      "  [ 0.90877604]\n",
      "  [ 0.3961575 ]\n",
      "  [ 0.12619859]\n",
      "  [-0.21512793]\n",
      "  [-0.3005419 ]\n",
      "  [-1.0832096 ]\n",
      "  [ 0.62267953]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.9456914 ]\n",
      "  [-0.35330385]\n",
      "  [ 1.173017  ]\n",
      "  [-0.3879896 ]\n",
      "  [ 0.5267783 ]\n",
      "  [ 1.2780995 ]\n",
      "  [ 0.64...5  ]\n",
      "  [-0.8887074 ]\n",
      "  [-0.5108041 ]\n",
      "  [ 1.5080289 ]\n",
      "  [-0.23950809]\n",
      "  [-1.4083158 ]\n",
      "  [ 1.2932988 ]\n",
      "  [ 0.13921814]]])\n",
      "h0_        = needle.Tensor([[[ 0.6349509 ]\n",
      "  [-0.9999984 ]\n",
      "  [ 0.02952897]\n",
      "  [ 0.9999335 ]\n",
      "  [ 0.9996577 ]\n",
      "  [-0.8755657 ]\n",
      "  [-0.80...515]\n",
      "  [ 0.8533263 ]\n",
      "  [ 0.8534165 ]\n",
      "  [ 0.853423  ]\n",
      "  [ 0.8180286 ]\n",
      "  [ 0.8524011 ]\n",
      "  [ 0.8438635 ]\n",
      "  [ 0.84661174]]])\n",
      "h_         = needle.Tensor([[[ 0.6349509 ]\n",
      "  [-0.9999984 ]\n",
      "  [ 0.02952897]\n",
      "  [ 0.9999335 ]\n",
      "  [ 0.9996577 ]\n",
      "  [-0.8755657 ]\n",
      "  [-0.80...515]\n",
      "  [ 0.8533263 ]\n",
      "  [ 0.8534165 ]\n",
      "  [ 0.853423  ]\n",
      "  [ 0.8180286 ]\n",
      "  [ 0.8524011 ]\n",
      "  [ 0.8438635 ]\n",
      "  [ 0.84661174]]])\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dfe3d60>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-1.0319941   0.08456874  0.6386366  ... -0.62564135 -0.7235123\n",
      "  -0.88796175]\n",
      " [-0.9602059  -0.1979122...0.61337185 -0.71554303\n",
      "  -0.8977618 ]\n",
      " [-1.0396461   0.11467898  0.6628269  ... -0.61219    -0.7147753\n",
      "  -0.89870584]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[0.9444996]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[581., 538.,  59., 992., 248., 394., 697., 415., 132.,  46., 567.,\n",
      "        766., 883., 560., 470.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-rnn-1000-False-12-1-1-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.1812947   0.38463554  0.9388203   0.6069732  -0.3742485\n",
      "   -2.2684298   0.7598397   0.5709231  -0.8606868  -0.36325267\n",
      "    0.23364419  0.35560203]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.5924602   2.348809    0.05773383 -0.29231665  0.555369\n",
      "    1.371495    0.6627643   0.92134833  1.6213737  -0.02291877\n",
      "   -1.2818562  -1.3321319 ]]])\n",
      "h0_        = needle.Tensor([[[ 0.0860373  -0.17738615 -0.0595277   0.3086545   0.43532383\n",
      "   -0.34100792  0.22786312 -0.26862854  0.2761405  -0.16697909\n",
      "    0.05676315 -0.10787087]]])\n",
      "h_         = needle.Tensor([[[ 0.0860373  -0.17738615 -0.0595277   0.3086545   0.43532383\n",
      "   -0.34100792  0.22786312 -0.26862854  0.2761405  -0.16697909\n",
      "    0.05676315 -0.10787087]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dfda790>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-2.62572885e-01 -8.04249570e-03 -4.97592986e-03  1.58735663e-01\n",
      "  -7.58018374e-01  1.31670564e-01 -1.4...01 -8.40454549e-02  1.43409491e-01 -2.63248920e-01\n",
      "   8.25276002e-02  6.52292222e-02  1.38007730e-01 -2.65395582e-01]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.28022772  0.24776155  0.09099411 -0.09612525 -0.2284375   0.06236617\n",
      "  -0.00485685  0.24477789 -0.0...065635 -0.05457329 -0.12655616 -0.14373046\n",
      "  -0.21054587 -0.26302528  0.28360274 -0.0933961   0.09501335 -0.16170233]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[889.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-rnn-1000-False-12-1-1-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.8565954   1.2939887   1.1340977   0.7354792  -0.01190864\n",
      "    0.23159161 -0.5985389  -1.1287043  -1...557   0.42619994 -1.07475\n",
      "    0.18229103 -0.06151382  1.3652536   0.7234891   0.29640064\n",
      "    0.9504601  -1.1751238 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.97484326 -1.0623581   1.4823186  -0.8995407   0.6676505\n",
      "   -0.1580958  -0.05381446  1.1348977  -1....6  -1.0476573   2.4693942\n",
      "    1.2026256  -0.99750626  1.156244   -1.3330417  -0.45172834\n",
      "   -0.50907314 -0.19327542]]])\n",
      "h0_        = needle.Tensor([[[ 0.2186131  -0.04844877 -0.09635929  0.33074224  0.1754728\n",
      "   -0.41352507 -0.1275268  -0.09493301 -0....68 -0.24084412  0.0295594\n",
      "    0.26906377  0.00496304  0.31551683 -0.44291383  0.06841896\n",
      "   -0.15062784  0.21120644]]])\n",
      "h_         = needle.Tensor([[[ 0.2186131  -0.04844877 -0.09635929  0.33074224  0.1754728\n",
      "   -0.41352507 -0.1275268  -0.09493301 -0....68 -0.24084412  0.0295594\n",
      "    0.26906377  0.00496304  0.31551683 -0.44291383  0.06841896\n",
      "   -0.15062784  0.21120644]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122df2f6a0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-3.53871942e-01  1.94459975e-01  8.53627175e-02  2.98147947e-02\n",
      "  -1.33743584e-01 -4.56745028e-01 -2.2...02  2.81883299e-01 -5.17200530e-01  2.71201879e-01\n",
      "   1.33242637e-01 -2.57307589e-02  9.28734541e-02  2.51034409e-01]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.01848768  0.14316803 -0.19015682  0.08392248  0.04113333  0.0163951\n",
      "   0.24393743 -0.24011597 -0.05...176578  0.20966518  0.13712926 -0.11474499\n",
      "   0.04345443  0.05369669  0.0811765  -0.13227558  0.17071651  0.23985459]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[248.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-rnn-1000-False-12-1-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-4.2935514e-01 -3.8691199e-01 -1.0436629e+00 -4.4820970e-01\n",
      "    7.2543666e-02  8.7720686e-01  1.65001...054e-01 -1.4973661e-01 -2.3030396e+00 -1.9151466e-01\n",
      "   -9.7699040e-01  6.9825149e-01 -1.4584841e+00  1.8918747e-01]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.11422434 -0.8966463  -0.01612271 -0.2802945  -0.19489686\n",
      "   -1.2518972  -0.41773018 -0.8360181   0...666 -0.11375523  1.2362124\n",
      "    1.3771517   1.2807093  -0.04183954  1.5012022  -0.7640815\n",
      "    0.59638494  0.3048058 ]]])\n",
      "h0_        = needle.Tensor([[[ 0.35541055  0.13782412  0.2065282  -0.42326942 -0.16408955\n",
      "   -0.48436242  0.2879982  -0.55328333  0...  -0.49855888 -0.18385333\n",
      "   -0.59082323  0.294352   -0.6587846  -0.00994946 -0.20262268\n",
      "   -0.39959538  0.23317331]]])\n",
      "h_         = needle.Tensor([[[ 0.35541055  0.13782412  0.2065282  -0.42326942 -0.16408955\n",
      "   -0.48436242  0.2879982  -0.55328333  0...  -0.49855888 -0.18385333\n",
      "   -0.59082323  0.294352   -0.6587846  -0.00994946 -0.20262268\n",
      "   -0.39959538  0.23317331]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dd22a60>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[ 0.38096106 -0.40102506 -0.01480514 ...  0.12244608  0.19397402\n",
      "  -0.21561691]\n",
      " [ 0.20619105 -0.304861....1367077   0.07931729\n",
      "  -0.19053906]\n",
      " [ 0.43173486 -0.42267162 -0.02499199 ...  0.11822891  0.25536323\n",
      "  -0.22048756]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.18173476  0.1304931   0.15677635  0.07058709  0.15010917  0.06591493\n",
      "  -0.14640374 -0.18223846  0.0...600074  0.20376396 -0.11943556  0.23999625\n",
      "  -0.07450869  0.04290164  0.21594135  0.2815949  -0.07737422 -0.02162039]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[995., 503., 927., 630., 156., 892., 581., 869.,  71., 525., 692.,\n",
      "        423., 888., 265.,  63.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-rnn-1000-False-12-1-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.9825016  -0.7597363  -0.14429902 -1.0883878  -0.6447864\n",
      "    0.62574196 -0.79230255 -0.47225264 -0....899  0.81741697 -0.38233176\n",
      "    1.2136532  -0.27023396  0.1562703   0.34674186  0.488962\n",
      "    0.8224359  -0.41049066]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-5.70211746e-02 -3.97634685e-01  1.53912921e-02  4.87331152e-01\n",
      "   -1.49027407e+00  4.39932466e-01  5...  7.37406611e-02 -2.38486338e+00  1.13855159e+00\n",
      "   -5.89516044e-01 -3.63912791e-01  7.98470497e-01 -1.22542143e+00]]])\n",
      "h0_        = needle.Tensor([[[ 4.49417114e-01 -1.47531509e-01  1.29497528e-01 -1.12983599e-01\n",
      "   -1.70550033e-01 -1.79506868e-01  3... -2.34605700e-01 -2.70334870e-01 -1.17742166e-01\n",
      "   -2.27731198e-01  3.79311383e-01 -3.10105607e-02 -4.18395758e-01]]])\n",
      "h_         = needle.Tensor([[[ 4.49417114e-01 -1.47531509e-01  1.29497528e-01 -1.12983599e-01\n",
      "   -1.70550033e-01 -1.79506868e-01  3... -2.34605700e-01 -2.70334870e-01 -1.17742166e-01\n",
      "   -2.27731198e-01  3.79311383e-01 -3.10105607e-02 -4.18395758e-01]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d9b77c0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[ 0.06324625 -0.11958067 -0.53736365 ... -0.6466726   0.00425872\n",
      "  -0.0063602 ]\n",
      " [-0.06831273 -0.113316....6642643   0.04609612\n",
      "  -0.12226216]\n",
      " [ 0.03051683 -0.11987931 -0.5180029  ... -0.65407085  0.01845476\n",
      "  -0.04573455]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 0.24198219  0.2115795  -0.12513098 -0.26970243  0.22675373  0.0892636\n",
      "  -0.26770663 -0.09765305  0.25...011714  0.0684775  -0.01005008  0.13324808\n",
      "   0.23099656  0.17577147  0.0382213   0.02683375  0.02888249  0.17539713]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[102., 966., 133., 731., 373., 453., 953., 993.,   9., 292.,  79.,\n",
      "        781., 746., 800., 741.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-rnn-1000-False-12-34-1-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.3284967  -0.76126784 -1.3715725  -2.1508358  -1.4665205\n",
      "   -0.06801768 -2.1755106  -0.34083498  0.98491746  1.7333695\n",
      "   -1.2865717  -0.45000076]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-0.3559307  -1.419147    0.7364584  -1.1211662  -0.9891444\n",
      "   -2.5258899   1.6418427   2.0361273   1.4179021  -0.09235936\n",
      "    1.0607973   0.367909  ]]])\n",
      "h0_        = needle.Tensor([[[ 0.720372    0.04177477  0.18788616  0.87398803 -0.22374883\n",
      "   -0.8297874  -0.11671085  0.24386916 -0.8988209   0.13655339\n",
      "   -0.902021    0.02103874]]])\n",
      "h_         = needle.Tensor([[[ 0.720372    0.04177477  0.18788616  0.87398803 -0.22374883\n",
      "   -0.8297874  -0.11671085  0.24386916 -0.8988209   0.13655339\n",
      "   -0.902021    0.02103874]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dec6520>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[ 1.81545138e-01  4.22854275e-01 -2.18590304e-01  3.18555415e-01\n",
      "   2.85016477e-01 -1.75323069e-01 -1.9...01  9.01295841e-02 -7.89593875e-01  8.41523260e-02\n",
      "  -1.70090839e-01 -3.75021219e-01  1.17415503e-01  2.86688000e-01]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.24126469  0.1400541  -0.22202927 -0.26907367 -0.18922696 -0.2821448\n",
      "   0.11492991  0.23683691  0.28...491     0.06494191  0.07573958  0.06890208\n",
      "   0.11763701  0.22177191 -0.16239682 -0.27704147  0.10474558  0.11563496]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[525.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-rnn-1000-False-12-34-1-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.01881425  1.0010207   1.1517853   1.7344444   1.5100784\n",
      "   -0.2312179   0.760626    0.6173845  -0....18   1.5133835  -1.5282851\n",
      "    1.0176604  -0.21096405  0.07279238  0.13608745 -1.3757678\n",
      "    0.29574525 -1.0466955 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.51703656 -0.06138618 -0.47396332 -0.3577757   0.5611862\n",
      "   -0.9902383  -1.8338159  -0.4445337  -0....8  -0.14090021 -0.7984382\n",
      "    0.5643882  -0.47679144  2.1893418  -0.4299619  -0.04768818\n",
      "   -1.7191297   1.4976356 ]]])\n",
      "h0_        = needle.Tensor([[[-0.4662294  -0.7615324  -0.04116732  0.31459257 -0.9423368\n",
      "   -0.5079227   0.8833392  -0.6376115  -0....5 -0.5740621   0.47947574\n",
      "    0.5712596  -0.598748    0.15768768  0.22624096 -0.11614234\n",
      "    0.16116154  0.2867114 ]]])\n",
      "h_         = needle.Tensor([[[-0.4662294  -0.7615324  -0.04116732  0.31459257 -0.9423368\n",
      "   -0.5079227   0.8833392  -0.6376115  -0....5 -0.5740621   0.47947574\n",
      "    0.5712596  -0.598748    0.15768768  0.22624096 -0.11614234\n",
      "    0.16116154  0.2867114 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122def8760>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[ 3.44481021e-02  8.61099660e-02 -3.15820366e-01  4.89109814e-01\n",
      "   4.09291267e-01  5.68384752e-02 -2.8...01 -5.00109673e-01  8.28090310e-02  2.23468691e-02\n",
      "   1.96092933e-01 -6.43080473e-02  9.72225666e-02  7.75716156e-02]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.24840596 -0.17911582  0.25537208  0.2178694  -0.14580037  0.08639562\n",
      "   0.27720112 -0.00763264 -0.2...541252  0.13741505 -0.16249716  0.10401314\n",
      "   0.28528935 -0.04036422 -0.19425422 -0.13010669  0.16875593 -0.06224597]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[766.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-rnn-1000-False-12-34-15-1-1] _____\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.424918    0.8539139  -0.65980315 -0.3414519   0.8110507\n",
      "    1.3861054   0.05879166  0.5977891  -2....463   2.1841216  -1.250285\n",
      "    0.9755161   0.3292347   0.84419155  1.5821127  -0.2824196\n",
      "   -0.7150136  -2.1515028 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-2.3536549e+00 -4.5430668e-02  5.9354031e-01  1.5408456e+00\n",
      "   -1.5357645e-01 -3.6651859e-01 -2.24789...098e-01  1.2431856e+00 -1.0540766e+00  2.2792444e-01\n",
      "    1.7609337e-01  5.9786059e-02 -8.3743465e-01  4.1490716e-01]]])\n",
      "h0_        = needle.Tensor([[[-0.9552371   0.065445    0.0799595  -0.78309023  0.9397366\n",
      "    0.8662336  -0.39251602  0.745685   -0....13  0.80782646  0.88002545\n",
      "    0.86718285 -0.8717386  -0.4905225   0.8908213   0.8878583\n",
      "   -0.42396778  0.3036544 ]]])\n",
      "h_         = needle.Tensor([[[-0.9552371   0.065445    0.0799595  -0.78309023  0.9397366\n",
      "    0.8662336  -0.39251602  0.745685   -0....13  0.80782646  0.88002545\n",
      "    0.86718285 -0.8717386  -0.4905225   0.8908213   0.8878583\n",
      "   -0.42396778  0.3036544 ]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122df4c610>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[ 0.31542605  0.80885655  0.3045649  ...  0.8682489  -0.4265487\n",
      "   0.12407362]\n",
      " [-0.35136718  0.2092441....35059714 -0.62936413\n",
      "   0.2904571 ]\n",
      " [ 0.18101506  0.42410946 -0.2317656  ...  0.53654635  0.00953667\n",
      "   0.6145625 ]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.11749951  0.11184068 -0.03220356  0.25347713 -0.1896241   0.00931941\n",
      "  -0.28406128  0.00444619  0.0...051257 -0.15763533 -0.00578394  0.28317368\n",
      "   0.286955    0.00707339 -0.15360254  0.02910115  0.21408609 -0.20314196]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[533.,  49., 957.,   6., 478., 913., 572., 369., 533., 201., 521.,\n",
      "        876., 218., 430., 473.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-rnn-1000-False-12-34-15-2-1] _____\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'rnn'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 9.02328134e-01 -5.83739042e-01  5.47811128e-02  2.02584118e-01\n",
      "    1.23567879e+00 -3.60038765e-02  8... -1.17367342e-01 -1.90734491e-02 -2.82517105e-01\n",
      "   -7.82304585e-01 -1.17605567e+00  8.86327147e-01  3.75191092e-01]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-4.49165344e-01  4.56454039e-01  2.49777412e+00 -3.17866921e-01\n",
      "   -1.78055918e+00  6.47496223e-01 -1...  9.28943574e-01 -4.63028327e-02 -4.92938489e-01\n",
      "   -1.08299375e+00 -4.75532889e-01 -2.64204293e-01 -7.16733694e-01]]])\n",
      "h0_        = needle.Tensor([[[ 0.85065746 -0.745681    0.8615968  -0.06899422  0.87829953\n",
      "   -0.42613542 -0.24999231  0.10732451 -0...21  0.3395301  -0.0619198\n",
      "   -0.38186628  0.12582631  0.22236112  0.5486412   0.05884215\n",
      "    0.39563882 -0.06264587]]])\n",
      "h_         = needle.Tensor([[[ 0.85065746 -0.745681    0.8615968  -0.06899422  0.87829953\n",
      "   -0.42613542 -0.24999231  0.10732451 -0...21  0.3395301  -0.0619198\n",
      "   -0.38186628  0.12582631  0.22236112  0.5486412   0.05884215\n",
      "    0.39563882 -0.06264587]]])\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dd72340>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[ 0.03112101  0.41932172  0.24712616 ...  0.2566561  -0.25557813\n",
      "   0.1278051 ]\n",
      " [ 0.02744129 -0.364121...0.19537827 -0.4389897\n",
      "   0.40904075]\n",
      " [-0.19120729 -0.16014212  0.32489896 ... -0.08546462 -0.16732424\n",
      "   0.5766615 ]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 2.78792560e-01 -2.41113156e-01  3.70517187e-02 -2.40349621e-01\n",
      "  -2.22816661e-01 -1.17684804e-01 -1.9...01 -2.12963000e-01 -5.15780784e-02  2.48509884e-01\n",
      "  -2.30907246e-01 -2.42120266e-01  2.05232009e-01 -2.41438583e-01]])\n",
      "seq_length = 1\n",
      "seq_model  = 'rnn'\n",
      "x          = array([[544., 124., 736., 785., 504., 232., 844., 525., 848., 487., 481.,\n",
      "        816., 123., 910.,  45.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-lstm-1-False-1-1-1-1-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[0.7662947]]])\n",
      "c0_        = needle.Tensor([[[0.23090824]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.43985987]]])\n",
      "h0_        = needle.Tensor([[[0.08851971]]])\n",
      "h_         = (needle.Tensor([[[0.08851971]]]), needle.Tensor([[[0.23090824]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122de6b310>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.01005046]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.9752855  -0.08042683  0.5108648  -0.1556632 ]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-lstm-1-False-1-1-1-2-1] ________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.8003203 ]]\n",
      "\n",
      " [[-0.16221297]]])\n",
      "c0_        = needle.Tensor([[[-0.14439225]]\n",
      "\n",
      " [[-0.2752602 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.1756706]]\n",
      "\n",
      " [[-1.7794828]]])\n",
      "h0_        = needle.Tensor([[[-0.07109325]]\n",
      "\n",
      " [[-0.10388581]]])\n",
      "h_         = (needle.Tensor([[[-0.07109325]]\n",
      "\n",
      " [[-0.10388581]]]), needle.Tensor([[[-0.14439225]]\n",
      "\n",
      " [[-0.2752602 ]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122de0c5e0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.71441156]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.77010244  0.682854    0.5990375  -0.84070283]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-lstm-1-False-1-1-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.89280653]\n",
      "  [ 0.83789384]\n",
      "  [-1.8877958 ]\n",
      "  [ 0.3199424 ]\n",
      "  [-0.5265532 ]\n",
      "  [-0.0042319 ]\n",
      "  [-0.08...173]\n",
      "  [-0.49814722]\n",
      "  [ 1.353996  ]\n",
      "  [-0.94524866]\n",
      "  [ 1.1363583 ]\n",
      "  [ 1.3217999 ]\n",
      "  [-0.7733222 ]\n",
      "  [ 1.2476412 ]]])\n",
      "c0_        = needle.Tensor([[[-0.09641092]\n",
      "  [-0.09641092]\n",
      "  [-0.09641092]\n",
      "  [-0.09641092]\n",
      "  [-0.09641092]\n",
      "  [-0.09641092]\n",
      "  [-0.09...092]\n",
      "  [-0.09641092]\n",
      "  [-0.09641092]\n",
      "  [-0.09641092]\n",
      "  [-0.09641092]\n",
      "  [-0.09641092]\n",
      "  [-0.09641092]\n",
      "  [-0.09641092]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.4106622 ]\n",
      "  [ 0.722804  ]\n",
      "  [ 1.7877659 ]\n",
      "  [-1.9316541 ]\n",
      "  [-0.16869023]\n",
      "  [-0.24942495]\n",
      "  [ 0.75...183]\n",
      "  [ 0.20915881]\n",
      "  [-1.0177094 ]\n",
      "  [-0.626732  ]\n",
      "  [ 0.75251895]\n",
      "  [-0.49831545]\n",
      "  [ 1.2776854 ]\n",
      "  [ 1.8672732 ]]])\n",
      "h0_        = needle.Tensor([[[-0.04375406]\n",
      "  [-0.04375406]\n",
      "  [-0.04375406]\n",
      "  [-0.04375406]\n",
      "  [-0.04375406]\n",
      "  [-0.04375406]\n",
      "  [-0.04...406]\n",
      "  [-0.04375406]\n",
      "  [-0.04375406]\n",
      "  [-0.04375406]\n",
      "  [-0.04375406]\n",
      "  [-0.04375406]\n",
      "  [-0.04375406]\n",
      "  [-0.04375406]]])\n",
      "h_         = (needle.Tensor([[[-0.04375406]\n",
      "  [-0.04375406]\n",
      "  [-0.04375406]\n",
      "  [-0.04375406]\n",
      "  [-0.04375406]\n",
      "  [-0.04375406]\n",
      "  [-0.0...92]\n",
      "  [-0.09641092]\n",
      "  [-0.09641092]\n",
      "  [-0.09641092]\n",
      "  [-0.09641092]\n",
      "  [-0.09641092]\n",
      "  [-0.09641092]\n",
      "  [-0.09641092]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d8fb1c0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[0.6243548]\n",
      " [0.6243548]\n",
      " [0.6243548]\n",
      " [0.6243548]\n",
      " [0.6243548]\n",
      " [0.6243548]\n",
      " [0.6243548]\n",
      " [0.6243548]\n",
      " [0.6243548]\n",
      " [0.6243548]\n",
      " [0.6243548]\n",
      " [0.6243548]\n",
      " [0.6243548]\n",
      " [0.6243548]\n",
      " [0.6243548]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.07466479  0.27358502  0.42391813 -0.84545195]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-lstm-1-False-1-1-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.2023892e-03]\n",
      "  [-4.7844436e-02]\n",
      "  [-2.5191081e-01]\n",
      "  [-7.6152664e-01]\n",
      "  [ 3.2284416e-02]\n",
      "  [ 3.408...1]\n",
      "  [ 3.0964422e-01]\n",
      "  [-2.3460644e-01]\n",
      "  [-1.2650024e+00]\n",
      "  [-1.1187366e+00]\n",
      "  [ 7.9995316e-01]\n",
      "  [ 6.9556296e-01]]])\n",
      "c0_        = needle.Tensor([[[-0.01345998]\n",
      "  [-0.01345998]\n",
      "  [-0.01345998]\n",
      "  [-0.01345998]\n",
      "  [-0.01345998]\n",
      "  [-0.01345998]\n",
      "  [-0.01...484]\n",
      "  [-0.18267484]\n",
      "  [-0.18267484]\n",
      "  [-0.18267484]\n",
      "  [-0.18267484]\n",
      "  [-0.18267484]\n",
      "  [-0.18267484]\n",
      "  [-0.18267484]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.90217835]\n",
      "  [-0.8539105 ]\n",
      "  [ 0.40905383]\n",
      "  [-1.0937238 ]\n",
      "  [ 1.7113255 ]\n",
      "  [-0.09876747]\n",
      "  [-1.58...033]\n",
      "  [ 1.3813422 ]\n",
      "  [ 1.4890785 ]\n",
      "  [-0.60114014]\n",
      "  [ 0.7271692 ]\n",
      "  [ 0.09555168]\n",
      "  [ 1.3866453 ]\n",
      "  [-0.20991908]]])\n",
      "h0_        = needle.Tensor([[[-0.00500302]\n",
      "  [-0.00500302]\n",
      "  [-0.00500302]\n",
      "  [-0.00500302]\n",
      "  [-0.00500302]\n",
      "  [-0.00500302]\n",
      "  [-0.00...749]\n",
      "  [-0.07232749]\n",
      "  [-0.07232749]\n",
      "  [-0.07232749]\n",
      "  [-0.07232749]\n",
      "  [-0.07232749]\n",
      "  [-0.07232749]\n",
      "  [-0.07232749]]])\n",
      "h_         = (needle.Tensor([[[-0.00500302]\n",
      "  [-0.00500302]\n",
      "  [-0.00500302]\n",
      "  [-0.00500302]\n",
      "  [-0.00500302]\n",
      "  [-0.00500302]\n",
      "  [-0.0...84]\n",
      "  [-0.18267484]\n",
      "  [-0.18267484]\n",
      "  [-0.18267484]\n",
      "  [-0.18267484]\n",
      "  [-0.18267484]\n",
      "  [-0.18267484]\n",
      "  [-0.18267484]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d867c70>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.25850704]\n",
      " [0.25850704]\n",
      " [0.25850704]\n",
      " [0.25850704]\n",
      " [0.25850704]\n",
      " [0.25850704]\n",
      " [0.25850704]\n",
      " [0.25850704]\n",
      " [0.25850704]\n",
      " [0.25850704]\n",
      " [0.25850704]\n",
      " [0.25850704]\n",
      " [0.25850704]\n",
      " [0.25850704]\n",
      " [0.25850704]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.7331613  -0.0194117  -0.31440207 -0.3150474 ]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-lstm-1-False-1-34-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.6554625]]])\n",
      "c0_        = needle.Tensor([[[0.05913715]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[1.3248488]]])\n",
      "h0_        = needle.Tensor([[[0.00774774]]])\n",
      "h_         = (needle.Tensor([[[0.00774774]]]), needle.Tensor([[[0.05913715]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d9e7370>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[0.7546173]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.41770756 -0.62705    -0.03292871  0.43338305]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-lstm-1-False-1-34-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.6095386]]\n",
      "\n",
      " [[-2.1751277]]])\n",
      "c0_        = needle.Tensor([[[-0.9461421 ]]\n",
      "\n",
      " [[ 0.06683321]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[0.92191076]]\n",
      "\n",
      " [[0.35010257]]])\n",
      "h0_        = needle.Tensor([[[-9.8257515e-05]]\n",
      "\n",
      " [[ 2.1729024e-02]]])\n",
      "h_         = (needle.Tensor([[[-9.8257515e-05]]\n",
      "\n",
      " [[ 2.1729024e-02]]]), needle.Tensor([[[-0.9461421 ]]\n",
      "\n",
      " [[ 0.06683321]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122de97eb0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.37659702]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.11445948  0.9807642   0.21180211  0.11675227]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-lstm-1-False-1-34-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.1020794 ]\n",
      "  [ 0.6223598 ]\n",
      "  [ 0.8325051 ]\n",
      "  [-0.92062104]\n",
      "  [-2.1494434 ]\n",
      "  [-1.5078176 ]\n",
      "  [-0.97...824]\n",
      "  [-0.30200142]\n",
      "  [ 1.7565663 ]\n",
      "  [ 1.8184716 ]\n",
      "  [ 0.2741036 ]\n",
      "  [ 0.62261766]\n",
      "  [-1.2742546 ]\n",
      "  [-0.04324943]]])\n",
      "c0_        = needle.Tensor([[[0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.27313915]\n",
      "  [ 0.6790693 ]\n",
      "  [ 0.25016612]\n",
      "  [-0.9396427 ]\n",
      "  [ 0.7043021 ]\n",
      "  [ 0.54550433]\n",
      "  [-0.68...21 ]\n",
      "  [ 0.52123207]\n",
      "  [ 0.68715817]\n",
      "  [ 0.31617364]\n",
      "  [-1.5486616 ]\n",
      "  [-0.20936643]\n",
      "  [-0.56819385]\n",
      "  [ 0.57771564]]])\n",
      "h0_        = needle.Tensor([[[0.00165366]\n",
      "  [0.00165366]\n",
      "  [0.00165366]\n",
      "  [0.00165366]\n",
      "  [0.00165366]\n",
      "  [0.00165366]\n",
      "  [0.00165366]...0.00165366]\n",
      "  [0.00165366]\n",
      "  [0.00165366]\n",
      "  [0.00165366]\n",
      "  [0.00165366]\n",
      "  [0.00165366]\n",
      "  [0.00165366]\n",
      "  [0.00165366]]])\n",
      "h_         = (needle.Tensor([[[0.00165366]\n",
      "  [0.00165366]\n",
      "  [0.00165366]\n",
      "  [0.00165366]\n",
      "  [0.00165366]\n",
      "  [0.00165366]\n",
      "  [0.00165366...06]\n",
      "  [0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]\n",
      "  [0.9380006]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dab6040>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.31995845]\n",
      " [-0.31995845]\n",
      " [-0.31995845]\n",
      " [-0.31995845]\n",
      " [-0.31995845]\n",
      " [-0.31995845]\n",
      " [-0.31995845]\n",
      " [-0.31995845]\n",
      " [-0.31995845]\n",
      " [-0.31995845]\n",
      " [-0.31995845]\n",
      " [-0.31995845]\n",
      " [-0.31995845]\n",
      " [-0.31995845]\n",
      " [-0.31995845]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.7391249  0.787614  -0.987143   0.9841534]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-lstm-1-False-1-34-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.8202232 ]\n",
      "  [ 1.668973  ]\n",
      "  [-1.362989  ]\n",
      "  [-1.1063243 ]\n",
      "  [-0.76473546]\n",
      "  [ 0.3077689 ]\n",
      "  [ 0.15...64 ]\n",
      "  [-0.03940774]\n",
      "  [-0.63553005]\n",
      "  [-2.9201126 ]\n",
      "  [ 1.5449848 ]\n",
      "  [ 0.8695043 ]\n",
      "  [-0.2548651 ]\n",
      "  [ 2.1944833 ]]])\n",
      "c0_        = needle.Tensor([[[0.13558501]\n",
      "  [0.13558501]\n",
      "  [0.13558501]\n",
      "  [0.13558501]\n",
      "  [0.13558501]\n",
      "  [0.13558501]\n",
      "  [0.13558501]...0.26366773]\n",
      "  [0.26366773]\n",
      "  [0.26366773]\n",
      "  [0.26366773]\n",
      "  [0.26366773]\n",
      "  [0.26366773]\n",
      "  [0.26366773]\n",
      "  [0.26366773]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.6630012 ]\n",
      "  [ 2.1557865 ]\n",
      "  [ 0.9446997 ]\n",
      "  [-0.6556446 ]\n",
      "  [-0.0787809 ]\n",
      "  [ 0.08315621]\n",
      "  [-0.29...675]\n",
      "  [-1.175407  ]\n",
      "  [ 2.474677  ]\n",
      "  [ 0.13556089]\n",
      "  [ 0.4343809 ]\n",
      "  [-1.6420304 ]\n",
      "  [ 0.1103031 ]\n",
      "  [ 0.47064084]]])\n",
      "h0_        = needle.Tensor([[[0.09925087]\n",
      "  [0.09925087]\n",
      "  [0.09925087]\n",
      "  [0.09925087]\n",
      "  [0.09925087]\n",
      "  [0.09925087]\n",
      "  [0.09925087]...0.11772774]\n",
      "  [0.11772774]\n",
      "  [0.11772774]\n",
      "  [0.11772774]\n",
      "  [0.11772774]\n",
      "  [0.11772774]\n",
      "  [0.11772774]\n",
      "  [0.11772774]]])\n",
      "h_         = (needle.Tensor([[[0.09925087]\n",
      "  [0.09925087]\n",
      "  [0.09925087]\n",
      "  [0.09925087]\n",
      "  [0.09925087]\n",
      "  [0.09925087]\n",
      "  [0.09925087....26366773]\n",
      "  [0.26366773]\n",
      "  [0.26366773]\n",
      "  [0.26366773]\n",
      "  [0.26366773]\n",
      "  [0.26366773]\n",
      "  [0.26366773]\n",
      "  [0.26366773]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dac6b50>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.6919066]\n",
      " [0.6919066]\n",
      " [0.6919066]\n",
      " [0.6919066]\n",
      " [0.6919066]\n",
      " [0.6919066]\n",
      " [0.6919066]\n",
      " [0.6919066]\n",
      " [0.6919066]\n",
      " [0.6919066]\n",
      " [0.6919066]\n",
      " [0.6919066]\n",
      " [0.6919066]\n",
      " [0.6919066]\n",
      " [0.6919066]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[0.34929886 0.42022195 0.29947314 0.13070358]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-lstm-1-False-12-1-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.48504326  1.0722837   1.7936976  -0.06834166  0.5434297\n",
      "   -0.47757417  0.9420725  -0.8896667  -2.6078925   0.39897344\n",
      "    0.4751413  -1.1943333 ]]])\n",
      "c0_        = needle.Tensor([[[ 0.05695467 -0.0423881   0.17511426  0.13864969 -0.12572885\n",
      "    0.17271125  0.10494134 -0.22444431  0.02696218 -0.19711727\n",
      "    0.0517494  -0.01912745]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.0216583  -1.8401256   0.6613151   1.0494391   0.02864823\n",
      "    0.39594114 -1.1694133  -0.7528426   0.35944086  1.8857192\n",
      "    1.6175876   1.8304819 ]]])\n",
      "h0_        = needle.Tensor([[[ 0.02775979 -0.02589786  0.10595305  0.07599911 -0.05729308\n",
      "    0.09752225  0.05073128 -0.10060564  0.01052448 -0.11181994\n",
      "    0.02879726 -0.0079143 ]]])\n",
      "h_         = (needle.Tensor([[[ 0.02775979 -0.02589786  0.10595305  0.07599911 -0.05729308\n",
      "    0.09752225  0.05073128 -0.10060564  ...  0.13864969 -0.12572885\n",
      "    0.17271125  0.10494134 -0.22444431  0.02696218 -0.19711727\n",
      "    0.0517494  -0.01912745]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122da97f70>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[0.29719207]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.26597828  0.06374833  0.11021464  0.28577054 -0.16914149  0.28829023\n",
      "  -0.0978711   0.11900349  0.0...56669   0.07670788 -0.21797645 -0.10077088\n",
      "   0.09028652  0.2144206   0.19250269  0.20940812  0.13125609  0.03643045]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_______ test_language_model_implementation[cuda-lstm-1-False-12-1-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.51571846 -1.4852687   0.92551965 -1.1397358  -1.0055655\n",
      "   -0.67867863 -0.5960916  -1.8689212   0....25  -0.0878342   0.48858884\n",
      "   -0.26049247  0.5250563   0.8306669  -1.2989497   0.563664\n",
      "    0.79205704 -1.60069   ]]])\n",
      "c0_        = needle.Tensor([[[-0.01209254 -0.05155593  0.1419909  -0.13219601 -0.07798129\n",
      "   -0.12834315 -0.07442141 -0.14379968  0...1 -0.00183466 -0.01086868\n",
      "    0.10966466 -0.10509018 -0.01118284 -0.1207431   0.03582154\n",
      "    0.03802688  0.10905328]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.9321719   2.2195768  -0.77015597  1.2132951  -0.67087567\n",
      "   -0.7472334   0.09447088  1.5984462  -0...  -0.7208191  -0.32146174\n",
      "   -0.85902435 -0.3600861   0.13399915  0.00525444  0.46695453\n",
      "    0.75486606  1.3498062 ]]])\n",
      "h0_        = needle.Tensor([[[-0.00660265 -0.03124756  0.05746257 -0.08142284 -0.03613766\n",
      "   -0.06244422 -0.04317495 -0.06767803  0...36 -0.0009148  -0.0047326\n",
      "    0.04683576 -0.05019927 -0.00544616 -0.06225939  0.02063585\n",
      "    0.01843703  0.05212149]]])\n",
      "h_         = (needle.Tensor([[[-0.00660265 -0.03124756  0.05746257 -0.08142284 -0.03613766\n",
      "   -0.06244422 -0.04317495 -0.06767803  ... -0.00183466 -0.01086868\n",
      "    0.10966466 -0.10509018 -0.01118284 -0.1207431   0.03582154\n",
      "    0.03802688  0.10905328]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d7fdd90>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.20601965]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 1.02131620e-01 -7.56396586e-03  2.57651091e-01  1.96206391e-01\n",
      "   2.21560374e-01  1.66433863e-02  2.8...01 -1.20955773e-01 -8.03181678e-02  2.69977301e-01\n",
      "  -2.88199544e-01  1.95052929e-03  2.77652621e-01  1.32891595e-01]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-lstm-1-False-12-1-15-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.01028843 -0.6881055   0.5865195  -1.7134173   0.4698948\n",
      "    0.73750347 -0.12472814 -0.16205053  0....5  0.735964    0.15719034\n",
      "    1.2527939  -0.65885216 -1.7045822  -0.01995783  0.08431786\n",
      "    0.72985035  0.47085544]]])\n",
      "c0_        = needle.Tensor([[[ 0.09560165  0.1475287  -0.03556899 -0.10019741 -0.00892585\n",
      "    0.03675596  0.14363371  0.17003614  0...9 -0.10019741 -0.00892585\n",
      "    0.03675596  0.14363371  0.17003614  0.17083046 -0.08196668\n",
      "    0.05265181 -0.0282505 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.7578684e+00 -1.6491243e+00  3.7396833e-01 -7.9290658e-01\n",
      "    8.6646378e-01  6.3438326e-02 -2.54734...965e-01 -1.0214316e+00 -1.0036560e+00  2.7935845e-01\n",
      "   -1.2224121e+00  5.6965065e-01  1.1874930e+00  5.1698577e-01]]])\n",
      "h0_        = needle.Tensor([[[ 0.0383577   0.08416833 -0.01768981 -0.05365515 -0.0044983\n",
      "    0.01682608  0.08056019  0.08447707  0....981 -0.05365515 -0.0044983\n",
      "    0.01682608  0.08056019  0.08447707  0.10134242 -0.0349623\n",
      "    0.02967245 -0.01340937]]])\n",
      "h_         = (needle.Tensor([[[ 0.0383577   0.08416833 -0.01768981 -0.05365515 -0.0044983\n",
      "    0.01682608  0.08056019  0.08447707  0... -0.10019741 -0.00892585\n",
      "    0.03675596  0.14363371  0.17003614  0.17083046 -0.08196668\n",
      "    0.05265181 -0.0282505 ]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d9e7910>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.21651927]\n",
      " [-0.21651927]\n",
      " [-0.21651927]\n",
      " [-0.21651927]\n",
      " [-0.21651927]\n",
      " [-0.21651927]\n",
      " [-0.21651927]\n",
      " [-0.21651927]\n",
      " [-0.21651927]\n",
      " [-0.21651927]\n",
      " [-0.21651927]\n",
      " [-0.21651927]\n",
      " [-0.21651927]\n",
      " [-0.21651927]\n",
      " [-0.21651927]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 0.17046049  0.08831991  0.22156733  0.03406066  0.2102765  -0.05120765\n",
      "   0.02738409  0.03683869  0.2...06078   0.07637721 -0.27719927 -0.28824338\n",
      "   0.07394265 -0.15154257 -0.22561342  0.0942658   0.05136983 -0.08205333]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-lstm-1-False-12-1-15-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 8.82246077e-01  1.00933410e-01  1.84966505e-01  1.08564675e-01\n",
      "    6.41428709e-01 -1.14604819e+00 -3...  4.96093750e-01 -8.55474770e-01 -9.18109953e-01\n",
      "   -1.00017905e+00 -2.12153935e+00 -5.64994216e-01  6.67554557e-01]]])\n",
      "c0_        = needle.Tensor([[[-0.09964171 -0.00809279  0.00179777 -0.2222699  -0.0290827\n",
      "    0.02584302 -0.09073587 -0.00752288 -0....6 -0.1527536  -0.13098139\n",
      "   -0.15210369 -0.03827885 -0.06698395  0.09662948 -0.18882863\n",
      "    0.08647819  0.00159814]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-4.80785489e-01  3.13415408e-01  2.45180950e-01  3.39391768e-01\n",
      "    7.41246104e-01 -3.50767821e-01 -5...  1.21668589e+00  6.30971968e-01  1.68680358e+00\n",
      "    8.32674325e-01 -5.68981886e-01  4.09493625e-01 -1.52798629e+00]]])\n",
      "h0_        = needle.Tensor([[[-0.03842222 -0.00389746  0.00072211 -0.1409125  -0.01265563\n",
      "    0.01066508 -0.04453864 -0.00280493 -0...3 -0.05687037 -0.07026471\n",
      "   -0.07226469 -0.0186769  -0.03801654  0.05218573 -0.11314244\n",
      "    0.04380495  0.00083857]]])\n",
      "h_         = (needle.Tensor([[[-0.03842222 -0.00389746  0.00072211 -0.1409125  -0.01265563\n",
      "    0.01066508 -0.04453864 -0.00280493 -... -0.1527536  -0.13098139\n",
      "   -0.15210369 -0.03827885 -0.06698395  0.09662948 -0.18882863\n",
      "    0.08647819  0.00159814]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d7c88b0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.14486206]\n",
      " [0.14486206]\n",
      " [0.14486206]\n",
      " [0.14486206]\n",
      " [0.14486206]\n",
      " [0.14486206]\n",
      " [0.14486206]\n",
      " [0.14486206]\n",
      " [0.14486206]\n",
      " [0.14486206]\n",
      " [0.14486206]\n",
      " [0.14486206]\n",
      " [0.14486206]\n",
      " [0.14486206]\n",
      " [0.14486206]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.25609386  0.22712219  0.24093945  0.16243866  0.06154193 -0.26396525\n",
      "   0.28169653 -0.22238855  0.1...878691  0.1946082   0.20073795  0.05175724\n",
      "  -0.16234615 -0.28317338 -0.03242223 -0.19503711  0.02245579  0.07213151]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-lstm-1-False-12-34-1-1-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.6545706   0.43574426  0.32802573 -0.03830874 -0.44151574\n",
      "    0.06639887 -1.5507519  -1.0718825  -1.1196625  -1.7943208\n",
      "    0.52890706 -0.99303085]]])\n",
      "c0_        = needle.Tensor([[[ 0.20776379 -0.30735943 -0.36044398 -0.7816915   0.42307657\n",
      "    0.5113029   0.13450535  0.44827968 -0.10366855  0.2707647\n",
      "    0.09067131  0.08279124]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.86971337 -0.3815543  -0.22399853 -0.16368681  2.1001697\n",
      "    0.76841986  0.6515404   1.1094822   1.2701658   1.7530922\n",
      "   -0.15590651 -2.0264015 ]]])\n",
      "h0_        = needle.Tensor([[[ 0.12376504 -0.10983345 -0.11508842 -0.18456896  0.33191592\n",
      "    0.32230374  0.09123103  0.28868654 -0.09344202  0.18751927\n",
      "    0.04501531  0.03732303]]])\n",
      "h_         = (needle.Tensor([[[ 0.12376504 -0.10983345 -0.11508842 -0.18456896  0.33191592\n",
      "    0.32230374  0.09123103  0.28868654 -...8 -0.7816915   0.42307657\n",
      "    0.5113029   0.13450535  0.44827968 -0.10366855  0.2707647\n",
      "    0.09067131  0.08279124]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122ddbdca0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.2792284]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.01709201  0.00533228  0.22309642 -0.12110558  0.038339   -0.23001663\n",
      "  -0.04236524  0.18475157 -0.0...507039  0.23194769  0.16767828  0.12257197\n",
      "   0.13832861 -0.11680288  0.26063338  0.21844722  0.24575016  0.22976696]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-lstm-1-False-12-34-1-2-1] _______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.1012899  -0.31541762 -0.4681967  -0.10665599  0.12816818\n",
      "   -0.15266892 -0.8597604  -0.06048429 -0...6  -1.4844316  -1.6274623\n",
      "   -0.2975969  -2.407932   -1.1219472   1.4135486  -0.03049889\n",
      "    0.2663816   0.7776178 ]]])\n",
      "c0_        = needle.Tensor([[[-0.2321527   0.1711873  -0.021545    0.67072195 -0.10711952\n",
      "   -0.035377   -0.27550757 -0.10143936 -0...6  0.07964286  0.04601501\n",
      "   -0.0442076  -0.09224901  0.02558797 -0.03032485  0.13173579\n",
      "    0.01258843 -0.07437389]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.57845014 -2.2524936   0.47239274 -0.9676827   2.9304664\n",
      "    1.0222927   1.4294907  -0.7435185  -0....79  -1.8269033  -0.8140975\n",
      "   -0.80787545 -1.1356825  -1.9031745   0.79396844 -0.9112435\n",
      "   -0.8432976  -0.05767224]]])\n",
      "h0_        = needle.Tensor([[[-0.13326053  0.0881175  -0.01342005  0.1766536  -0.02431992\n",
      "   -0.0202528  -0.17982946 -0.04927381 -0...55  0.03522664  0.01936719\n",
      "   -0.0219064  -0.049859    0.01172222 -0.01423026  0.0635296\n",
      "    0.00734747 -0.04203084]]])\n",
      "h_         = (needle.Tensor([[[-0.13326053  0.0881175  -0.01342005  0.1766536  -0.02431992\n",
      "   -0.0202528  -0.17982946 -0.04927381 -...  0.07964286  0.04601501\n",
      "   -0.0442076  -0.09224901  0.02558797 -0.03032485  0.13173579\n",
      "    0.01258843 -0.07437389]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122db37dc0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[0.07117977]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[ 7.97563568e-02 -1.90926239e-01  2.85975069e-01 -2.64180958e-01\n",
      "  -6.30978048e-02  1.96580708e-01 -1.2...01  2.37665132e-01  4.07100059e-02  2.69174606e-01\n",
      "  -1.36027604e-01 -1.89058512e-01  1.36127874e-01 -2.01251209e-01]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-lstm-1-False-12-34-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.71397519e+00  3.38630319e-01 -1.79897547e-01 -1.32546449e+00\n",
      "    1.33129895e+00  5.48705995e-01 -9...  2.20862880e-01  1.25913575e-01 -4.86315280e-01\n",
      "   -1.06907748e-02  6.26955042e-03  9.73134220e-01 -2.87408382e-01]]])\n",
      "c0_        = needle.Tensor([[[ 0.47865012  0.17769332 -0.3143576  -0.08873142  0.31720862\n",
      "   -0.44887093  0.17311558  0.28926703 -0...  -0.08873142  0.31720862\n",
      "   -0.44887093  0.17311558  0.28926703 -0.0520421   0.42413113\n",
      "    0.23981294 -0.17431706]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.12152291 -1.3395644   0.08743067 -0.14923552 -1.1546906\n",
      "    0.8056713  -1.6044631   0.8518169  -0....26  2.1875443   0.9059692\n",
      "    1.0846242  -0.3021168   0.49812084  0.49641752  0.06579638\n",
      "   -0.37463382 -0.58084935]]])\n",
      "h0_        = needle.Tensor([[[ 0.02451296  0.1511646  -0.20492882 -0.04193144  0.13829832\n",
      "   -0.05591508  0.12149543  0.11542156 -0...2 -0.04193144  0.13829832\n",
      "   -0.05591508  0.12149543  0.11542156 -0.00891073  0.28915346\n",
      "    0.20745477 -0.14553487]]])\n",
      "h_         = (needle.Tensor([[[ 0.02451296  0.1511646  -0.20492882 -0.04193144  0.13829832\n",
      "   -0.05591508  0.12149543  0.11542156 -... -0.08873142  0.31720862\n",
      "   -0.44887093  0.17311558  0.28926703 -0.0520421   0.42413113\n",
      "    0.23981294 -0.17431706]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122de0eca0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[0.26608497]\n",
      " [0.26608497]\n",
      " [0.26608497]\n",
      " [0.26608497]\n",
      " [0.26608497]\n",
      " [0.26608497]\n",
      " [0.26608497]\n",
      " [0.26608497]\n",
      " [0.26608497]\n",
      " [0.26608497]\n",
      " [0.26608497]\n",
      " [0.26608497]\n",
      " [0.26608497]\n",
      " [0.26608497]\n",
      " [0.26608497]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-0.01245141 -0.01784042  0.07761259  0.17934847  0.072312    0.14133862\n",
      "  -0.04954465  0.03919559  0.2...888058 -0.22797748 -0.06429529  0.19905096\n",
      "   0.03981914 -0.1406309  -0.05722993 -0.22834015 -0.23904508 -0.00715763]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-lstm-1-False-12-34-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.5041078   1.4026728  -0.23736553 -0.06777828  1.014228\n",
      "   -1.1192932   0.18613732 -0.42240047 -0.2...3  -1.1989262   2.0835881\n",
      "   -0.2646584   0.28049165  0.08407123 -0.913103    0.40009326\n",
      "   -0.5780008   2.59427   ]]])\n",
      "c0_        = needle.Tensor([[[ 0.02626906  0.2988298  -0.25194505 -0.15061706 -0.17980047\n",
      "    0.1108887   0.32252142  0.2190428   0...1  0.11910452 -0.05376728\n",
      "   -0.06749404 -0.16624324 -0.13512968  0.0133617   0.24603052\n",
      "   -0.22548167 -0.0777978 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.03020358e+00 -1.31608635e-01 -1.31019986e+00 -2.53633714e+00\n",
      "   -3.79787117e-01 -8.08356643e-01 -2...  9.98433948e-01 -1.77321875e+00 -2.85569787e-01\n",
      "    1.68268979e+00 -9.32887197e-01  2.75223255e-01 -3.94612819e-01]]])\n",
      "h0_        = needle.Tensor([[[ 0.01821106  0.11851981 -0.09247354 -0.06136975 -0.05121359\n",
      "    0.06990085  0.20030136  0.0967202   0...   0.06200858 -0.03129886\n",
      "   -0.03576484 -0.07105935 -0.0602569   0.00699958  0.10427173\n",
      "   -0.09572259 -0.04126425]]])\n",
      "h_         = (needle.Tensor([[[ 0.01821106  0.11851981 -0.09247354 -0.06136975 -0.05121359\n",
      "    0.06990085  0.20030136  0.0967202   ...  0.11910452 -0.05376728\n",
      "   -0.06749404 -0.16624324 -0.13512968  0.0133617   0.24603052\n",
      "   -0.22548167 -0.0777978 ]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122da97490>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.04120903]\n",
      " [-0.04120903]\n",
      " [-0.04120903]\n",
      " [-0.04120903]\n",
      " [-0.04120903]\n",
      " [-0.04120903]\n",
      " [-0.04120903]\n",
      " [-0.04120903]\n",
      " [-0.04120903]\n",
      " [-0.04120903]\n",
      " [-0.04120903]\n",
      " [-0.04120903]\n",
      " [-0.04120903]\n",
      " [-0.04120903]\n",
      " [-0.04120903]])\n",
      "output_size = 1\n",
      "p          = needle.Tensor([[-2.31230646e-01 -2.80415088e-01 -1.80412695e-01  2.41155177e-01\n",
      "   4.15151007e-03 -1.50112137e-01  3.0...01 -5.59448190e-02  2.23939762e-01 -2.34965593e-01\n",
      "   1.73371971e-01  1.06070293e-02  8.44907835e-02  2.96410024e-02]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-lstm-1000-False-1-1-1-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.9198055]]])\n",
      "c0_        = needle.Tensor([[[-0.3146948]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[0.0536571]]])\n",
      "h0_        = needle.Tensor([[[-0.10194249]]])\n",
      "h_         = (needle.Tensor([[[-0.10194249]]]), needle.Tensor([[[-0.3146948]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d977880>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[ 2.95427293e-01 -8.34922135e-01  6.51452899e-01 -4.44941550e-01\n",
      "   8.16736877e-01 -7.44507074e-01 -3.8...01  7.81588435e-01 -5.96893847e-01  9.76229668e-01\n",
      "  -1.07049906e+00  8.50479484e-01 -1.04367590e+00  7.33062029e-01]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 0.16410565  0.6440954  -0.6397116   0.33556587]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[658.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m______ test_language_model_implementation[cuda-lstm-1000-False-1-1-1-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.01301148]]\n",
      "\n",
      " [[ 1.423189  ]]])\n",
      "c0_        = needle.Tensor([[[0.37950826]]\n",
      "\n",
      " [[0.3118644 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.19810726]]\n",
      "\n",
      " [[ 0.2241395 ]]])\n",
      "h0_        = needle.Tensor([[[0.08409023]]\n",
      "\n",
      " [[0.10325649]]])\n",
      "h_         = (needle.Tensor([[[0.08409023]]\n",
      "\n",
      " [[0.10325649]]]), needle.Tensor([[[0.37950826]]\n",
      "\n",
      " [[0.3118644 ]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122db467c0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-1.63296610e-01  7.73164868e-01 -3.79932135e-01  3.27973127e-01\n",
      "   3.95520777e-01 -1.01992869e+00  5.4...01 -5.13049841e-01 -1.53772116e-01 -3.88867706e-01\n",
      "  -2.96751380e-01 -7.29387105e-01 -4.50781852e-01  8.96349669e-01]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 0.42513967 -0.9368921   0.9436574  -0.44111544]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[657.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-lstm-1000-False-1-1-15-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-0.15741071]\n",
      "  [-0.83460355]\n",
      "  [ 0.06998521]\n",
      "  [ 1.1641151 ]\n",
      "  [-0.88390344]\n",
      "  [-0.52134466]\n",
      "  [ 0.58...214]\n",
      "  [ 0.18436003]\n",
      "  [-2.3362615 ]\n",
      "  [-0.20937419]\n",
      "  [ 0.57846045]\n",
      "  [-1.0434073 ]\n",
      "  [-1.208207  ]\n",
      "  [ 0.30639762]]])\n",
      "c0_        = needle.Tensor([[[-0.6335257 ]\n",
      "  [-0.5406191 ]\n",
      "  [-0.6517171 ]\n",
      "  [-0.53517914]\n",
      "  [-0.54606485]\n",
      "  [-0.6034763 ]\n",
      "  [-0.29...706]\n",
      "  [-0.5776936 ]\n",
      "  [-0.4901272 ]\n",
      "  [-0.3013762 ]\n",
      "  [-0.55016863]\n",
      "  [-0.59403825]\n",
      "  [-0.4179822 ]\n",
      "  [-0.5536285 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.53956616]\n",
      "  [-0.16797405]\n",
      "  [-0.19809617]\n",
      "  [-0.64548427]\n",
      "  [ 0.42378786]\n",
      "  [ 0.6992507 ]\n",
      "  [-1.03...08 ]\n",
      "  [ 1.1152579 ]\n",
      "  [ 0.9209164 ]\n",
      "  [-0.29780304]\n",
      "  [-0.05410396]\n",
      "  [-0.63115484]\n",
      "  [ 1.0227426 ]\n",
      "  [ 1.3624773 ]]])\n",
      "h0_        = needle.Tensor([[[-0.42808336]\n",
      "  [-0.24690765]\n",
      "  [-0.4825256 ]\n",
      "  [-0.23944508]\n",
      "  [-0.25463766]\n",
      "  [-0.3556308 ]\n",
      "  [-0.06...681]\n",
      "  [-0.30535126]\n",
      "  [-0.18624437]\n",
      "  [-0.0631798 ]\n",
      "  [-0.2606419 ]\n",
      "  [-0.336141  ]\n",
      "  [-0.12485627]\n",
      "  [-0.265828  ]]])\n",
      "h_         = (needle.Tensor([[[-0.42808336]\n",
      "  [-0.24690765]\n",
      "  [-0.4825256 ]\n",
      "  [-0.23944508]\n",
      "  [-0.25463766]\n",
      "  [-0.3556308 ]\n",
      "  [-0.0...06]\n",
      "  [-0.5776936 ]\n",
      "  [-0.4901272 ]\n",
      "  [-0.3013762 ]\n",
      "  [-0.55016863]\n",
      "  [-0.59403825]\n",
      "  [-0.4179822 ]\n",
      "  [-0.5536285 ]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d5f8e20>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.40905535 -0.97637355  0.04052731 ... -0.48559037 -0.5071575\n",
      "  -1.1006364 ]\n",
      " [-0.39039105 -0.900972 ....43127078 -0.30935162\n",
      "  -0.81179523]\n",
      " [-0.39234018 -0.90884626  0.183998   ... -0.45652422 -0.40131253\n",
      "  -0.9460789 ]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 0.332223   -0.5303452  -0.5401713  -0.97672397]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[400., 804.,  58., 972., 325., 844., 184., 772., 308.,   4., 648.,\n",
      "        971., 118., 871., 789.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-lstm-1000-False-1-1-15-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 2.0139706 ]\n",
      "  [ 1.0606725 ]\n",
      "  [-0.13568825]\n",
      "  [ 0.09597873]\n",
      "  [ 0.06477105]\n",
      "  [-1.6415964 ]\n",
      "  [-1.19...337]\n",
      "  [-1.8935969 ]\n",
      "  [-0.2741788 ]\n",
      "  [-0.0613507 ]\n",
      "  [-0.9656221 ]\n",
      "  [-0.58194643]\n",
      "  [-1.617876  ]\n",
      "  [-1.336707  ]]])\n",
      "c0_        = needle.Tensor([[[ 1.05902493e-01]\n",
      "  [ 2.29537547e-01]\n",
      "  [ 1.21992186e-01]\n",
      "  [ 1.24365680e-01]\n",
      "  [-9.11226049e-02]\n",
      "  [ ... 4.32941884e-01]\n",
      "  [ 4.42342520e-01]\n",
      "  [ 4.54463631e-01]\n",
      "  [ 4.49094683e-01]\n",
      "  [ 4.45468754e-01]\n",
      "  [ 4.50674742e-01]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 1.6108307 ]\n",
      "  [-0.93560094]\n",
      "  [ 0.06261684]\n",
      "  [ 0.4625872 ]\n",
      "  [ 0.92138094]\n",
      "  [-0.50128317]\n",
      "  [-0.07...57 ]\n",
      "  [-0.38131055]\n",
      "  [-0.89493   ]\n",
      "  [ 1.3769238 ]\n",
      "  [ 1.589868  ]\n",
      "  [-0.8042049 ]\n",
      "  [-0.19233757]\n",
      "  [-0.01187883]]])\n",
      "h0_        = needle.Tensor([[[ 3.1546682e-02]\n",
      "  [ 7.8860387e-02]\n",
      "  [ 3.6960892e-02]\n",
      "  [ 3.7774969e-02]\n",
      "  [-2.1635585e-02]\n",
      "  [ 8.178...1]\n",
      "  [ 3.0121535e-01]\n",
      "  [ 3.0567315e-01]\n",
      "  [ 3.1126466e-01]\n",
      "  [ 3.0880982e-01]\n",
      "  [ 3.0713221e-01]\n",
      "  [ 3.0953589e-01]]])\n",
      "h_         = (needle.Tensor([[[ 3.1546682e-02]\n",
      "  [ 7.8860387e-02]\n",
      "  [ 3.6960892e-02]\n",
      "  [ 3.7774969e-02]\n",
      "  [-2.1635585e-02]\n",
      "  [ 8.17...4.32941884e-01]\n",
      "  [ 4.42342520e-01]\n",
      "  [ 4.54463631e-01]\n",
      "  [ 4.49094683e-01]\n",
      "  [ 4.45468754e-01]\n",
      "  [ 4.50674742e-01]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d6e2520>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.2450589  -0.863078    0.316322   ...  0.39405844  1.1514168\n",
      "   0.5877799 ]\n",
      " [-0.24326298 -0.8597230...  0.39383215  1.1520377\n",
      "   0.5882707 ]\n",
      " [-0.24622884 -0.86526364  0.31916484 ...  0.39311522  1.154005\n",
      "   0.5898259 ]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.0238392  -0.02279508 -0.39471307  0.95810664]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[952., 256., 224., 441., 277., 838., 556., 693., 210., 838., 402.,\n",
      "        472., 158.,  60., 278.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-lstm-1000-False-1-34-1-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.0186608]]])\n",
      "c0_        = needle.Tensor([[[-0.9967923]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[0.6830903]]])\n",
      "h0_        = needle.Tensor([[[-0.05586454]]])\n",
      "h_         = (needle.Tensor([[[-0.05586454]]]), needle.Tensor([[[-0.9967923]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122da9c520>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-3.96967560e-01 -9.23355758e-01  7.12238431e-01 -6.95764460e-03\n",
      "  -5.27897835e-01 -5.24820328e-01  9.4...01  9.55494165e-01  8.85879040e-01 -6.21501327e-01\n",
      "   7.80022383e-01  5.61617672e-01  5.39458022e-02 -8.10496330e-01]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 0.633687   -0.1404     -0.81869876  0.9513527 ]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[655.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-lstm-1000-False-1-34-1-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-1.0277467 ]]\n",
      "\n",
      " [[-0.55288863]]])\n",
      "c0_        = needle.Tensor([[[0.8200748 ]]\n",
      "\n",
      " [[0.18772832]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[1.274355]]\n",
      "\n",
      " [[0.041184]]])\n",
      "h0_        = needle.Tensor([[[0.46556857]]\n",
      "\n",
      " [[0.11714068]]])\n",
      "h_         = (needle.Tensor([[[0.46556857]]\n",
      "\n",
      " [[0.11714068]]]), needle.Tensor([[[0.8200748 ]]\n",
      "\n",
      " [[0.18772832]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dc593d0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[ 0.7224379   0.02976801  0.37231946  0.70324993 -0.6665764  -0.5922048\n",
      "  -0.691606    0.9142659  -1.00...1591814 -0.79976124  0.57426715  0.8403886   0.5172939   0.8520275\n",
      "  -0.8331158  -0.523228    0.0696344   0.64276165]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 0.7876111   0.21307671 -0.3685779  -0.41248244]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[631.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-lstm-1000-False-1-34-15-1-1] _____\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.4036629 ]\n",
      "  [ 0.67054343]\n",
      "  [ 1.4137117 ]\n",
      "  [-0.90343255]\n",
      "  [ 1.8010461 ]\n",
      "  [ 0.76976454]\n",
      "  [-0.67...1  ]\n",
      "  [ 3.1536386 ]\n",
      "  [-1.2475    ]\n",
      "  [-0.78995895]\n",
      "  [ 0.76899874]\n",
      "  [-0.25927007]\n",
      "  [-0.38059485]\n",
      "  [ 0.30539027]]])\n",
      "c0_        = needle.Tensor([[[ 0.64672875]\n",
      "  [-0.11525745]\n",
      "  [ 0.36085162]\n",
      "  [ 0.08166248]\n",
      "  [ 0.12501276]\n",
      "  [-0.00543615]\n",
      "  [ 0.02...489]\n",
      "  [-0.77665514]\n",
      "  [ 0.77029896]\n",
      "  [-0.17752786]\n",
      "  [ 0.02666374]\n",
      "  [ 0.9203482 ]\n",
      "  [ 0.9737859 ]\n",
      "  [-0.00647375]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.47801465]\n",
      "  [ 0.5247543 ]\n",
      "  [ 1.2326607 ]\n",
      "  [ 0.905315  ]\n",
      "  [ 0.01635304]\n",
      "  [ 1.2151544 ]\n",
      "  [-0.30...96 ]\n",
      "  [-0.00264689]\n",
      "  [ 0.3175158 ]\n",
      "  [ 0.2199615 ]\n",
      "  [ 1.6980988 ]\n",
      "  [-0.45564246]\n",
      "  [-1.499648  ]\n",
      "  [-1.6248593 ]]])\n",
      "h0_        = needle.Tensor([[[ 0.3544191 ]\n",
      "  [-0.11136967]\n",
      "  [ 0.21316445]\n",
      "  [ 0.02220736]\n",
      "  [ 0.01629057]\n",
      "  [-0.00519807]\n",
      "  [ 0.02...509]\n",
      "  [-0.628383  ]\n",
      "  [ 0.11368545]\n",
      "  [-0.04099156]\n",
      "  [ 0.02565658]\n",
      "  [ 0.02789915]\n",
      "  [ 0.00514261]\n",
      "  [-0.00569106]]])\n",
      "h_         = (needle.Tensor([[[ 0.3544191 ]\n",
      "  [-0.11136967]\n",
      "  [ 0.21316445]\n",
      "  [ 0.02220736]\n",
      "  [ 0.01629057]\n",
      "  [-0.00519807]\n",
      "  [ 0.0...89]\n",
      "  [-0.77665514]\n",
      "  [ 0.77029896]\n",
      "  [-0.17752786]\n",
      "  [ 0.02666374]\n",
      "  [ 0.9203482 ]\n",
      "  [ 0.9737859 ]\n",
      "  [-0.00647375]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d7fd280>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[ 0.57150763 -0.23518075 -1.2089195  ...  0.04640574  0.4897584\n",
      "   0.43386033]\n",
      " [ 0.8102799  -0.3103306...0.09773483  0.56058264\n",
      "   0.5830786 ]\n",
      " [ 0.75610703 -0.2932805  -0.84988374 ...  0.09932693  0.5627794\n",
      "   0.587707  ]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.1794747  -0.33518818 -0.06870388 -0.4318722 ]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[992., 872., 200., 656., 576., 983., 371., 308., 645., 960., 489.,\n",
      "        512.,  46., 210., 546.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-lstm-1000-False-1-34-15-2-1] _____\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 1, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.4513916 ]\n",
      "  [ 0.9778519 ]\n",
      "  [ 1.2360182 ]\n",
      "  [ 0.31479192]\n",
      "  [-0.907556  ]\n",
      "  [ 0.200306  ]\n",
      "  [-0.75...704]\n",
      "  [ 1.369389  ]\n",
      "  [ 1.3460667 ]\n",
      "  [ 0.9816053 ]\n",
      "  [ 0.6670352 ]\n",
      "  [-0.19253094]\n",
      "  [-0.05989458]\n",
      "  [-0.71300274]]])\n",
      "c0_        = needle.Tensor([[[ 0.1010905 ]\n",
      "  [-0.12745944]\n",
      "  [ 0.4930879 ]\n",
      "  [ 0.45654663]\n",
      "  [ 0.9896611 ]\n",
      "  [-0.66013   ]\n",
      "  [ 0.19...227]\n",
      "  [ 0.33980605]\n",
      "  [ 0.30389747]\n",
      "  [ 0.3638824 ]\n",
      "  [ 0.3961784 ]\n",
      "  [ 0.30575776]\n",
      "  [ 0.30029255]\n",
      "  [ 0.4010266 ]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 1.1646583 ]\n",
      "  [ 1.6369458 ]\n",
      "  [ 0.38771945]\n",
      "  [ 0.04025381]\n",
      "  [-0.8574231 ]\n",
      "  [ 0.3244236 ]\n",
      "  [-0.78...444]\n",
      "  [-1.110096  ]\n",
      "  [-0.77000254]\n",
      "  [ 0.68520886]\n",
      "  [ 0.73202586]\n",
      "  [-1.195196  ]\n",
      "  [ 1.9784569 ]\n",
      "  [ 0.3869936 ]]])\n",
      "h0_        = needle.Tensor([[[ 0.01322711]\n",
      "  [-0.00369699]\n",
      "  [ 0.00374683]\n",
      "  [ 0.02785829]\n",
      "  [ 0.46794543]\n",
      "  [-0.3024435 ]\n",
      "  [ 0.04...417]\n",
      "  [ 0.22821948]\n",
      "  [ 0.21064414]\n",
      "  [ 0.23890425]\n",
      "  [ 0.2517642 ]\n",
      "  [ 0.21160105]\n",
      "  [ 0.20877576]\n",
      "  [ 0.25354305]]])\n",
      "h_         = (needle.Tensor([[[ 0.01322711]\n",
      "  [-0.00369699]\n",
      "  [ 0.00374683]\n",
      "  [ 0.02785829]\n",
      "  [ 0.46794543]\n",
      "  [-0.3024435 ]\n",
      "  [ 0.0...27]\n",
      "  [ 0.33980605]\n",
      "  [ 0.30389747]\n",
      "  [ 0.3638824 ]\n",
      "  [ 0.3961784 ]\n",
      "  [ 0.30575776]\n",
      "  [ 0.30029255]\n",
      "  [ 0.4010266 ]]]))\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d9a1d60>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[ 0.8543809  -0.7395852   0.17152482 ... -0.08482955  1.1281528\n",
      "  -0.7477235 ]\n",
      " [ 0.85493267 -0.7389284...-0.08451388  1.1099647\n",
      "  -0.7280923 ]\n",
      " [ 0.86221486 -0.7302598   0.15813246 ... -0.0849838   1.1370401\n",
      "  -0.75731593]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 0.49146795  0.05163447 -0.6650038   0.98415947]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[196., 948., 930.,  18.,   7., 812., 910., 564.,  45., 312., 536.,\n",
      "        188., 345., 411., 896.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-lstm-1000-False-12-1-1-1-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.5867939  -0.61864656 -1.0867304   1.3329355   2.705425\n",
      "   -1.3926512   0.38238224 -1.440082    1.3881117  -0.8941302\n",
      "   -2.3274288  -0.31635723]]])\n",
      "c0_        = needle.Tensor([[[ 0.03709403  0.02588401  0.2019177   0.14443804  0.03438829\n",
      "    0.29047334 -0.01047486 -0.00598499  0.06745591 -0.2012917\n",
      "   -0.15325937  0.16201538]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.42166492 -0.18270753  0.8385887  -1.1504469  -2.3554504\n",
      "   -0.3400343  -1.2989515   0.0858118   0.3807543  -0.72130746\n",
      "    0.89463776 -0.37871754]]])\n",
      "h0_        = needle.Tensor([[[ 0.01410132  0.01341786  0.11402987  0.08582444  0.01933916\n",
      "    0.17866972 -0.00644266 -0.00173892  0.03018293 -0.06657477\n",
      "   -0.08916812  0.07815105]]])\n",
      "h_         = (needle.Tensor([[[ 0.01410132  0.01341786  0.11402987  0.08582444  0.01933916\n",
      "    0.17866972 -0.00644266 -0.00173892  ...   0.14443804  0.03438829\n",
      "    0.29047334 -0.01047486 -0.00598499  0.06745591 -0.2012917\n",
      "   -0.15325937  0.16201538]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122ddf0fd0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-4.94691059e-02 -1.22635223e-01 -1.53700590e-01 -1.91298872e-01\n",
      "  -2.58882761e-01 -1.81656867e-01 -8.0...01 -1.02439672e-01  2.00573474e-01  1.81314200e-01\n",
      "   2.60357529e-01 -1.05312273e-01  8.27812999e-02 -3.03362995e-01]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-2.25793883e-01  1.99005261e-01  6.70538545e-02 -1.70930102e-01\n",
      "   2.62008399e-01  1.75240219e-01 -6.2...02  3.92468423e-02  8.26301202e-02  2.51674503e-01\n",
      "  -2.03885004e-01  2.45451763e-01 -1.48428798e-01  2.23363861e-01]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[345.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-lstm-1000-False-12-1-1-2-1] ______\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.30170754  0.00931103  0.30290133 -1.2382512  -0.45037127\n",
      "   -0.74673396  0.9953753   1.4882483  -1...55  2.1276855  -2.1333625\n",
      "    0.08669069  0.63071394  1.2714185  -1.425007   -0.98216677\n",
      "   -0.0159953   1.60252   ]]])\n",
      "c0_        = needle.Tensor([[[-0.13047323  0.03509803 -0.03486961 -0.20880143  0.05909828\n",
      "   -0.14513934 -0.21693477  0.01477564 -0...042  0.11763888 -0.140935\n",
      "    0.02341773 -0.03012126  0.00432901  0.08475952 -0.11307023\n",
      "    0.13071425 -0.07015019]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[ 0.48126507  0.42870793  1.0069052   2.6173296  -0.51593715\n",
      "   -1.6744075   2.3612986   1.7458556  -1...67  0.10925218  0.26481315\n",
      "   -1.0069131   0.8747041  -0.3233555  -0.25929996 -0.5685255\n",
      "    0.65101236  0.8599306 ]]])\n",
      "h0_        = needle.Tensor([[[-0.06161384  0.01545213 -0.01740299 -0.10256854  0.03239379\n",
      "   -0.0717457  -0.10472596  0.00536925 -0...2  0.06202072 -0.05729363\n",
      "    0.0120513  -0.01381903  0.00204524  0.03529001 -0.05808116\n",
      "    0.05498315 -0.03242709]]])\n",
      "h_         = (needle.Tensor([[[-0.06161384  0.01545213 -0.01740299 -0.10256854  0.03239379\n",
      "   -0.0717457  -0.10472596  0.00536925 -...42  0.11763888 -0.140935\n",
      "    0.02341773 -0.03012126  0.00432901  0.08475952 -0.11307023\n",
      "    0.13071425 -0.07015019]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122dd22370>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.15582554 -0.04256393  0.22500353  0.1753048  -0.21838582  0.17728181\n",
      "  -0.12744272 -0.18038605 -0.0...5674    0.0479732  -0.24215671 -0.15590848  0.21776947  0.02578098\n",
      "  -0.04838294 -0.3483197  -0.25096136  0.09697706]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-1.06674328e-01  2.42229193e-01  1.39350548e-01 -6.61300197e-02\n",
      "   2.39311792e-02 -1.31910918e-02 -9.4...01  8.59636217e-02  6.01641200e-02 -1.30917817e-01\n",
      "  -1.80571526e-01 -2.59996392e-02 -2.82339513e-01  1.62713751e-01]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[83.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-lstm-1000-False-12-1-15-1-1] _____\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 0.85713273  1.1811343   1.0376214   0.48410928  0.87993574\n",
      "   -1.0225024  -0.64285797  0.21105747 -1...325  1.2194138  -0.6820513\n",
      "   -0.2004253   1.4712284  -0.5910514  -1.1578972  -1.4399108\n",
      "    0.07393146 -0.05184821]]])\n",
      "c0_        = needle.Tensor([[[-0.11535706 -0.08093984 -0.07970529 -0.15083928 -0.12106723\n",
      "   -0.03202159  0.04609838  0.00657922  0...62 -0.14324166 -0.13107355\n",
      "   -0.03886204  0.04477985  0.01406455  0.0954241   0.0087164\n",
      "    0.10554234 -0.07886463]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-0.08567768 -0.88565314 -0.9462612   1.2557544  -0.18981163\n",
      "    0.22312029 -0.08306122 -0.25934076  0...027  0.29301932 -1.0811044\n",
      "    1.1744598   2.3405235   1.1448625   0.21997917  2.0776787\n",
      "   -0.56112826 -0.34586835]]])\n",
      "h0_        = needle.Tensor([[[-0.05848877 -0.03524768 -0.04504028 -0.07159864 -0.05914762\n",
      "   -0.01649814  0.02295365  0.00331807  0...9 -0.06795592 -0.06316299\n",
      "   -0.02006595  0.02229793  0.00719226  0.05052303  0.00441092\n",
      "    0.03784383 -0.04344563]]])\n",
      "h_         = (needle.Tensor([[[-0.05848877 -0.03524768 -0.04504028 -0.07159864 -0.05914762\n",
      "   -0.01649814  0.02295365  0.00331807  ...2 -0.14324166 -0.13107355\n",
      "   -0.03886204  0.04477985  0.01406455  0.0954241   0.0087164\n",
      "    0.10554234 -0.07886463]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d9bc9d0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[ 0.10040806 -0.23949584  0.16650431 ... -0.0660642   0.1686837\n",
      "   0.1266849 ]\n",
      " [ 0.09280677 -0.2328256....07528044  0.16483478\n",
      "   0.12713748]\n",
      " [ 0.10210921 -0.24117538  0.16645618 ... -0.07035952  0.16687062\n",
      "   0.12687452]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.25005072  0.07074619 -0.01087654 -0.09933624  0.2633023   0.28383082\n",
      "   0.1158561   0.16763955 -0.2...465553  0.04520871  0.22949201 -0.18328772\n",
      "   0.00420769  0.01155833 -0.17417084  0.2846885  -0.17208567 -0.05665326]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[822., 959., 412.,  31., 882.,  55., 666.,  38., 475., 369., 690.,\n",
      "        386., 120., 927., 999.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-lstm-1000-False-12-1-15-2-1] _____\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 1\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 5.11972845e-01  6.04183935e-02  1.35453939e-01 -7.45863438e-01\n",
      "    8.91876638e-01  4.22069550e-01  1...  2.33369780e+00 -2.14904975e-02 -5.02435505e-01\n",
      "   -3.74820501e-01  2.03095102e+00 -1.69346166e+00  5.54448217e-02]]])\n",
      "c0_        = needle.Tensor([[[ 2.03630477e-02  8.30298960e-02  2.58678496e-02 -1.19196631e-01\n",
      "   -1.16256103e-02  1.43322900e-01 -7... -1.69133276e-01 -1.25296727e-01  1.86409473e-01\n",
      "   -2.49184985e-02  1.04695559e-02 -7.37101808e-02 -1.68842375e-01]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 1\n",
      "h0         = needle.Tensor([[[-1.19190955e+00  1.38314605e+00 -2.01605022e-01 -2.33160779e-01\n",
      "    5.06325841e-01  2.25941271e-01  2...  1.00490355e+00 -5.61647773e-01  3.00850570e-01\n",
      "   -9.65895772e-01 -1.28242090e-01  3.02389771e-01 -2.03372881e-01]]])\n",
      "h0_        = needle.Tensor([[[ 0.00980436  0.04817392  0.01421637 -0.04774671 -0.00430741\n",
      "    0.0712162  -0.04022263 -0.00517736  0...   0.08484885 -0.08857773\n",
      "   -0.08886489 -0.07529417  0.1055492  -0.01266552  0.00399304\n",
      "   -0.04582086 -0.07561112]]])\n",
      "h_         = (needle.Tensor([[[ 0.00980436  0.04817392  0.01421637 -0.04774671 -0.00430741\n",
      "    0.0712162  -0.04022263 -0.00517736  ...-1.69133276e-01 -1.25296727e-01  1.86409473e-01\n",
      "   -2.49184985e-02  1.04695559e-02 -7.37101808e-02 -1.68842375e-01]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d8cc100>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.16531883 -0.26279023 -0.20892046 ... -0.13437551  0.02887273\n",
      "   0.09536498]\n",
      " [-0.16670674 -0.265203...0.13454744  0.02861664\n",
      "   0.0957199 ]\n",
      " [-0.16749185 -0.26639608 -0.2078127  ... -0.13606931  0.0265926\n",
      "   0.09877439]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 0.19257984 -0.27776232 -0.19808938 -0.07482929  0.08891733 -0.2582239\n",
      "  -0.15337306  0.07861111  0.25...3017002 -0.20573713  0.08700688  0.2354555\n",
      "   0.20598039  0.02043812  0.20158978 -0.1547352   0.21095674 -0.23441704]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[659., 547., 254., 823., 456., 765., 188., 193.,  20., 298., 154.,\n",
      "        817.,  23., 359., 888.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-lstm-1000-False-12-34-1-1-1] _____\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[ 0.63168824 -0.38308266  0.5615775  -1.0143027  -0.9330717\n",
      "    0.2700853  -0.17581078  0.537507    1.1303936  -0.21568377\n",
      "    0.31720698  1.1777153 ]]])\n",
      "c0_        = needle.Tensor([[[ 0.22580358  0.40613607 -0.23668529  0.19065969 -0.69658387\n",
      "    0.8242251  -0.3027378  -0.33251783  0.56213266  0.4774112\n",
      "   -0.41212565 -0.06582651]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.1929736   0.3314435  -0.01058134  1.1055508  -0.12255757\n",
      "    0.06990878  1.2215285   0.3888448   0.1945505  -1.6797084\n",
      "   -0.06991651  0.280528  ]]])\n",
      "h0_        = needle.Tensor([[[ 0.15918967  0.33919263 -0.16338712  0.13624305 -0.41176373\n",
      "    0.34594086 -0.20167005 -0.15226139  0.16795687  0.25638554\n",
      "   -0.11062521 -0.03797923]]])\n",
      "h_         = (needle.Tensor([[[ 0.15918967  0.33919263 -0.16338712  0.13624305 -0.41176373\n",
      "    0.34594086 -0.20167005 -0.15226139  ...9  0.19065969 -0.69658387\n",
      "    0.8242251  -0.3027378  -0.33251783  0.56213266  0.4774112\n",
      "   -0.41212565 -0.06582651]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122ddc2e20>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[ 2.89138019e-01  1.06094122e-01 -2.26921253e-02  1.18780471e-01\n",
      "  -3.34999822e-02  5.16443253e-02  2.1...01  1.83726802e-01 -2.36649588e-01  2.32713044e-01\n",
      "  -1.14288121e-01 -1.16312966e-01 -1.41143173e-01  7.72940069e-02]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-0.22602075 -0.11568716  0.0545978  -0.00758421  0.05550113  0.2677353\n",
      "  -0.0507022   0.18464507 -0.04...394023 -0.04101422 -0.09220007  0.10347108\n",
      "  -0.07009436  0.06768291 -0.099283   -0.06925507 -0.18125501  0.1965004 ]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[115.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m_____ test_language_model_implementation[cuda-lstm-1000-False-12-34-1-2-1] _____\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 1\n",
      "c0         = needle.Tensor([[[-0.23648499  2.0298579   0.02264493  2.3861187   1.1815099\n",
      "    1.1969525  -0.5986841  -0.44794622  0....58   2.0717087   0.5258665\n",
      "    0.6221753  -0.31798467  1.3168404   0.6577743   2.0477052\n",
      "   -0.04477667 -0.20196119]]])\n",
      "c0_        = needle.Tensor([[[ 0.34174788  0.22011235  0.04101252 -0.18233033  0.46651512\n",
      "   -0.16028269  0.23604155 -0.47890502 -0...91  0.04958     0.13316607\n",
      "   -0.12015565 -0.21244921 -0.08147225 -0.10150301  0.2325541\n",
      "   -0.03871147 -0.12104668]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 2.132017   -0.71583563 -0.6763416   1.0734042   0.9603533\n",
      "    2.4341125   0.43986976 -1.8383502   0....91 -0.17503202  1.6004313\n",
      "   -0.26765892 -0.3442297  -0.5960106   0.08624668 -0.18370226\n",
      "    0.7723123  -1.539257  ]]])\n",
      "h0_        = needle.Tensor([[[ 0.21930781  0.15363038  0.00513796 -0.10827283  0.36680016\n",
      "   -0.11643825  0.15081066 -0.28434116 -0...9  0.02963252  0.05948009\n",
      "   -0.06078837 -0.10207494 -0.03837739 -0.04246365  0.12381976\n",
      "   -0.01871157 -0.06082524]]])\n",
      "h_         = (needle.Tensor([[[ 0.21930781  0.15363038  0.00513796 -0.10827283  0.36680016\n",
      "   -0.11643825  0.15081066 -0.28434116 -...1  0.04958     0.13316607\n",
      "   -0.12015565 -0.21244921 -0.08147225 -0.10150301  0.2325541\n",
      "   -0.03871147 -0.12104668]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d84ed60>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[ 0.22314337  0.21171343  0.27380383 -0.11305879  0.15337384  0.03851241\n",
      "  -0.17507097  0.17786768  0.0...601897 -0.16152525 -0.04078292  0.10741563  0.13792962 -0.24944535\n",
      "  -0.1077507   0.17500986 -0.104064    0.06191199]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-1.77946925e-01 -1.26804681e-02 -1.68896601e-01  2.27242514e-01\n",
      "   6.22932538e-02  1.21515460e-01 -1.5...01  2.82692760e-01 -1.69610277e-01 -2.80226678e-01\n",
      "  -4.29976471e-02 -9.93110687e-02 -1.53891504e-01 -2.38917962e-01]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[745.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m____ test_language_model_implementation[cuda-lstm-1000-False-12-34-15-1-1] _____\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[ 1.1652015   0.6421255  -0.78335613  0.34818876  1.3762124\n",
      "   -0.6400498  -1.0374693   0.6242572  -0....99   0.7488966   0.7872464\n",
      "   -2.2031517   0.9190952  -0.03713661  0.75242937  1.2803999\n",
      "    0.2603578  -0.7320167 ]]])\n",
      "c0_        = needle.Tensor([[[ 2.73957998e-01  5.83688691e-02  1.67095110e-01 -3.41353267e-02\n",
      "    6.00480735e-01 -3.66766959e-01  1...  6.24431610e-01 -6.22824356e-02 -2.34027222e-01\n",
      "   -3.23676497e-01  5.07523894e-01 -3.93810958e-01  5.25549911e-02]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[ 0.11180218 -1.2407348  -2.2909417   2.2815125   0.85167813\n",
      "    0.99331737 -0.77972955 -0.7391859   2...65 -0.7975426  -0.16727352\n",
      "   -1.6345788   0.05601054 -1.3124211  -0.94082683 -1.2493151\n",
      "    0.68908846  2.494081  ]]])\n",
      "h0_        = needle.Tensor([[[ 1.32939339e-01  2.12072786e-02  6.63853511e-02 -2.39501037e-02\n",
      "    1.71956763e-01 -1.99688405e-01  3...  8.55048895e-02 -5.41088693e-02 -1.88005313e-01\n",
      "   -3.58170941e-02  9.58764181e-02 -2.72936553e-01  1.55045250e-02]]])\n",
      "h_         = (needle.Tensor([[[ 1.32939339e-01  2.12072786e-02  6.63853511e-02 -2.39501037e-02\n",
      "    1.71956763e-01 -1.99688405e-01  ... 6.24431610e-01 -6.22824356e-02 -2.34027222e-01\n",
      "   -3.23676497e-01  5.07523894e-01 -3.93810958e-01  5.25549911e-02]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122de6b2b0>\n",
      "num_layers = 1\n",
      "output     = needle.Tensor([[-0.20615938  0.19344309 -0.07830049 ...  0.3132062  -0.1116563\n",
      "   0.07198589]\n",
      " [-0.18652895  0.0402330....4241073   0.05145633\n",
      "  -0.14934157]\n",
      " [ 0.01126343  0.01017015  0.13537678 ...  0.2787038   0.00751801\n",
      "  -0.19467844]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[ 1.63826883e-01 -1.41389176e-01  1.49482533e-01 -2.04688236e-01\n",
      "  -1.56299338e-01  2.73500532e-01  1.9...01 -9.90695730e-02  6.21357970e-02 -1.14975587e-01\n",
      "   2.59477254e-02 -1.78391442e-01 -1.71831369e-01 -2.30617270e-01]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[982., 479., 803., 914., 328.,  66., 134.,  72., 273., 928., 754.,\n",
      "         33., 676.,  88.,  32.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[31m\u001b[1m____ test_language_model_implementation[cuda-lstm-1000-False-12-34-15-2-1] _____\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, embedding_size = 34\n",
      "hidden_size = 12, init_hidden = False, output_size = 1000, seq_model = 'lstm'\n",
      "device = cuda(0)\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33membedding_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, EMBEDDING_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33moutput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, OUTPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_MODEL)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_language_model_implementation\u001b[39;49;00m(seq_length, num_layers, batch_size, embedding_size, hidden_size,\n",
      "                            init_hidden, output_size, seq_model, device):\n",
      "        \u001b[90m#TODO add test for just nn.embedding?\u001b[39;49;00m\n",
      "        x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "        h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "        c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "    \n",
      "        model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(h_, \u001b[96mtuple\u001b[39;49;00m)\n",
      "            h0_, c0_ = h_\n",
      "            \u001b[94massert\u001b[39;49;00m c0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "            h0_ = h_\n",
      "        \u001b[94massert\u001b[39;49;00m h0_.shape == (num_layers, batch_size, hidden_size)\n",
      "        \u001b[94massert\u001b[39;49;00m output.shape == (batch_size * seq_length, output_size)\n",
      "        \u001b[90m#TODO actually test values\u001b[39;49;00m\n",
      "        output.backward()\n",
      "        \u001b[94mfor\u001b[39;49;00m p \u001b[95min\u001b[39;49;00m model.parameters():\n",
      ">           \u001b[94massert\u001b[39;49;00m p.grad \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AttributeError: 'Parameter' object has no attribute 'grad'\u001b[0m\n",
      "\n",
      "batch_size = 15\n",
      "c0         = needle.Tensor([[[-1.22600126e+00 -4.28522795e-01 -9.88741994e-01 -7.34324515e-01\n",
      "    1.72432077e+00  8.85813534e-02  8...  2.40991282e+00  3.17920732e+00  1.91730261e+00\n",
      "    8.67069066e-01 -1.66986334e+00  6.00777924e-01  6.15044415e-01]]])\n",
      "c0_        = needle.Tensor([[[-4.12097722e-01 -3.97606939e-01  4.23870772e-01  1.46046296e-01\n",
      "   -1.19413808e-01  7.58420080e-02 -3... -8.98489356e-02 -1.28650457e-01  1.23576939e-01\n",
      "   -1.71209738e-01  9.21061710e-02 -1.19042270e-01  7.78756291e-03]]])\n",
      "device     = cuda(0)\n",
      "embedding_size = 34\n",
      "h0         = needle.Tensor([[[-1.58295441e+00 -2.34616446e+00  7.45915234e-01  3.09935724e-03\n",
      "    1.68751433e-01 -1.41611695e+00 -1...  5.04944682e-01  2.82257676e-01  1.69209003e-01\n",
      "   -8.59573931e-02  3.70107085e-01  9.16817427e-01 -1.56482470e+00]]])\n",
      "h0_        = needle.Tensor([[[-8.37504193e-02 -2.95527905e-01  2.76101738e-01  5.26440889e-02\n",
      "   -4.60659601e-02  3.08278427e-02 -1... -5.54325655e-02 -6.76272139e-02  6.13637380e-02\n",
      "   -8.95891190e-02  4.99314331e-02 -5.61600961e-02  4.46626171e-03]]])\n",
      "h_         = (needle.Tensor([[[-8.37504193e-02 -2.95527905e-01  2.76101738e-01  5.26440889e-02\n",
      "   -4.60659601e-02  3.08278427e-02 -...-8.98489356e-02 -1.28650457e-01  1.23576939e-01\n",
      "   -1.71209738e-01  9.21061710e-02 -1.19042270e-01  7.78756291e-03]]]))\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "model      = <models.LanguageModel object at 0x7f122d7ceeb0>\n",
      "num_layers = 2\n",
      "output     = needle.Tensor([[-0.08074665  0.0316468  -0.13166359 ...  0.18826564  0.02840411\n",
      "   0.15428272]\n",
      " [-0.05509815  0.050568....2014729   0.01884761\n",
      "   0.1494222 ]\n",
      " [-0.09464105  0.03863439 -0.13129349 ...  0.18980762  0.03171474\n",
      "   0.15173352]])\n",
      "output_size = 1000\n",
      "p          = needle.Tensor([[-1.59635037e-01 -1.91565171e-01  2.02412993e-01 -2.52506614e-01\n",
      "  -1.43178836e-01  1.86882541e-01 -1.2...01 -1.75369933e-01  7.43618459e-02  1.46113649e-01\n",
      "   1.70500696e-01  7.11238459e-02  1.12588055e-01  3.49781625e-02]])\n",
      "seq_length = 1\n",
      "seq_model  = 'lstm'\n",
      "x          = array([[497., 691., 637., 392., 711., 650., 457., 158., 295., 652., 933.,\n",
      "        143., 428., 457., 722.]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:221: AttributeError\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "../../../../miniconda3/envs/py39/lib/python3.9/site-packages/mugrade/mugrade.py:71\n",
      "  /home/dasongg/miniconda3/envs/py39/lib/python3.9/site-packages/mugrade/mugrade.py:71: PytestUnknownMarkWarning: Unknown pytest.mark.hookwrapper - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html\n",
      "    @pytest.mark.hookwrapper\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/warnings.html\n",
      "=========================== short test summary info ============================\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-15-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-1-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-1-2-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-15-1-1]\n",
      "FAILED tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-15-2-1]\n",
      "\u001b[31m========= \u001b[31m\u001b[1m128 failed\u001b[0m, \u001b[32m384 passed\u001b[0m, \u001b[33m1564 deselected\u001b[0m, \u001b[33m1 warning\u001b[0m\u001b[31m in 25.60s\u001b[0m\u001b[31m =========\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"language_model_implementation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"language_model_training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.9.7, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "rootdir: /home/dasongg/cmu/10714/hws/needle\n",
      "plugins: anyio-3.3.4\n",
      "collected 47 items / 46 deselected / 1 selected                                \u001b[0m\n",
      "\n",
      "tests/hw4/test_sequence_models.py \n",
      "Submitting language_model...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "Grader test 9 passed\n",
      "Grader test 10 passed\n",
      "\u001b[31mF\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m____________________________ submit_language_model _____________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92msubmit_language_model\u001b[39;49;00m():\n",
      "        \u001b[90m# devices = [ndl.cpu(), ndl.cuda()] if ndl.cuda().enabled() else [ndl.cpu()]\u001b[39;49;00m\n",
      "        devices = [ndl.cpu(), ndl.cuda()]\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m ndl.cuda().enabled():\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mYou need a GPU to run some of these tests.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "        \u001b[94mfor\u001b[39;49;00m (device, seq_length, num_layers, batch_size, embedding_size, hidden_size, seq_model, output_size) \u001b[95min\u001b[39;49;00m itertools.product(\n",
      "            devices, TEST_SEQ_LENGTHS, TEST_NUM_LAYERS, TEST_BATCH_SIZES, TEST_EMBEDDING_SIZES, TEST_HIDDEN_SIZES, TEST_SEQ_MODEL, TEST_OUTPUT_SIZES):\n",
      "            x = np.random.randint(\u001b[94m0\u001b[39;49;00m, output_size, (seq_length, batch_size)).astype(np.float32)\n",
      "            h0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "            c0 = ndl.Tensor(np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32), device=device)\n",
      "            model = LanguageModel(embedding_size, output_size, hidden_size, num_layers, seq_model, device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = (h0, c0)\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h = h0\n",
      "            output, h_ = model(ndl.Tensor(x, device=device), h)\n",
      "            \u001b[94mif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h0_, c0_ = h_\n",
      "                mugrade_submit(c0_.numpy())\n",
      "            \u001b[94melif\u001b[39;49;00m seq_model == \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "                h0_ = h_\n",
      "            mugrade_submit(h0_.numpy())\n",
      "            mugrade_submit(output.numpy())\n",
      "    \n",
      "        device = ndl.cpu() \u001b[90m# TODO CHANGE BACK\u001b[39;49;00m\n",
      "        \u001b[90m# device = ndl.cpu()\u001b[39;49;00m\n",
      "        corpus = ndl.data.Corpus(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/ptb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, max_lines=\u001b[94m20\u001b[39;49;00m)\n",
      "        seq_len = \u001b[94m8\u001b[39;49;00m\n",
      "        num_examples = \u001b[94m88\u001b[39;49;00m\n",
      "        batch_size = \u001b[94m12\u001b[39;49;00m\n",
      "        seq_model = \u001b[33m'\u001b[39;49;00m\u001b[33mlstm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "        num_layers = \u001b[94m2\u001b[39;49;00m\n",
      "        hidden_size = \u001b[94m12\u001b[39;49;00m\n",
      "        n_epochs=\u001b[94m2\u001b[39;49;00m\n",
      "        train_data = ndl.data.batchify(corpus.train, batch_size=batch_size, device=device, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        model = LanguageModel(\u001b[94m28\u001b[39;49;00m, \u001b[96mlen\u001b[39;49;00m(corpus.dictionary), hidden_size=hidden_size, num_layers=num_layers,\n",
      "            seq_model=seq_model, device=device)\n",
      ">       train_acc, train_loss = train_ptb(model, train_data, seq_len=seq_len, n_epochs=n_epochs, device=device)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:365: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "model = <models.LanguageModel object at 0x7f36e956a580>\n",
      "data = array([[  0,  35,  37,  80,  26, 115, 133, 151,  42, 108, 148,  42],\n",
      "       [  1,  36,  42,  27,  99, 116,  28, 152,  ...78,  98,  81, 131,  42,  35,  32,  27,  32, 202],\n",
      "       [ 34,  36,  79,  24,  32, 132, 138, 168,  68, 190, 205,  98]])\n",
      "seq_len = 8, n_epochs = 2, optimizer = <class 'needle.optim.SGD'>, lr = 4.0\n",
      "weight_decay = 0.0, loss_fn = <class 'needle.nn.SoftmaxLoss'>, clip = None\n",
      "device = cpu(0), dtype = 'float32'\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtrain_ptb\u001b[39;49;00m(model, data, seq_len=\u001b[94m40\u001b[39;49;00m, n_epochs=\u001b[94m1\u001b[39;49;00m, optimizer=ndl.optim.SGD,\n",
      "              lr=\u001b[94m4.0\u001b[39;49;00m, weight_decay=\u001b[94m0.0\u001b[39;49;00m, loss_fn=nn.SoftmaxLoss, clip=\u001b[94mNone\u001b[39;49;00m,\n",
      "              device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Performs {n_epochs} epochs of training.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Args:\u001b[39;49;00m\n",
      "    \u001b[33m        model: LanguageModel instance\u001b[39;49;00m\n",
      "    \u001b[33m        data: data of shape (nbatch, batch_size) given from batchify function\u001b[39;49;00m\n",
      "    \u001b[33m        seq_len: i.e. bptt, sequence length\u001b[39;49;00m\n",
      "    \u001b[33m        n_epochs: number of epochs (int)\u001b[39;49;00m\n",
      "    \u001b[33m        optimizer: Optimizer class\u001b[39;49;00m\n",
      "    \u001b[33m        lr: learning rate (float)\u001b[39;49;00m\n",
      "    \u001b[33m        weight_decay: weight decay (float)\u001b[39;49;00m\n",
      "    \u001b[33m        loss_fn: nn.Module class\u001b[39;49;00m\n",
      "    \u001b[33m        clip: max norm of gradients (optional)\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns:\u001b[39;49;00m\n",
      "    \u001b[33m        avg_acc: average accuracy over dataset from last epoch of training\u001b[39;49;00m\n",
      "    \u001b[33m        avg_loss: average loss over dataset from last epoch of training\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m4\u001b[39;49;00m)\n",
      "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mapps/simple_training.py\u001b[0m:128: NotImplementedError\n",
      "=========================== short test summary info ============================\n",
      "FAILED tests/hw4/test_sequence_models.py::submit_language_model - NotImplemen...\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m46 deselected\u001b[0m\u001b[31m in 9.92s\u001b[0m\u001b[31m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"Bjo9uucaPqkSTXyqSoEv\" -k \"language_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can train your language model on the Penn Treebank dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import needle as ndl\n",
    "sys.path.append('./apps')\n",
    "from models import LanguageModel\n",
    "from simple_training import train_ptb, evaluate_ptb\n",
    "\n",
    "device = ndl.cpu()\n",
    "corpus = ndl.data.Corpus(\"data/ptb\", max_lines=100)\n",
    "train_data = ndl.data.batchify(corpus.train, batch_size=16, device=ndl.cpu(), dtype=\"float32\")\n",
    "model = LanguageModel(30, len(corpus.dictionary), hidden_size=10, num_layers=2, seq_model='rnn', device=ndl.cpu())\n",
    "train_ptb(model, train_data, seq_len=1, n_epochs=1)\n",
    "evaluate_ptb(model, train_data, seq_len=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
